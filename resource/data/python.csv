	title	author	date	url	text	comment_count	fullname	type	co_authors	api_index
0	Sunday Daily Thread: What's everyone working on this week?	Unknown	2023-12-31 00:00:09	https://www.reddit.com/r/Python/comments/18utrn3/sunday_daily_thread_whats_everyone_working_on/	# Weekly Thread: What's Everyone Working On This Week? üõ†Ô∏è Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to! ## How it Works: 1. **Show & Tell**: Share your current projects, completed works, or future ideas. 2. **Discuss**: Get feedback, find collaborators, or just chat about your project. 3. **Inspire**: Your project might inspire someone else, just as you might get inspired here. ## Guidelines: * Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome. * Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here. ## Example Shares: 1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate! 2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better. 3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier! Let's build and grow together! Share your journey and learn from others. Happy coding! üåü	6.0	t3_18utrn3	reddit		
1	Saturday Daily Thread: Resource Request and Sharing! Daily Thread	Unknown	2024-01-06 00:00:18	https://www.reddit.com/r/Python/comments/18zlr3i/saturday_daily_thread_resource_request_and/	"# Weekly Thread: Resource Request and Sharing üìö Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread! ## How it Works: 1. **Request**: Can't find a resource on a particular topic? Ask here! 2. **Share**: Found something useful? Share it with the community. 3. **Review**: Give or get opinions on Python resources you've used. ## Guidelines: * Please include the type of resource (e.g., book, video, article) and the topic. * Always be respectful when reviewing someone else's shared resource. ## Example Shares: 1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms. 2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures. 3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators. ## Example Requests: 1. **Looking for**: Video tutorials on web scraping with Python. 2. **Need**: Book recommendations for Python machine learning. Share the knowledge, enrich the community. Happy learning! üåü"	1.0	t3_18zlr3i	reddit		
2	How to write a python decorator (and why)	Unknown	2024-01-06 11:19:32	https://www.reddit.com/r/Python/comments/18zxxak/how_to_write_a_python_decorator_and_why/	tldr; Decorators are a nice way to wrap functions in other functions and re-use code [https://www.jaredbwelch.com/blog/How\_to\_write\_a\_python\_decorator\_and\_why](https://www.jaredbwelch.com/blog/How_to_write_a_python_decorator_and_why)	9.0	t3_18zxxak	reddit		
3	Astronomy / Space Science: Working on meteor data	git push -f	2024-01-06 17:53:49	https://www.reddit.com/r/Python/comments/1905n4g/astronomy_space_science_working_on_meteor_data/	"Hey everyone, I started with a new ""Space Science with Python"" tutorial and would like to share it with you. It is about tiny dust particles entering our atmosphere: meteors. Thankfully, the International Astronomical Union (IAU) provides free-accessible datasets with almost 1 Million meteors. These data contain physical and dynamical properties like the brightness of the meteor, its original orbit around the Sun and the appearance coordinates on the sky. If you are interested, there data is here: [https://ceres.ta3.sk/iaumdcdb/home/catalog/video](https://ceres.ta3.sk/iaumdcdb/home/catalog/video) But if you are not that deep into this space-scientific field: I started to create some Jupyter Notebooks to work with the data. The objective of my tutorial: first, understanding the meteor physics and then I'll create a Variational Autoencoder based meteor shower detection model. Anyway, if you are interested, here is the code: [https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/tree/main/Project-Meteor-Science](https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/tree/main/Project-Meteor-Science) And the corresponding tutorial playlist, and yes, my videos are not fancy YouTube professional productions, I am just a guy sharing his passion with the world: [https://www.youtube.com/watch?v=5FK3dTrW\_Fc&list=PLNvIBWkEdZ2g3ifrQ6O06fkeetf8e1NDg](https://www.youtube.com/watch?v=5FK3dTrW_Fc&list=PLNvIBWkEdZ2g3ifrQ6O06fkeetf8e1NDg) Cheers, Thomas"	2.0	t3_1905n4g	reddit		
4	One billion row challenge	Unknown	2024-01-05 21:23:44	https://www.reddit.com/r/Python/comments/18zi0o5/one_billion_row_challenge/	Just saw this repo trending and thought of doing this in different languages, e.g. Python. [https://github.com/gunnarmorling/1brc](https://github.com/gunnarmorling/1brc) Do you know if it's already available?	7.0	t3_18zi0o5	reddit		
5	Question for real devs	Unknown	2024-01-06 18:32:46	https://www.reddit.com/r/Python/comments/1906kh7/question_for_real_devs/	I've been a hobbyist game developer for a while, not very good, because of a certain wall I keep hitting. I can spend weeks on a simple idea, grow it until the code is too convoluted to work on effectively any more, and then fail to finish the project entirely. How does a real developer maintain the focus on SRP and modularization so that a really complex thing can eventually be finished? Or am I focusing on the wrong things? Mostly using Python and Pygame these days but open to change.	2.0	t3_1906kh7	reddit		
6	Python Docker Monitor to test my skills	Unknown	2024-01-06 13:52:58	https://www.reddit.com/r/Python/comments/1900fxe/python_docker_monitor_to_test_my_skills/	Hi everyone, I'm excited to share a project I've been working on to get back into development after a two-year hiatus. I'd love to get your feedback on it! I'd like to get back as a dev but I'm not sure I'm capable. [repo link](https://github.com/smscarano/docker_monitor)	1.0	t3_1900fxe	reddit		
7	FlaskyLMS - A Simple Leave Management System in Flask with Google Calendar Integration	Unknown	2024-01-06 11:30:19	https://www.reddit.com/r/Python/comments/18zy385/flaskylms_a_simple_leave_management_system_in/	A simple leave management tool that I built for myself a while ago. Now sharing on GitHub. Not the most pretty looking and lacks many bells and whistles but still gets the main job done xD * User-friendly leave request process: Employees can easily submit leave requests through a simple and intuitive interface. * Admin approval and rejection: Admins can review leave requests, approve or reject them, and provide feedback if needed. * Email notifications: Both employees and admins receive timely email notifications for new requests, approvals, and rejections. * Google Calendar integration: Approved leaves are automatically added as events to the admin's Google Calendar, ensuring visibility. Try or give your feedback: https://github.com/Suleman-Elahi/FlaskyLMS	0.0	t3_18zy385	reddit		
8	"2,000 free sign ups available for the ""Automate the Boring Stuff with Python"" online course. (Jan 2024)"	"Author of ""Automate the Boring Stuff"""	2024-01-05 21:51:36	https://www.reddit.com/r/Python/comments/18ziobn/2000_free_sign_ups_available_for_the_automate_the/	"If you want to learn to code, I've released 2,000 free sign ups for my course following my Automate the Boring Stuff with Python book (each has 1,000 sign ups, use the other one if one is sold out): https://udemy.com/course/automate/?couponCode=JAN2024FREE https://udemy.com/course/automate/?couponCode=JAN2024FREE2 If you are reading this after the sign ups are used up, you can always find [the first 15 of the course's 50 videos are free on YouTube if you want to preview them.](https://www.youtube.com/watch?v=1F_OgqRuSdI&list=PL0-84-yl1fUnRuXGFe_F7qSH1LEnn9LkW) YOU CAN ALSO WATCH THE VIDEOS WITHOUT SIGNING UP FOR THE COURSE. All of the videos on the course webpage have ""preview"" turned on. Scroll down to find and click ""Expand All Sections"" and then click the preview link. You won't have access to the forums and other materials, but you can watch the videos. **NOTE: Be sure to BUY the course for $0, and not sign up for Udemy's subscription plan. The subscription plan is free for the first seven days and then they charge you. It's selected by default. If you are on a laptop and can't click the BUY checkbox, try shrinking the browser window. Some have reported it works in mobile view.** **I'm also working on another Udemy course** that follows my recent book ""Beyond the Basic Stuff with Python"". So far I have [the first 15 of the planned 56 videos done. You can watch them for free on YouTube.](https://www.youtube.com/watch?v=kSrnLbioN6w&list=PL0-84-yl1fUmeV_2bBSguF_S0TVZk8wow&index=1) **Frequently Asked Questions:** (*read this before posting questions*) * This course is for beginners and assumes no previous programming experience, but the second half is useful for experienced programmers who want to learn about various third-party Python modules. * If you don't have time to take the course now, that's fine. Signing up gives you lifetime access so you can work on it at your own pace. * This Udemy course covers roughly the same content as the 1st edition book (the book has a little bit more, but all the basics are covered in the online course), which you can read for free online at https://inventwithpython.com * The 2nd edition of Automate the Boring Stuff with Python is free online: https://automatetheboringstuff.com/2e/ * I do plan on updating the Udemy course, but it'll take a while because I have other book projects I'm working on. If you sign up for this Udemy course, you'll get the updated content automatically once I finish it. It won't be a separate course. * It's totally fine to start on the first edition and then read the second edition later. I'll be writing a blog post to guide first edition readers to the parts of the second edition they should read. * **You're not too old to learn to code. You don't need to be ""good at math"" to be good at coding.** * Signing up is the first step. Actually finishing the course is the next. :) [There are several ways to get/stay motivated.](https://www.reddit.com/r/learnprogramming/wiki/faq#wiki_how_can_i_get.2Fstay_motivated_to_learn_programming.3F) I suggest getting a ""gym buddy"" to learn with. Check out /r/ProgrammingBuddies"	0.0	t3_18ziobn	reddit		
9	MiniFirehose - A lightweight data buffering and delivery system	Unknown	2024-01-06 14:10:55	https://www.reddit.com/r/Python/comments/1900se3/minifirehose_a_lightweight_data_buffering_and/	Hi everyone! I wanted to share a project I made in just a week. It's called MiniFirehose (somewhat similar to AWS Firehose). It's a really simple tool for managing data, kind of like Kafka or MQTT but much easier to use and lighter on resources. With MiniFirehose, you can collect messages and send them to places like your local filesystem or Amazon S3. It's not complicated to set up, and it's great if you're working on something small and don't need a big system. Since I made it pretty quickly, there might be some small bugs. If you try it and have any ideas on how to make it better, I'd love to hear from you. Or, if you know other tools like this, let me know! so I don't spend much time on it. You can check it out here: \[[mini-firehose](https://github.com/waqar-ahmed/mini-firehose)\]. I'm looking forward to hearing what you think! Thanks!	0.0	t3_1900se3	reddit		
10	VisioNomicon - GPT-4V Smart Image Renamer	Unknown	2024-01-06 02:20:59	https://www.reddit.com/r/Python/comments/18zovd6/visionomicon_gpt4v_smart_image_renamer/	VisioNomicon is a powerful Python-based command-line utility tool designed to rename image files using the capabilities of GPT-4. Descriptive filenames are generated based on a user given template and the content of the image. Try it out, and let me know what you guys think! All the details can be found at: [https://github.com/rehanzo/VisioNomicon](https://github.com/rehanzo/VisioNomicon)	0.0	t3_18zovd6	reddit		
11	Polars in Aggregate: A small subselection on where we have been working on.	Unknown	2024-01-05 09:26:56	https://www.reddit.com/r/Python/comments/18z2wp7/polars_in_aggregate_a_small_subselection_on_where/	See the blog here: https://pola.rs/posts/polars\_in\_aggregrate-0.20/	3.0	t3_18z2wp7	reddit		
12	Event Driven vs Loop Driven what's your preference?	Unknown	2024-01-05 06:33:25	https://www.reddit.com/r/Python/comments/18z08uh/event_driven_vs_loop_driven_whats_your_preference/	Streamlit is loop driven it runs every time any thing change on the app, is it performance issue for you? do you prefer Event driven framework against loop driven?	11.0	t3_18z08uh	reddit		
13	Is style transfer possible in python without downloading heavy packages?	Unknown	2024-01-06 04:43:26	https://www.reddit.com/r/Python/comments/18zroew/is_style_transfer_possible_in_python_without/	I found this project called arbitrary style transfer in the browser using tensorflow.js: https://reiinakano.com/arbitrary-image-stylization-tfjs/ (source code: https://github.com/reiinakano/arbitrary-image-stylization-tfjs) This style transfer works in the browser without uploading anything in server, it just installs a smaller version of inception v3 model to transfer style from any image. You just have to select the images from your disk and it stylizes the image. Though I have found python repositories for arbitrary style transfer but they require lots of things to setup like torch, tensoflow, network models, training datasets and also needs a gpu. Moreover I don't want to use google collab, I want something light weight like that website, but in python so that I can use it in offline mode. (with that low size inception v3 model only) In short I want some fast style transfer without downloading any heavy python packages on my system. Comment if you have any project links...	1.0	t3_18zroew	reddit		
14	MineSweeper Game in Python and Tkinter	Unknown	2024-01-05 16:32:02	https://www.reddit.com/r/Python/comments/18zaz6v/minesweeper_game_in_python_and_tkinter/	I made a MineSweeper game using Python and Tkinter. Code: https://github.com/DataWizual/MineSweeper Here's the video explaining how I did it: https://www.youtube.com/watch?v=uYv26qoHLN0	1.0	t3_18zaz6v	reddit		
15	Saving Metadata When Using Python Decorators | Jacob Padilla	Unknown	2024-01-05 19:16:22	https://www.reddit.com/r/Python/comments/18zexf0/saving_metadata_when_using_python_decorators/	Wrapping one object over another can result in the loss of valuable metadata; that's why using the functools.wraps decorator is crucial when developing your own Python decorators. In this [article](https://jacobpadilla.com/articles/Functools-Deep-Dive), explore the intricacies of functools.wraps and how it works under the hood!	0.0	t3_18zexf0	reddit		
16	Draw2Img: A simple web UI for interactive text-guided image to image generation via SDXL-Turbo, intended for any age and level of expertise.	Unknown	2024-01-05 18:06:30	https://www.reddit.com/r/Python/comments/18zd9dx/draw2img_a_simple_web_ui_for_interactive/	With the release of SDXL-Turbo in late Nov 2023, it became feasible to perform text-guided image to image generation in real-time on a consumer grade GPU. Inspired by this progress and my little cousins' artwork, I put together a web app that integrates an interactive canvas & paint tool with the capabilities of SDXL-Turbo. The project is called Draw2Img, and I want to share it here in the hopes that you or your family enjoys it as much as we have. What makes this project unique is the combination of: 1) a simple and accessible web based UI for younger or non-technical users 2) the stunning speed & quality of image generation 3) user friendly & LAN party ready (easy to run, multiple concurrent users supported) Thanks in advance for your feedback and support, cheers! https://github.com/GradientSurfer/Draw2Img	0.0	t3_18zd9dx	reddit		
17	PyWindowsScreenCapture, Tool for efficient screen capturing on Windows	Unknown	2024-01-05 17:34:58	https://www.reddit.com/r/Python/comments/18zcht6/pywindowsscreencapture_tool_for_efficient_screen/	"I stepping into the world of C programming with my latest project, ""Windows Screen Capture DLL,"" and its Python wrapper, ""PyWindowsScreenCapture."" This project represents not just a tool for efficient screen capturing on Windows but also my journey in learning and improving my C programming skills. \*\*About the Project:\*\* \- \*\*Windows Screen Capture DLL\*\*: A dynamic link library I developed to push the boundaries of screen capture performance on Windows platforms. \- \*\*PyWindowsScreenCapture\*\*: A Python wrapper that provides an easy-to-use interface to the DLL, making it accessible for Python developers. \*\*Key Features:\*\* \- Optimized for performance, potentially outperforming MSS (Python Screen Capture). \- Multi-monitor support, capturing high-resolution screens efficiently. \- Designed with simplicity and minimal dependencies in mind. The motivation behind this project was not only to create a high-performance tool but also to challenge myself and enhance my understanding of C programming. As my first serious foray into C, I'm keen on receiving feedback, suggestions, and contributions from the community to help me grow as a developer. While this project is still in its beta phase, I am proud of what I've accomplished and am excited to see how it can evolve with community input. Whether you're interested in high-speed screen capturing or have insights into C development, I welcome your thoughts and contributions. You can check out the project and contribute here: \- DLL: https://github.com/offerrall/WindowsScreenCapture \- Python Wrapper: https://github.com/offerrall/PyWindowsScreenCapture I‚Äôm looking forward to your feedback and suggestions. Thank you for being a part of my programming journey!"	0.0	t3_18zcht6	reddit		
18	Traktstats without premium	Unknown	2024-01-05 16:05:50	https://www.reddit.com/r/Python/comments/18zachx/traktstats_without_premium/	Hi Everyone, I wanted to share my python project, this python [program](https://github.com/Ahmedazim7804/trakt_vip_stats) uses trakt and tmdb api to generate all-time-stats like the official feature of trakt which requires subscription. You can then use [this app](https://github.com/Ahmedazim7804/traktstats_app) to view those stats visually. if you have any feedback, i would love to hear it. Edit :- English is not my first language, so excuse any grammer mistake.	1.0	t3_18zachx	reddit		
19	LLama.cpp AI reddit poster / commenter	Unknown	2024-01-05 15:51:39	https://www.reddit.com/r/Python/comments/18za06z/llamacpp_ai_reddit_poster_commenter/	These two scripts use llama.cpp but note - rename the llama.cpp main.exe file to main2.exe or change the bits in the code to main.exe . You can change the AI model in the code when it runs the main2.exe to a gguf model of your choice. Both ask what subreddit you want to post to and with what prompt. The scripts use reddit API which you have to have. I dunno about the reddit AI policy. I tested it on a subreddit called Hergidonia I made up to play with it. Install the modules in the beginning of the script and llama.cpp and it should work fine if the main.exe is in the folder you run it and the ai model points to your gguf model. https://pastebin.com/yqTq1aMt	0.0	t3_18za06z	reddit		
20	API Logic Server - Kafka Application Integration	Unknown	2024-01-05 03:15:19	https://www.reddit.com/r/Python/comments/18ywi8a/api_logic_server_kafka_application_integration/	API Logic Server is an open source Python project that creates executable web app projects instantly from da database, with a single CLI command -- a JSON:API with Swagger, and a multi-page multi-table Admin App. SQLAlchemy classes are created automatically. Customize the project in your IDE using Python and rules. Rules are spreadsheet-like assertions expressed in Python, implementing role-based row-level security, and multi-table constraint and derivation logic for database integrity. You can extend the API with standard Flask and SQLAlchemy. Application Integration is supported via APIs and Kafka Message handling. Consulting and Training are available. Links: * \[Docs\]([https://apilogicserver.github.io/Docs/](https://apilogicserver.github.io/Docs/)) - includes 5 min video * \[Application Integration\]([https://apilogicserver.github.io/Docs/Sample-Integration/](https://apilogicserver.github.io/Docs/Sample-Integration/)) * \[Rules\]([https://apilogicserver.github.io/Docs/Logic-Why/](https://apilogicserver.github.io/Docs/Logic-Why/)) * \[API\]([https://apilogicserver.github.io/Docs/API/](https://apilogicserver.github.io/Docs/API/)) * \[Admin Web App\](https://apilogicserver.github.io/Docs/Admin-Tour/)	2.0	t3_18ywi8a	reddit		
21	Statically enforcing frozen data classes in Python	Unknown	2024-01-04 11:54:33	https://www.reddit.com/r/Python/comments/18ybepc/statically_enforcing_frozen_data_classes_in_python/	Wrote a quick TIL on how to statically enforce frozen data classes in Python. Had to resort to crowd sourcing & good ol' stackoverflow to figure this one out since LLMs were of no help: https://rednafi.com/python/statically_enforcing_frozen_dataclasses/	6.0	t3_18ybepc	reddit		
22	GGUF LLAMA AI - Package for simplified text generation with Llama models quantized to GGUF format	Unknown	2024-01-04 17:25:39	https://www.reddit.com/r/Python/comments/18yijbp/gguf_llama_ai_package_for_simplified_text/	I'm looking for some developer who'd be interested in helping develop this simple project that tries to maximally simplify gguf models deployment on cpu to make this tech more accessible [https://github.com/laelhalawani/glai](https://github.com/laelhalawani/glai) It is a llama-ccp wrapper that simplifies use of llama based models.It features a built in ModelDB with json entries that can be used to automatically download and deploy quantized gguf models from hf.Then there are to classes AutoAI and EasyAI.The frist one takes min of 3 arguments including search query or path or url and max tokens and max input tokens. And that's all that's needed to load the model for inference. The later allows configuration of the model in few simple steps. Giving more granular control, while still prioritizing simplicity. There's a bunch of examples and detailed documentation already. The project is also published on pypi \`pip install glai\`	2.0	t3_18yijbp	reddit		
23	Friday Daily Thread: r/Python Meta and Free-Talk Fridays	Unknown	2024-01-05 00:01:09	https://www.reddit.com/r/Python/comments/18ys8mu/friday_daily_thread_rpython_meta_and_freetalk/	# Weekly Thread: Meta Discussions and Free Talk Friday üéôÔ∏è Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related! ## How it Works: 1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community. 2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community. 3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting. ## Guidelines: * All topics should be related to Python or the /r/python community. * Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy). ## Example Topics: 1. **New Python Release**: What do you think about the new features in Python 3.11? 2. **Community Events**: Any Python meetups or webinars coming up? 3. **Learning Resources**: Found a great Python tutorial? Share it here! 4. **Job Market**: How has Python impacted your career? 5. **Hot Takes**: Got a controversial Python opinion? Let's hear it! 6. **Community Ideas**: Something you'd like to see us do? tell us. Let's keep the conversation going. Happy discussing! üåü	2.0	t3_18ys8mu	reddit		
24	Clickstream Aggregation in Python with Redis	Unknown	2024-01-04 18:07:01	https://www.reddit.com/r/Python/comments/18yjjow/clickstream_aggregation_in_python_with_redis/	This is a tutorial article on how you can use Redis PubSub capabilities with the Python streaming library Bytewax to aggregate clickstreams in Python. &#x200B; https://redis.com/blog/redis-driven-dataflow-for-clickstream-aggregation-with-bytewax/	0.0	t3_18yjjow	reddit		
25	Why Python is slower than Java?	Unknown	2024-01-03 09:44:10	https://www.reddit.com/r/Python/comments/18xfmq2/why_python_is_slower_than_java/	Sorry for the stupid question, I just have strange question. If CPython interprets Python source code and saves them as byte-code in .pyc and java does similar thing only with compiler, In next request to code, interpreter will not interpret source code ,it will take previously interpreted .pyc files , why python is slower here? Both PVM and JVM will read previously saved byte code then why JVM executes much faster than PVM? Sorry for my english , let me know if u don't understand anything. I will try to explain	42.0	t3_18xfmq2	reddit		
26	Fast and secure routing development and OpenAPI bindings in sanic, flask, tornado, starlette	Unknown	2024-01-04 07:59:38	https://www.reddit.com/r/Python/comments/18y7t6j/fast_and_secure_routing_development_and_openapi/	I created a library - [pait](https://github.com/so1n/pait), which is compatible with multiple Python web frameworks. At the same time, it has absorbed some excellent designs from FastAPI. Through pait, you can quickly and safely develop routing functions and view OpenAPI data.	0.0	t3_18y7t6j	reddit		
27	Check Out Flasknotes - A Flask Note-Taking Web App!	Unknown	2024-01-04 04:13:13	https://www.reddit.com/r/Python/comments/18y3x63/check_out_flasknotes_a_flask_notetaking_web_app/	**Hey Python enthusiasts!** I'm excited to share my latest project, Flasknotes - a simple web-based note-taking application built using Flask and MySQL. This project boasts various features, including role-based authentication, CRUD operations, and the ability to mark your favorite notes. **Project Links:** * **GitHub Repository:** [Flasknotes GitHub Repo](https://github.com/ghandylan/flask-notes) * **Live Demo:** [Flasknotes Demo](https://flasknotes.pythonanywhere.com/home)	2.0	t3_18y3x63	reddit		
28	Fastest Way to Read Excel in Python	Unknown	2024-01-03 12:58:43	https://hakibenita.com/fast-excel-python	Empty	10.0	t3_18xitr3	reddit		
29	Ezsynth -- Ebsynth Video Stylization as a Python Library.	Unknown	2024-01-04 01:58:49	https://www.reddit.com/r/Python/comments/18y13rv/ezsynth_ebsynth_video_stylization_as_a_python/	Hey all! I've been working on this project on and off for a few months, and for the most part, its pretty stable at this point.If you're familiar with the program ebsynth, you'll be right at home with Ezsynth.Ezsynth is a recreation of the ebsynth video stylization process, through the use of: - a) The ebsynth.dll source code, interfaced through ctypes, - b) RAFT Optical Flow, and - C) PhyCV physics based edge detection. Ultimately the goal was to create a simple, pythonic way to achieve a similar output to the ebsynth program. Most current methods involve GUI mapping, etc, in order to make ebsynth work with python. Ezsynth is a full recreation of the original ebsynth paper, offering both the original method of stylization, and updated versions using RAFT and various PhyCV features. I've only been programming since April, most of my work is done by coming up with workflows, writing pseudo code, and then bouncing back and forth with GPT 4 on how to accomplish what I want. Check it [here](https://github.com/Trentonom0r3/Ezsynth), and I apologize for any noob mistakes or things you may find-- I'm still learning! A demo of what it does can be found [here](https://github.com/Trentonom0r3/Ezsynth/blob/a3981fa3169fb076284fba432f239017e3d7e021/ezsynthdemo.mp4)=	2.0	t3_18y13rv	reddit		
30	Simple keylogger made in Python	Unknown	2024-01-04 09:25:36	https://www.reddit.com/r/Python/comments/18y92tw/simple_keylogger_made_in_python/	Here is the repo: [https://github.com/Migue8gl/Python-scripts](https://github.com/Migue8gl/Python-scripts) I am open to criticism on what I can improve in this small project. Over time I would like to create more Python scripts touching on different areas.I have to say that. I'm not new to programming and I'm not new to Python either, but I'm sure I have some things wrong that can be fixed.	1.0	t3_18y92tw	reddit		
31	Thursday Daily Thread: Python Careers, Courses, and Furthering Education!	Unknown	2024-01-04 00:00:07	https://www.reddit.com/r/Python/comments/18xydsg/thursday_daily_thread_python_careers_courses_and/	# Weekly Thread: Professional Use, Jobs, and Education üè¢ Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**. --- ## How it Works: 1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles. 2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources. 3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally. --- ## Guidelines: - This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar. - Keep discussions relevant to Python in the professional and educational context. --- ## Example Topics: 1. **Career Paths**: What kinds of roles are out there for Python developers? 2. **Certifications**: Are Python certifications worth it? 3. **Course Recommendations**: Any good advanced Python courses to recommend? 4. **Workplace Tools**: What Python libraries are indispensable in your professional work? 5. **Interview Tips**: What types of Python questions are commonly asked in interviews? --- Let's help each other grow in our careers and education. Happy discussing! üåü	1.0	t3_18xydsg	reddit		
32	Knuckledragger: Experimenting with a Python Proof Assistant	Unknown	2024-01-03 16:19:24	https://www.reddit.com/r/Python/comments/18xn6ne/knuckledragger_experimenting_with_a_python_proof/	Hi, An idea I've toyed around for a while is how to chain together inferences of automated theorem provers like z3py into larger developments. I've started putting fingers to keyboard. The point is to make something accessible to a larger, less specialized audience and to target mathematics akin to that in sympy, so I'm very interested in feedback about what works for people. * Blog post: https://www.philipzucker.com/python-itp/ * Very WIP repo: https://github.com/philzook58/knuckledragger	2.0	t3_18xn6ne	reddit		
33	AWS Hosting Flask/Python Application on EC2 Instance	Unknown	2024-01-03 20:07:02	https://youtu.be/VFTeLN0J9Lw?si=kdOsJW004fnhzMWa	Empty	0.0	t3_18xsn2l	reddit		
34	An AI Python Web app to analyze resumes	Unknown	2024-01-04 17:08:09	https://www.reddit.com/r/Python/comments/18yi41b/an_ai_python_web_app_to_analyze_resumes/	Hey r/python, say goodbye to tedious resume evaluations ‚Äì https://resume-analyzer.ploomberapp.io/. üåê What do you guys think? I wanted to supercharge my hiring process and make smarter decisions in a snap. I've connected this code, based on Open AI and on Streamlit. This Python code is open-sourced and is available in the [GitHub repo](https://github.com/gopiashokan/AI-Powered-Resume-Analyzer-and-LinkedIn-Scraper-with-Selenium). I've hosted it on Ploomber Cloud.	8.0	t3_18yi41b	reddit		
35	Okay, I have this genuine question, why does Python allow hashing functions?	Unknown	2024-01-02 23:58:18	https://www.reddit.com/r/Python/comments/18x4kw6/okay_i_have_this_genuine_question_why_does_python/	So I was working on my programming language and was taking inspiration from Python, and realized that Python allows hashing functions and you can have functions As keys, this is what confuses me here what is the use of this, and how do they do it to begin with? Like do they have something like a dictionary data structure that has Python objects as keys? That sounds like it's memory inefficient. &#x200B;	11.0	t3_18x4kw6	reddit		
36	Pydantic has too much deprecation, making it difficult to keep up with updates and maintaining the code. Lots of functionality has been renamed, and some are removed during v1‚Üív2 transition. Even sample code from November 2023 is deprecated now! Are there better alternatives?	Unknown	2024-01-03 19:15:33	https://www.reddit.com/r/Python/comments/18xrc1y/pydantic_has_too_much_deprecation_making_it/	Almost all tutorials I see online (and ChatGPT's knowledge base) teach you Pydantic v1. There are numerous things that are deprecated during transition to v2 (@root_validator, @validator, using 'always', etc. are all gone now.). I even found a code example on its Github from November 2023 which now throws an error, saying that FieldValidationInfo is deprecated now, use <new_thing> instead... I wanted to use something to validate user inputs to my API, but getting Pydantic right and then keeping it updated has been too much unnecessary work, which makes me wonder if you have also faced this problem and what your solution is?	27.0	t3_18xrc1y	reddit		
37	PyJigsaw: A Digital Jigsaw Puzzle Factory	Unknown	2024-01-03 10:48:14	https://www.reddit.com/r/Python/comments/18xglbx/pyjigsaw_a_digital_jigsaw_puzzle_factory/	I created a jigsaw puzzle constructor which uses mostly Python with a small assist from Inkscape. You can create SVG puzzle sets and templates programmatically, which could be useful as part of a jigsaw puzzle app (my original intention for it). I've shelved the wider project but the constructor was in a decent place, so decided to tidy it up and package it. Repo and install instructions are available on my [GitHub](https://github.com/tomdeabreucodes/PyJig). If you're interested in a slightly longer post with some additional background, I also put a post up about it [here](https://tomdeabreu.uk/posts/jigsaw-puzzle-cut-template-svg/). [blank cut template](https://preview.redd.it/esielejcf7ac1.png?width=1320&format=png&auto=webp&s=2c9ceb9e18c5c5ffa4c4b07bbfcf6963b35138f5) &#x200B; [Applied cut on image](https://preview.redd.it/0b5i72uef7ac1.png?width=1320&format=png&auto=webp&s=229a039f2fc9363060698044eccbd6833f524af1) &#x200B;	0.0	t3_18xglbx	reddit		
38	llama.cpp GGUF inference in a couple lines of code	Unknown	2024-01-03 14:09:54	https://www.reddit.com/r/Python/comments/18xk9eo/llamacpp_gguf_inference_in_a_couple_lines_of_code/	&#x200B; https://preview.redd.it/l4r0ne7tf8ac1.png?width=1296&format=png&auto=webp&s=932ff628716371aa4770e574df9134d30c2bc9f5 [txtai](https://github.com/neuml/txtai) has a unified LLM pipeline that can load Hugging Face models, llama.cpp GGUF files and LLM APIs. The example above downloads a GGUF file from the Hugging Face Hub and runs inference with the model. See this article for more: [https://neuml.hashnode.dev/integrate-llm-frameworks](https://neuml.hashnode.dev/integrate-llm-frameworks)	1.0	t3_18xk9eo	reddit		
39	Python GUI framework for windows applications and embedded systems.	Unknown	2024-01-03 04:52:15	https://www.reddit.com/r/Python/comments/18xav2l/python_gui_framework_for_windows_applications_and/	A few months ago I saw someone posting maybe here or in another subreddit about a Python framework for making GUIs. I distinctly remember that it can be used to make guis for embedded systems as well as something similar to windows apps. Unfortunately, I forgot the name of it and can't seem to find that post anywhere. Does anyone have any clues as to what this framework is called? &#x200B; Many thanks\~	13.0	t3_18xav2l	reddit		
40	Polars DataFrames now have a `.plot` namespace!	:pandas_Logo: pandas Core Dev 	2024-01-02 16:32:49	https://www.reddit.com/r/Python/comments/18wti72/polars_dataframes_now_have_a_plot_namespace/	As of Polars 0.20.3, you can use \`polars.DataFrame.plot\` to visualise your data. The plotting logic isn't in Polars itself, but in hvplot (so you'll need that installed too) &#x200B; Here's some examples of what you can do: https://preview.redd.it/h8fhtnvi02ac1.png?width=693&format=png&auto=webp&s=5a299bac0df26575f3a4efa071707061cea719c4 https://preview.redd.it/k2071pvi02ac1.png?width=728&format=png&auto=webp&s=3ed2ce9e07f39b7c694f4dc8648647bed34daa60 https://preview.redd.it/r8t6oovi02ac1.png?width=680&format=png&auto=webp&s=907461be7c05fdd63b1b469cd8fd5c24c2b9741d https://preview.redd.it/bm8yuqvi02ac1.png?width=742&format=png&auto=webp&s=358da56c5c3e2d13bbf3576e655f3bc7b6e9d24a https://preview.redd.it/mi0udtvi02ac1.png?width=734&format=png&auto=webp&s=160f01651d2723742630cb5af50a90c74972c8d4	11.0	t3_18wti72	reddit		
41	I made an IDE using PyQt6 [UPDATE]	Unknown	2024-01-02 14:40:27	https://www.reddit.com/r/Python/comments/18wqxkm/i_made_an_ide_using_pyqt6_update/	&#x200B; [Editor](https://preview.redd.it/b79eg796g1ac1.png?width=1763&format=png&auto=webp&s=851ec11f48cc38652f96e4a515241dde89cf1705) [Markdown Editing](https://preview.redd.it/pi26k767g1ac1.png?width=1920&format=png&auto=webp&s=5eea5ff8f5f595a238a1010fb643183251306965) Highlighted Features: * Supports up to 30 languages w Syntax highlighting * auto complete * split pane markdown editor * terminal with Aura Text specific commands and also terminal history * plugin support * autocomplete (you can literally theme anything) GitHub: [https://github.com/rohankishore/Aura-Text](https://github.com/rohankishore/Aura-Text)	4.0	t3_18wqxkm	reddit		
42	I made an Educational Deep Learning Framework from scratch	Unknown	2024-01-02 21:02:46	https://www.reddit.com/r/Python/comments/18x097o/i_made_an_educational_deep_learning_framework/	Learning ML, I‚Äôve always been interested in **PyTorch** and its **Autograd engine** (which creates the backprop automatically). In [this project](https://github.com/eduardoleao052/Autograd-from-scratch.git), I tried to **reimplement most of PyTorch** (including the Autograd) from scratch in a **well-documented, unit tested, and interpretable** way. It was really useful for me, and I hope it can help you understand Autograd better as well! Hope you enjoy! GitHub repository [here](https://github.com/eduardoleao052/Autograd-from-scratch.git)!	3.0	t3_18x097o	reddit		
43	üçÄ How to Create Stunning Music Posters in Seconds: Introducing BeatPrints!	Unknown	2024-01-02 14:06:26	https://www.reddit.com/r/Python/comments/18wq7ru/how_to_create_stunning_music_posters_in_seconds/	&#x200B; https://preview.redd.it/2ae0jplk91ac1.png?width=1280&format=png&auto=webp&s=d6c6b7276f42dac753eb309e47fa6b12f49a1672 **Ever wondered how to create music posters like the ones you see on Pinterest?** üé® Maybe you've wanted something aesthetic to jazz up your Instagram stories or noticed your walls looking a tad empty? Perhaps you're the collector type or simply love decking out your space with artistic vibes? Look no further‚Äîintroducing BeatPrints! üé® **What's BeatPrints?** BeatPrints is your one-stop tool for crafting eye-catching music posters that stand out! It's your gateway to generate custom, beautiful posters that capture the essence of your favorite music track from Spotify. **ü§∑ Why you want to use it?** * **Ease of Use:** Say goodbye to complex design software‚ÄîBeatPrints makes poster creation straightforward and fun! * **Aesthetic Appeal:** Create posters perfect that's for Instagram, Pinterest, or maybe sprucing up your living space. * **Versatility:** Whether you're a collector, a decorator, or just love stylish visuals, BeatPrints has you covered. üîó **GitHub Project Link:** [BeatPrints on GitHub](https://github.com/TrueMyst/BeatPrints) Let BeatPrints transform your favourites music tracks into stunning posters! üé®‚ú®	1.0	t3_18wq7ru	reddit		
44	PyPy has moved to GitHub	pmatti - mattip was taken	2024-01-01 19:19:08	https://www.reddit.com/r/Python/comments/18w45u2/pypy_has_moved_to_github/	PyPy has moved its development efforts from Mercurial + Heptapod to Git + GitHub. Read more about it [here](https://www.pypy.org/posts/2023/12/pypy-moved-to-git-github.html)	6.0	t3_18w45u2	reddit		
45	Good pytube alternative?	Unknown	2024-01-02 20:44:17	https://www.reddit.com/r/Python/comments/18wzsg8/good_pytube_alternative/	I was using pytube to download my Shazam library and, well, it worked; but the AdBlock blocker in YouTube broke everything. Pytube cannot skip the ads, but is actively downloading them. Pytube seems discontinued. Does somebody know about a good alternative, or do I have to live without my downloader?	3.0	t3_18wzsg8	reddit		
46	Wednesday Daily Thread: Beginner questions	Unknown	2024-01-03 00:00:10	https://www.reddit.com/r/Python/comments/18x4mfq/wednesday_daily_thread_beginner_questions/	# Weekly Thread: Beginner Questions üêç Welcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you. ## How it Works: 1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here! 2. **Community Support**: Get answers and advice from the community. 3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources. ## Guidelines: * This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link). ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **What is the difference between a list and a tuple?** 2. **How do I read a CSV file in Python?** 3. **What are Python decorators and how do I use them?** 4. **How do I install a Python package using pip?** 5. **What is a virtual environment and why should I use one?** Let's help each other learn Python! üåü	1.0	t3_18x4mfq	reddit		
47	Python's Array: Working With Numeric Data Efficiently	Unknown	2024-01-02 17:26:23	https://realpython.com/python-array/	Empty	0.0	t3_18wut5u	reddit		
48	i made a ChatGPT bot for Telegram	Unknown	2024-01-02 14:06:58	https://www.reddit.com/r/Python/comments/18wq86m/i_made_a_chatgpt_bot_for_telegram/	This project utilizing the new Assistant OpenAl API. link to source: https://github.com/andykras/gptbot Bot is built using the async features of aiogram and AsyncOpenAl, showcasing modern asynchronous programming in Python.	1.0	t3_18wq86m	reddit		
49	Arrest v0.1.5 is released! Including a lot of new improvements based on the community feedback!	Unknown	2024-01-02 05:45:30	https://www.reddit.com/r/Python/comments/18whybi/arrest_v015_is_released_including_a_lot_of_new/	Hi everyone! I am really happy to announce Arrest [v0.1.5](https://pypi.org/project/arrest/) after the overwhelming number of feedback from the community in my last post here. A brief overview of the changes made: &#x200B; * Added support for most of the httpx arguments (i.e., cookies, auth, transport, cert, etc) as kwargs in both service and resource initializations. * Added backoff retries for all the http calls being made with configurable max retries (set as environment variable) * Add a new decorator for a resource instance \`.handler(...)\` where you can specify the subpath from the resource and define your own custom function. The function is injected with a reference to the resource instance, and the complete url for easier access. The function can be triggered as a free function but also is registered under the resource instance, so can be invoked via \`resource\_name.func\_name(...)\` * Added support for passing your own \`httpx.AsyncClient\` instance to either service or resource. (can also be a subclass of \`httpx.AsyncClient\`) For more details, please check out the [docs](https://s-bose.github.io/arrest/). [Github repo](https://github.com/s-bose/arrest) for anyone who wants to take a look! Thank you to everyone whose feedback made these changes happen. I'd appreciate it if you could let me know of anything else that might be helpful to be implemented!	1.0	t3_18whybi	reddit		
50	Build amazing AI projects with Google‚Äôs Gemini models and Python	Unknown	2024-01-02 15:49:46	https://www.reddit.com/r/Python/comments/18wshab/build_amazing_ai_projects_with_googles_gemini/	Hi everyone, I‚Äôm excited to share with you my repository of Python projects and ideas that use Google‚Äôs latest and most powerful generative AI models: Gemini-pro and Gemini-pro-vision. These models can perform various tasks such as text-to-speech conversion, interactive chat, image and video processing, and content generation. With my repository, you can: * Convert any text into natural-sounding speech with Gemini-pro * Chat with a friendly and engaging AI assistant powered by Gemini-pro-chat * Recognize and analyze images and videos with Gemini-pro-vision * Generate diverse and dynamic content such as poems, stories, code, essays, and more with Gemini-pro My repository also provides educational insights and project ideas for students and researchers who want to learn more about Google‚Äôs Gemini models and their applications. You can explore the limitless possibilities of AI with Gemini and embark on a journey of innovation and discovery. If you are interested, please check out my repository here: [https://github.com/GitCoder052023/Build-with-Gemini](https://github.com/GitCoder052023/Build-with-Gemini) I would love to hear your feedback and suggestions on how to improve my projects and ideas. Feel free to leave a comment or open an issue on GitHub. Thank you for your time and attention. I hope you enjoy building amazing AI projects with Gemini and Python. üòä	0.0	t3_18wshab	reddit		
51	I made a program that solves mazes from images!	Unknown	2024-01-01 15:41:08	https://www.reddit.com/r/Python/comments/18vz81t/i_made_a_program_that_solves_mazes_from_images/	It was made in Python, except for one file that was written in Cython. You can read more about it here -> [https://github.com/triskj0/maze-solver](https://github.com/triskj0/maze-solver) I'll be glad some of you guys check it out, and maybe even try it for yourself! I am, of course, open to any suggestions on how to continue improving it. Have a nice day, everyone!	3.0	t3_18vz81t	reddit		
52	Hypercorn 0.16.0 released - a WSGI/ASGI server supporting HTTP 1, 2, 3 and Websockets	Unknown	2024-01-01 14:07:49	https://www.reddit.com/r/Python/comments/18vxfyu/hypercorn_0160_released_a_wsgiasgi_server/	Hypercorn is a WSGI and ASGI server that supports HTTP/1, HTTP/2, HTTP/3, and WebSockets. It also supports asyncio, uvloop, and trio worker classes. This release: - Adds ProxyFixMiddleware to make it much easier to run Hypercorn behind a proxy with the headers pointing at the client rather than the proxy. - A max_requests config that forces workers to restart when hit. This helps with memory leaks as the restart frees any leaked memory. - A max keep alive requests config that limits the requests per kept-alive connection. This mitigates the HTTP/2 rapid reset attack in the same manner as Nginx. - Finally fixes many bugs. [Read more](https://github.com/pgjones/hypercorn/blob/main/CHANGELOG.rst).	3.0	t3_18vxfyu	reddit		
53	Hey Guys! Just went looking back at older projects and found this one, its a level editor/maker!	Unknown	2024-01-02 00:47:48	https://www.reddit.com/r/Python/comments/18wbx3k/hey_guys_just_went_looking_back_at_older_projects/	It is a 2d level maker that taught me more about how pygame works, now I use Godot but I really appreciate this project for how much it taught me. Just wanted feedback, I know it looks bad being just colored squares but the code is really were I think I did the best. I dunno I dont code for a living, perhaps its pathetic and worthy of public shamming, let me know what you guys think. [link](https://github.com/GithubUserNotABot/Level-maker/blob/main/main.py)	2.0	t3_18wbx3k	reddit		
54	PDFSyntax, a new Python API library to inspect and update PDF files	Unknown	2024-01-01 20:35:21	https://www.reddit.com/r/Python/comments/18w5zj3/pdfsyntax_a_new_python_api_library_to_inspect_and/	Hi! This is my pet project, written from scratch because there is so much to discover and learn in the process. The focus is on API simplicity and incremental updates (a PDF feature that is often overlooked). Progress is slow because I do not have much spare time to work on this. This ALPHA quality software is far from finished but I would love to hear some feedback and feature requests. Here is the link to the project on GitHub: [https://github.com/desgeeko/pdfsyntax](https://github.com/desgeeko/pdfsyntax) Regards	1.0	t3_18w5zj3	reddit		
55	What is SLOW_SUM in the CPython source code?	Unknown	2024-01-01 11:39:31	https://www.reddit.com/r/Python/comments/18vv3aa/what_is_slow_sum_in_the_cpython_source_code/	File: `Python/bltinmodule.c` ([link to precise line](https://github.com/python/cpython/blob/471aa752415029c508693fa7971076f5148022a6/Python/bltinmodule.c#L2551C9-L2551C17)) While reading CPython's source code I came across the `SLOW_SUM` symbol, but I couldn't find its definition. `SLOW_SUM` is referenced only once in the entire CPython source code, so I couldn't find any information on why it exists. From the source code, I understand that it's a compiler flag that disables an optimization when performing sums on numeric types through the `sum()` built-in function. However, why would you pass `SLOW_SUM` to the compiler to disable optimized sums on numeric types? I don't know if this is the right place to ask such a specific question. If it's not, can you point me to the right forum?	3.0	t3_18vv3aa	reddit		
56	Arezzo: Automatic polyphonic piano music transcription in Python	Unknown	2024-01-01 23:38:59	https://www.reddit.com/r/Python/comments/18wacbi/arezzo_automatic_polyphonic_piano_music/	[https://github.com/Kat9-123/Arezzo](https://github.com/Kat9-123/Arezzo) Through the power of Machine Learning‚Ñ¢ this program can take an audio file of (polyphonic) piano music and generate the corresponding sheet music! The code is dodgy in places, and not very well documented. As this was a school project, I didn't spend as much time as I'd have liked to refine it, because I simply ran out of time and steam. Especially the bits added last are very messy. Still, the UX is great, with a bunch of features easily accessible through a config file and command line switches. This is my first project using ML and audio processing, so that may explain why it lacks in some departments. So does it work? Sure, but not very well. Marginally worse than the free\* options I found online. *testing/results/TEST\_RESULTS\_V1.csv* contains some stats. It does have quite some limitations, as is doesn't recognise rests, tempo changes (like rubato), dynamics, articulations, upbeats and more. These limitations are bad, but not catastrophic. Oh and it actually generates MIDI files and uses MuseScore4 to generate the sheet music PDF's, but it does actually find key, tempo and time signature. \**Not really of course* **Please give feedback! :D**	0.0	t3_18wacbi	reddit		
57	Tuesday Daily Thread: Advanced questions	Unknown	2024-01-02 00:00:09	https://www.reddit.com/r/Python/comments/18watqc/tuesday_daily_thread_advanced_questions/	# Weekly Wednesday Thread: Advanced Questions üêç Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices. ## How it Works: 1. **Ask Away**: Post your advanced Python questions here. 2. **Expert Insights**: Get answers from experienced developers. 3. **Resource Pool**: Share or discover tutorials, articles, and tips. ## Guidelines: * This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday. * Questions that are not advanced may be removed and redirected to the appropriate thread. ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **How can you implement a custom memory allocator in Python?** 2. **What are the best practices for optimizing Cython code for heavy numerical computations?** 3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?** 4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?** 5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?** 6. **What are some advanced use-cases for Python's decorators?** 7. **How can you achieve real-time data streaming in Python with WebSockets?** 8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?** 9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?** 10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)** Let's deepen our Python knowledge together. Happy coding! üåü	0.0	t3_18watqc	reddit		
58	Yet another multidirectory/multirepository git runner.	Unknown	2024-01-01 19:43:45	https://www.reddit.com/r/Python/comments/18w4quj/yet_another_multidirectorymultirepository_git/	Hi, I made this thing for git: [https://github.com/jasursadikov/mud](https://github.com/jasursadikov/mud) This tool allows you to run git commands in multiple repositories simultaneously. I was using other tools like that but mine has some features that I was looking for: 1. Asyncronous commands running 2. Nerd fonts to have some pretty view 3. Status table that shows what is going on with all repos that I have 4. Aliases, so I can safe 0.03125ms by avoiding typing long commands 5. Filtering. This tool can filter repos by branch/tag/modified/diverged 6. Global config and local configs.	1.0	t3_18w4quj	reddit		
59	Get Surfline surf forecasts with python	Unknown	2024-01-01 18:32:14	https://medium.com/@giocaizzi/get-surfline-surf-forecasts-with-python-93fe92230c01	Empty	3.0	t3_18w31mr	reddit		
60	I made a video showcasing the projects in 2023 using Python and Pygame!	Unknown	2024-01-01 09:49:27	https://www.reddit.com/r/Python/comments/18vtkcs/i_made_a_video_showcasing_the_projects_in_2023/	You can watch it here - [https://youtu.be/o6ISmnLqVDQ](https://youtu.be/o6ISmnLqVDQ) Source code for most of the project is available on my [GitHub page](https://github.com/robomarchello) Happy New Year everyone! And this is one of the projects: [pressure soft body simulation](https://i.redd.it/872nmxhrts9c1.gif)	1.0	t3_18vtkcs	reddit		
61	Discover Your Personality Traits with Persai: A Python Package for detecting Big Five personality	Unknown	2024-01-02 17:46:06	https://www.reddit.com/r/Python/comments/18wvb6d/discover_your_personality_traits_with_persai_a/	Greetings everyone, I'm excited to introduce you to Persai, a Python package designed to provide deep insights into your personality. Using the Big Five personality traits model, Persai can analyze your Twitter posts and give you a unique perspective on your personality. All you have to do is input the tweets.js file you get when you export your Twitter data, and Persai will return your Big Five data. The technology behind Persai is GPT-4, and it's based on the findings from the paper ‚ÄúIs ChatGPT a Good Personality Recognizer? A Preliminary Study‚Äù. For more information about Persai, you can check out the GitHub repository here: https://github.com/yachty66/persai To delve deeper into what Persai can do, visit the website: https://www.persai.org/ Let's embark on this journey of self-discovery together! üß≠üíº	2.0	t3_18wvb6d	reddit		
62	URL-Shorter with Python	Unknown	2024-01-01 16:55:06	https://www.reddit.com/r/Python/comments/18w0tw8/urlshorter_with_python/	Hi everyoen, I want to introduce my latest project, URL-Shorter; You can deploy your own url-shorter service with that repository. [https://github.com/uysalserkan/url-shorter](https://github.com/uysalserkan/url-shorter)	0.0	t3_18w0tw8	reddit		
63	chrono24 - a simple API wrapper for watch enthusiasts üïí	Unknown	2024-01-01 04:57:33	https://www.reddit.com/r/Python/comments/18vpdsd/chrono24_a_simple_api_wrapper_for_watch/	"The [Chrono24](https://www.chrono24.com/) [API wrapper](https://github.com/irahorecka/chrono24/) is designed for watch enthusiasts in the Python community. This library offers in-depth access to Chrono24's watch listings. `pip install chrono24`, and explore brands and listings using simple Python commands: import chrono24 for listing in chrono24(query=""Rolex DateJust"").search(): print(listing) Dive into one of the biggest timepiece markets with [chrono24](https://github.com/irahorecka/chrono24) &#x200B; **Edit:** Given the constructive feedback from u/striata, the new API is as follows: import chrono24 for listing in chrono24.query(""Rolex DateJust"").search(): print(listing)"	1.0	t3_18vpdsd	reddit		
64	DocFlow - Document Management API	Unknown	2023-12-31 17:27:51	https://www.reddit.com/r/Python/comments/18vcjrw/docflow_document_management_api/	üöÄ Excited to announce the release of DocFlow - a Document Management API! I have been working on this project from quite some tie now. And learnt a lot. Writing this post, just to share how year ended for me. DocFlow is build using u/FastAPI, PostgreSQL, AWS S3, and Docker. It provides document's Upload, Download, Organization, Searching, Versioning, Sharing, Access Control List, Deletion, Archiving, Authentication and Authorization. The complete documentation of the API and ways to test and run DocFlow is mentioned on the GitHub Repository. üñáÔ∏è [Here](https://github.com/jiisanda/docflow) üì© I invite you to the repo, to do a code review, suggest changes and collaborate over the Discussions of [DocFlow](https://github.com/jiisanda/docflow/discussions). Happy Coding üôÜ‚Äç‚ôÇÔ∏è! **#DocFLow** **#DocumentManagement** **#API** **#release** **#github** **#fastapi** **#aws** **#docker** **#postgresql** **#awsservices** **#python** [DocFlow](https://preview.redd.it/nlqs5ypm0o9c1.png?width=500&format=png&auto=webp&s=bf8aa96aa81771c6208703844c4f9e004d7259e9)	3.0	t3_18vcjrw	reddit		
65	Xmas decoration, part 2	Unknown	2023-12-31 22:02:02	https://www.bitecode.dev/p/xmas-decoration-part-2	Empty	0.0	t3_18vi8wx	reddit		
66	Monday Daily Thread: Project ideas!	Unknown	2024-01-01 00:00:08	https://www.reddit.com/r/Python/comments/18vkgtu/monday_daily_thread_project_ideas/	"# Weekly Thread: Project Ideas üí° Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you. ## How it Works: 1. **Suggest a Project**: Comment your project idea‚Äîbe it beginner-friendly or advanced. 2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code. 3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration. ## Guidelines: * Clearly state the difficulty level. * Provide a brief description and, if possible, outline the tech stack. * Feel free to link to tutorials or resources that might help. # Example Submissions: ## Project Idea: Chatbot **Difficulty**: Intermediate **Tech Stack**: Python, NLP, Flask/FastAPI/Litestar **Description**: Create a chatbot that can answer FAQs for a website. **Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM) # Project Idea: Weather Dashboard **Difficulty**: Beginner **Tech Stack**: HTML, CSS, JavaScript, API **Description**: Build a dashboard that displays real-time weather information using a weather API. **Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8) ## Project Idea: File Organizer **Difficulty**: Beginner **Tech Stack**: Python, File I/O **Description**: Create a script that organizes files in a directory into sub-folders based on file type. **Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/) Let's help each other grow. Happy coding! üåü"	2.0	t3_18vkgtu	reddit		
67	Stockstir is a tool written in Python that lets you get stock information from any script at no cost - Version 2 is officially out!	Unknown	2023-12-31 00:53:09	https://www.reddit.com/r/Python/comments/18uuyjr/stockstir_is_a_tool_written_in_python_that_lets/	"Hello again! A few days ago I showcased my Stockstir project which I had made a while ago. You can refer to that thread [here](https://www.reddit.com/r/Python/comments/18sxqsc/stockstir_is_a_python_project_that_lets_you_get/). V2 is out! You can take a look at the [documentation](https://stockstir.readthedocs.io/en/latest/index.html) for up-to-date information on the new functions, enhancements, and fixes in the project. Also, the project link is here: [Stockstir Link](https://github.com/PatzEdi/Stockstir) As far as additions and suggestions which were made on the previous thread, Stockstir V2 now has a complete fail-safe system that uses more than one provider. It also has initial integration of an Alpha Vantage API (to be further developed still, now it is just an initial integration), and new options to gather prices and other stock info through CNBC and their JSON format API (Thank you to [Gr1pp717](https://www.reddit.com/user/Gr1pp717/) for that information!). As far as the quick usage, nothing has changed: ``` import Stockstir price = Stockstir.getSinglePrice(""ticker/stockSymbol"") print(price) ``` With the new provider system, the default provider is still CNBC. However, you can set a provider manually (There are three as of now) like so: ``` from Stockstir import Providers Providers.provider_number = 1 # Here, you can put any number that is between 0 and 2, as there are three providers now. The default remains 0. ``` The new fail-safe system automatically picks other providers in case one fails, bringing more reliability to the library as a whole. If you want to manually check if providers are working, you can do this: ``` from Stockstir import Providers Providers.runProviderChecks() ``` Hope you enjoy! Edit: Some suggestions/improvements have already been suggested in one of the comments below, thank you so much for that information, super useful! Here is the [link of the improvements that will come soon to Stockstir V2](https://www.reddit.com/r/Python/comments/18uuyjr/comment/kfnju1d/?utm_source=share&utm_medium=web2x&context=3)"	5.0	t3_18uuyjr	reddit		
68	I Created a game (kind of)	Unknown	2023-12-31 16:07:45	https://www.reddit.com/r/Python/comments/18vattd/i_created_a_game_kind_of/	I created a practice app to practice wordle (more specifically Duotrigordle), and I was wondering if anyone would be interested in playing it/testing it. Here's the github: [https://github.com/dcjvliet/Duotrigordle](https://github.com/dcjvliet/Duotrigordle) The code's pretty messy, but it's all open source and I figured I might as well share it. If you do decide to play it, feel free to leave feedback here.	0.0	t3_18vattd	reddit		
69	Transfer YouTube History from One Channel to Another Channel Using Python	Unknown	2023-12-30 20:54:06	https://www.reddit.com/r/Python/comments/18upgvh/transfer_youtube_history_from_one_channel_to/	*Transfer YouTube History from One Account to Another Account Using Python.* **Information:** There is no direct way to transport YouTube history from one account to another; you have to use Python to do it. It will take some time. - I've created a Python script that automates the transfer for you; it will take 10 seconds for each link. **Advice:** Be aware that you will need to monitor the transport because YouTube will detect unusual traffic, and it will sign out all your logged-in accounts. Therefore, I ADVISE YOU TO SAVE YOUR PASSWORD if you don't know it. **Preparation:** 1. Visual Studio Code 2. Google Chrome browser 3. MS Excel **Exporting youtube history:** 1. Go to [https://takeout.google.com](https://takeout.google.com/) 2. Choose the account (or brand account if you have more than one YouTube channel). 3. Click Deselect all. Check only: YouTube and YouTube Music section (Scroll to the end). 4. Click multiple formats: Scroll to history and change HTML to JSON, hit Ok. 5. Click All YouTube data included: Deselect all and choose only history. 6. Click next step. 7. Create export. 8. It will be sent to your email. 9. Create an empty folder called YoutubeHistory. This folder is for running every Python script that I will provide. 10. Drag and drop the watch-history.json file into the YoutubeHistory folder. **Convert JSON file to txt file using python:** 1. Create python script named: , save it in the YoutubeHistory folder. 2. Load this script and click save: &#8203; import json # Load the JSON data from the file with specified encoding with open('watch-history.json', 'r', encoding='utf-8') as file: data = json.load(file) urls = [] # Extract the URLs from the JSON data for item in data: if 'titleUrl' in item: urls.append(item['titleUrl']) if 'subtitles' in item: for subtitle in item['subtitles']: if 'url' in subtitle: urls.append(subtitle['url']) # Save the URLs to a text file with open('urls.txt', 'w') as file: for url in urls: file.write(url + '\n') Now click Ctrl+F5 to run the script. - You will get urls.txt file in the YoutubeHistory folder. **MS Excel (Organizing the history from old to new and removing duplicates):** First: You will need to remove the duplicates: 1. Copy the links from urls.txt and paste in a new excel work book. 2. CTRL+A to select all. - Click data: Remove duplicates and hit ok. Second: You will need to order the links (Old to New): 1. On column B: Number the links starting from 1. 2. CTRL+A to select all. 3. Click data: Sort. 4. Choose Sort by column B & Order by largest to smallest. Third: 1. Now create txt file and name it Flipped.txt in the YoutubeHistory folder. 2. Copy the links from the excel file and paste them in Flipped.txt **Transferring the history:** 1. Make sure you have selected the correct YouTube channel that you want to transfer to. 2. Open an empty tab in Chrome tab and keep it open. 3. Create python script named: automate\_youtube\_history.py , save it in the YoutubeHistory folder. 4. Load this script and click save: &#8203; import webbrowser import time import pyautogui # Read the URLs from a text file with open('Flipped.txt', 'r') as file: urls = file.readlines() urls = [url.strip() for url in urls] # Open each URL in a web browser for url in urls: webbrowser.open(url) time.sleep(10) # Close the current tab (you might need to adjust the coordinates) pyautogui.hotkey('ctrl', 'w') # This shortcut closes the current tab Now click Ctrl+F5 to run the script. **The process:** I recommend that you monitor the process every hour or 30 minutes because after some time, you may get logged out from all your accounts (this happened to me after 2 hours). If this occurs: 1. Stop the Python script from running. 2. Go to your watch history, and check the last video it stopped on. 3. Remove the links that were transferred successfully and keep the others. 4. Re-run the script.	11.0	t3_18upgvh	reddit		
70	I shared a Python Course (1.5 hours) on YouTube	 	2023-12-31 06:09:27	https://www.youtube.com/watch?v=VOdPQmm298o&list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&index=1	Empty	3.0	t3_18v157k	reddit		
71	BALanced Execution through Natural Activation : a human-computer interaction methodology for code running	Unknown	2023-12-31 10:20:47	https://www.reddit.com/r/Python/comments/18v4yqg/balanced_execution_through_natural_activation_a/	BALENA is a voice interaction framework utilizing state-of-the-art natural language processing and audio processing models to create a system that can interpret voice commands and associate them with predefined actions. The framework leverages the power of transformers and signal processing to understand user intent via spoken language and correlates them with a series of predefined actionable responses. [Framework workflow](https://preview.redd.it/juxyviw4wl9c1.png?width=6130&format=png&auto=webp&s=ce2a4cd2ba32dc062a704a1544a48233319ef432) ## Features * **Real-time audio streaming and recording**: Record audio from the microphone in real time for processing. * **Speech recognition with Wav2Vec 2.0**: Use a pre-trained Wav2Vec 2.0 model to convert speech to text. * **Text similarity and action triggering**: Encode the transcribed text to a vector space and find the closest action using sentence similarity techniques. * **High-pass filtering**: Process the audio signal with a high-pass filter to enhance signal quality. * **Auto-correction**: Utilize the Jaccard distance to correct words in the transcribed text auto-magically. * **Framework flexibility**: Support for different device execution contexts, allowing for usage on both CPU and CUDA devices. Link to the repo : [https://github.com/louisbrulenaudet/balena](https://github.com/louisbrulenaudet/balena)	0.0	t3_18v4yqg	reddit		
72	RecoverPy 2.1.5: Python file recovery tool	Unknown	2023-12-30 17:25:15	https://www.reddit.com/r/Python/comments/18uknqm/recoverpy_215_python_file_recovery_tool/	&#x200B; https://i.redd.it/t1foxzpbvg9c1.gif **Github**: [https://github.com/PabloLec/RecoverPy](https://github.com/PabloLec/RecoverPy) Hey everyone! I'm here to share something I've been working on for nearly three years now, RecoverPy, and its new 2.1.5 version. It's a nifty tool that can really be a lifesaver when you've accidentally deleted or overwritten files. It works its magic by conducting a text-based search to find the lost data. It sports a TUI built with Textual. I found it to be quite enjoyable to use and it seems many others agree, given its rise as one of the most (or the most?) popular TUI libraries in Python, despite still being in beta. Since its creation, RecoverPy has gone through quite a transformation. It's integrated lots of feedback from its user community, improved many aspects to enhance the user experience, and even underwent almost a full rewrite to switch up the TUI library in its second version. Essentially, it uses the strength of grep and dd to sift through partition blocks, giving you a user-friendly way to sift through the results. Interestingly, it found a niche not only among individuals looking to recover files but has also piqued interest in the hacking scene, which was a bit of a pleasant surprise for me. It seems the tool lends itself well to that sphere too. I manage to chip away at it from time to time, given that my free moments are becoming a bit of a rarity these days. It still has room to grow, and if anyone here feels like contributing, I'm more than open to collaborations. Your PRs would certainly be welcome! Feel free to give it a glance, and if you find it interesting or useful, a star on the repository would be greatly appreciated.	2.0	t3_18uknqm	reddit		
73	A small collection of lesser-known statistical functions - obscure_stats	Unknown	2023-12-30 09:17:56	https://www.reddit.com/r/Python/comments/18ubr4s/a_small_collection_of_lesserknown_statistical/	Hello r/Python I‚Äôm excited to share with you my new python package called `obscure_stats`. It is a collection of lesser-known statistical functions that are not available in the standard libraries like `scipy`, `statsmodels`, or `numpy`. The package is still in development, but I hope you will find it useful and interesting. You can install it with `pip install obscure_stats` or check out the source code on [GitHub](https://github.com/glevv/obscure_stats). I would appreciate any feedback, suggestions, or bug reports.	4.0	t3_18ubr4s	reddit		
74	Paracelsus: Visualize SQLAlchemy Databases using Mermaid or Dot Diagrams.	Unknown	2023-12-30 14:43:34	https://github.com/tedivm/paracelsus	Empty	0.0	t3_18uh43x	reddit		
75	My first public package: wigner-symbols	Unknown	2023-12-31 02:39:08	https://www.reddit.com/r/Python/comments/18ux6et/my_first_public_package_wignersymbols/	Hi everyone! I would like to share my first public repository with you all: [wigner-symbols](https://github.com/sheodun/wigner-symbols). This package just calculates Wigner [3j](https://en.wikipedia.org/wiki/3-j_symbol) and [6j](https://en.wikipedia.org/wiki/6-j_symbol) symbols, which are commonly used in quantum mechanics for calculating coefficients of angular momentum coupling. I come from a research background and often relied on a [very good site](https://www-stone.ch.cam.ac.uk/wigner.shtml) to check these symbol values, but I would rather use a python package; so I decided to make my own. It is a small repo and there isn't much here at the moment but it performs the job. I would really appreciate your feedback. Thank you! Edit: I have not been able to publish the package on PyPi yet as registration is temporarily suspended but I plan to once we are able to again	1.0	t3_18ux6et	reddit		
76	The Python Mega Course is still free on Udemy	Unknown	2023-12-29 13:34:26	https://www.reddit.com/r/Python/comments/18tn8y0/the_python_mega_course_is_still_free_on_udemy/	"As some of you may know, ""**The Python Mega Course: Build 10 Real World Applications**"" is one of the top Python courses on Udemy. Last year, I made that version of the course available for free to the Reddit community, and I am doing the same today. In 2023, the course attracted 20,000+ students and collected 900+ reviews, achieving an exceptionally high average rating of 4.8/5 on Udemy. This makes the course exceptionally highly rated on Udemy. **How can you get the course for free today?** Three simple steps: 1. Login to Udemy. 2. Go to the course page: [https://udemy.com/course/former-python-mega-course-build-10-real-world-applications/](https://udemy.com/course/former-python-mega-course-build-10-real-world-applications/) 3. Enter the password **mega\_course** to get the course for free. Thanks and have a relaxing end of the year!"	107.0	t3_18tn8y0	reddit		
77	ChatGPT API Basics for Developers (in Python)	Unknown	2023-12-31 09:04:20	https://www.tomaspanik.eu/en/posts/chatgpt-api/	Empty	0.0	t3_18v3v7n	reddit		
78	Grep over IPython output!	Unknown	2023-12-30 13:17:40	https://www.reddit.com/r/Python/comments/18ufgl3/grep_over_ipython_output/	Hi there! i just finish a little project allowing you to use `grep` over IPython output like so: ```ipython In [1]: {i:i for i in range(3)} Out[1]: {0: 0, 1: 1, 2: 2, } In [2]: %greps 1 Out[2]: ' 1: 1,\n' ``` [https://github.com/royreznik/greps](https://github.com/royreznik/greps)	1.0	t3_18ufgl3	reddit		
79	CPython Type System Internals: Video Series	Unknown	2023-12-30 14:51:58	https://codeconfessions.substack.com/p/cpython-type-system-internals-video	Empty	0.0	t3_18uhack	reddit		
80	A Free AI Scribe Project I am Working on! Please Provide Feedback!	Unknown	2023-12-30 16:26:16	https://www.reddit.com/r/Python/comments/18ujbet/a_free_ai_scribe_project_i_am_working_on_please/	Thought I would share a project that I have been working on. AI medical scribe products have popped up everywhere but have been very expensive to deploy. I wrote a program that can connect with a local server running a version of ChatGPT and Speech-To-Text that can take a conversation via microphone and create a SOAP note. You can turn off the AI scribe and use it in a normal chat-based manner. The LLM variables are locked in on the executable option since I wrote this for an end-user physician. Looking for any feedback (I am very much an amateur) from the community! What proved to be a bit tricky was developing a client that could use the device's microphone. [https://github.com/1984Doc/AI-Scribe](https://github.com/1984Doc/AI-Scribe)	0.0	t3_18ujbet	reddit		
81	Less is More? An Empirical Study on Configuration Issues in Python PyPI Ecosystem	Unknown	2023-12-30 09:19:48	https://www.reddit.com/r/Python/comments/18ubs0y/less_is_more_an_empirical_study_on_configuration/	The utilization of third-party libraries can potentially lead to conflicts in dependencies, prompting researchers to develop dependency conflict detectors. Specifically, the researchers propose PyCon, a source-level detector, for detecting potential configuration issues. [https://arxiv.org/abs/2310.12598](https://arxiv.org/abs/2310.12598) &#x200B;	2.0	t3_18ubs0y	reddit		
82	UdemyPy - The Free Udemy courses bot	Unknown	2023-12-30 15:33:16	https://www.reddit.com/r/Python/comments/18ui5nc/udemypy_the_free_udemy_courses_bot/	UdemyPy is an open-source Python project with the mission of making education accessible to everybody. It brings free Udemy courses directly to you on [WhatsApp](https://www.whatsapp.com/channel/0029VaHwvWZ7NoZsk8UOUl0z) and [Telegram](https://t.me/freecourses000). # How it Works UdemyPy scours the web for Udemy courses offering a 100% discount, ensuring you have access to a diverse range of subjects in any language. When looking for free courses shared by UdemyPy, remember to check the offer time left. Once it‚Äôs expired, the course will no longer be free. Whenever you find a course you like, click on the link and enroll in it. Despite the fact that courses are free only for a limited amount of time, once you are enrolled *they will be yours forever!* # Why UdemyPy? * Free of Charge: No payment methods needed; just create a Udemy account. * Unrestricted Learning: Explore courses in any category or language. * Supportive: UdemyPy supports content creators in reaching a wider audience. # Learn More Explore the project on [GitHub](https://github.com/dylannalex/udemypy). Feel free to show your support with a üåü if you find the project intriguing!	0.0	t3_18ui5nc	reddit		
83	Coding year in review 2023!	Unknown	2023-12-30 14:56:19	https://www.reddit.com/r/Python/comments/18uhdfv/coding_year_in_review_2023/	Love to hear your thoughts on last year with coding and coming year. Here's to our first script of 2024! https://www.youtube.com/watch?v=YcmKs2M1xAo	1.0	t3_18uhdfv	reddit		
84	Curser, and other AI code editors	Unknown	2023-12-30 13:24:15	https://www.reddit.com/r/Python/comments/18ufktx/curser_and_other_ai_code_editors/	Do you use these types of tool editors to help write code more effectively/efficiently? What are you using?	3.0	t3_18ufktx	reddit		
85	How to prevent python software from being reverse engineered or pirated?	Unknown	2023-12-29 03:56:54	https://www.reddit.com/r/Python/comments/18tdmiv/how_to_prevent_python_software_from_being_reverse/	I have a program on the internet that users pay to download and use. I'm thinking about adding a free trial, but I'm very concerned that users can simply download the trial and bypass the restrictions. The program is fully offline and somewhat simple. It's not like you need an entire team to crack it. In fact, there is literally a pyinstaller unpacker out there that can revert the EXE straight back to its python source code. I use pyinstaller. Anything I can do? One thing to look out for is unpackers, and the other thing is how to make it difficult for Ghidra for example to reverse the program. Edit: to clarify, I can't just offer this as an online service/program because it requires interaction with the user's system.	89.0	t3_18tdmiv	reddit		
86	CRAP - Clear Redundant Added Packages	Unknown	2023-12-29 16:20:45	https://www.reddit.com/r/Python/comments/18tqu9m/crap_clear_redundant_added_packages/	[https://github.com/ValdonVitija/crap](https://github.com/ValdonVitija/crap) Automatically clear redundant packages from virtual environments in python üêçüì¶üóëÔ∏è.	7.0	t3_18tqu9m	reddit		
87	Jake: A Free Alternative to Linktree Using GitHub Pages	Unknown	2023-12-29 10:47:28	https://www.reddit.com/r/Python/comments/18tkf7e/jake_a_free_alternative_to_linktree_using_github/	"Hello, I wanted to share a new Python project I've been working on called Jake. It's an alternative to popular link aggregator services like Linktree and OneLink. Jake leverages the power of GitHub Pages to provide you with a hassle-free way to create your one-link website. The best part? It won't cost you a dime! With Jake, you can easily showcase all your important links and content in one central hub, neatly organized and easily accessible. Your website will have a sleek URL in the format of ""username.github.io,"" giving it a professional touch. Jake is completely written in Python and uses the \`tinyhtml\` library to generate static HTML websites. Simply fill in the \`data.toml\` file with your information, and Jake will automatically build and deploy your website to GitHub Pages using a GitHub action. To give you a taste of what Jake can do, I've prepared a demo project for you to explore. Just visit [https://thevahidal.github.io/jake](https://thevahidal.github.io/jake) and see the potential for yourself. If you're interested in contributing or want to dive deeper into the project, you can find the Jake repository on GitHub at [https://github.com/thevahidal/jake](https://github.com/thevahidal/jake). I welcome all contributions, feedback, and bug reports. Your input will help shape the future of Jake and make it even better. Thank you for taking the time to read about Jake. I can't wait to see what we can achieve together. Best regards, Al"	9.0	t3_18tkf7e	reddit		
88	Tastymap, create/customize matplotlib color palettes for your palate	Unknown	2023-12-29 19:51:02	https://www.reddit.com/r/Python/comments/18tvpdz/tastymap_createcustomize_matplotlib_color/	"The number of colormaps matplotlib felt limiting to me so I created a web app and Python package to customize existing colormaps or start from scratch! from tastymap import cook_tmap tmap = cook_tmap( [""red"", ""green"", ""blue""], num_colors=256, reverse=True ) Install by: \`pip install tastymap\` or try it online here: [TastyKitchen - a Hugging Face Space by ahuang11](https://huggingface.co/spaces/ahuang11/tastykitchen) [TastyKitchen](https://i.redd.it/hf6fm1ukga9c1.gif) Docs here: [TastyMap (ahuang11.github.io)](https://ahuang11.github.io/tastymap/) Code here: [ahuang11/tastymap: colormaps cooked for your palate (github.com)](https://github.com/ahuang11/tastymap) There's also a way to have AI suggest a colormap based on a description: from tastymap import ai tmap = ai.suggest_tmap(""Pikachu"") tmap [Pikachu](https://preview.redd.it/3clppe0pga9c1.png?width=512&format=png&auto=webp&s=82b5570b05cd3b1f07683a7b837860d4442ce9ff)"	0.0	t3_18tvpdz	reddit		
89	Understanding Numeric Data Types in Python	Unknown	2023-12-29 19:18:05	https://fullspeedpython.com/articles/understanding-numeric-data-types/	Empty	0.0	t3_18tuy3y	reddit		
90	UniDep: Unified Conda and Pip dependency management via pyproject.toml	Unknown	2023-12-29 20:50:55	https://www.reddit.com/r/Python/comments/18tx3pm/unidep_unified_conda_and_pip_dependency/	"[UniDep](https://github.com/basnijholt/unidep) streamlines Python project dependency management by unifying Conda and Pip packages in a single system. Handling dependencies in Python projects can be challenging, especially when juggling Python and non-Python packages.This often leads to confusion and inefficiency, as developers juggle between multiple dependency files. - **üìù Unified Dependency File**: Use either `requirements.yaml` or `pyproject.toml` to manage both Conda and Pip dependencies in one place. - **‚öôÔ∏è Build System Integration**: Integrates with Setuptools and Hatchling for automatic dependency handling during `pip install ./your-package`. - **üíª One-Command Installation**: `unidep install` handles Conda, Pip, and local dependencies effortlessly. - **üè¢ Monorepo-Friendly**: Render (multiple) `requirements.yaml` or `pyproject.toml` files into one Conda `environment.yaml` file and maintain fully consistent global *and* per sub package `conda-lock` files. - **üåç Platform-Specific Support**: Specify dependencies for different operating systems or architectures. - **üîß `pip-compile` Integration**: Generate fully pinned `requirements.txt` files from `requirements.yaml` or `pyproject.toml` files using `pip-compile`. - **üîí Integration with `conda-lock`**: Generate fully pinned `conda-lock.yml` files from (multiple) `requirements.yaml` or `pyproject.toml` file(s), leveraging `conda-lock`. ### Example #### Example `requirements.yaml` Example of a `requirements.yaml` file: ```yaml name: example_environment channels: - conda-forge dependencies: - numpy # same name on conda and pip - conda: python-graphviz # When names differ between Conda and Pip pip: graphviz - pip: slurm-usage >=1.1.0,<2 # pip-only - conda: mumps # conda-only # Use platform selectors - conda: cuda-toolkit =11.8 # [linux64] local_dependencies: - ../other-project-using-unidep # include other projects that use unidep - ../common-requirements.yaml # include other requirements.yaml files - ../project-not-managed-by-unidep # üö® Skips its dependencies! platforms: # (Optional) specify platforms that are supported (used in conda-lock) - linux-64 - osx-arm64 ``` > `unidep` can process this during `pip install` and create a Conda installable `environment.yaml` or `conda-lock.yml` file, and more! > For a more in-depth example containing multiple installable projects, see the [`example`](https://github.com/basnijholt/unidep/tree/main/example) directory. #### Example `pyproject.toml` ***Alternatively***, one can fully configure the dependencies in the `pyproject.toml` file in the `[tool.unidep]` section: ```toml [tool.unidep] channels = [""conda-forge""] dependencies = [ ""numpy"", # same name on conda and pip { conda = ""python-graphviz"", pip = ""graphviz"" }, # When names differ between Conda and Pip { pip = ""slurm-usage >=1.1.0,<2"" }, # pip-only { conda = ""mumps"" }, # conda-only { conda = ""cuda-toolkit =11.8:linux64"" } # Use platform selectors by appending `:linux64` ] local_dependencies = [ ""../other-project-using-unidep"", # include other projects that use unidep ""../common-requirements.yaml"" # include other requirements.yaml files ""../project-not-managed-by-unidep"" # üö® Skips its dependencies! ] platforms = [ # (Optional) specify platforms that are supported (used in conda-lock) ""linux-64"", ""osx-arm64"" ] ``` This data structure is *identical* to the `requirements.yaml` format, with the exception of the `name` field and the [platform selectors](#platform-selectors). In the `requirements.yaml` file, one can use e.g., `# [linux64]`, which in the `pyproject.toml` file is `:linux64` at the end of the package name. Check out https://github.com/basnijholt/unidep"	1.0	t3_18tx3pm	reddit		
91	Voicebox: Python TTS lib with built-in audio effects	Unknown	2023-12-29 19:27:39	https://www.reddit.com/r/Python/comments/18tv650/voicebox_python_tts_lib_with_builtin_audio_effects/	"Hello there, I'm sharing a project I've been working on for some future robotics projects, and would appreciate some feedback. It's called [Voicebox](https://voicebox.readthedocs.io) ([GitHub](https://github.com/austin-bowen/voicebox)), and it's a Python library that essentially provides wrappers for a bunch of different text-to-speech programs/APIs, and includes lots of built-in audio effects like vocoder, ring mod, glitch, etc. It also includes [example voices](https://voicebox.readthedocs.io/en/stable/voicebox.examples.html) like Star Wars battle droid, GlaDOS, and 343 Guilty Spark. Audio samples [here](https://voicebox.readthedocs.io/en/stable/samples.html). The ""problem"" I was trying to solve was that a lot of TTS programs sound *too* realistic now, and I want an easy way to make audio from TTS sound more fun/robotic. There are also utilities like [`reliable_tts`](https://voicebox.readthedocs.io/en/stable/voicebox.html#voicebox.utils.reliable_tts) and [`ParallelVoicebox`](https://voicebox.readthedocs.io/en/stable/voicebox.voiceboxes.html#voicebox.voiceboxes.parallel.ParallelVoicebox) that make it easy to build responsive and robust TTS systems, which is important for robot projects. LMK what you think! &#x200B; Example: Use gTTS with a vocoder effect to speak in a robotic voice from voicebox import SimpleVoicebox from voicebox.tts import gTTS from voicebox.effects import Vocoder, Normalize voicebox = SimpleVoicebox( tts=gTTS(), effects=[Vocoder.build(), Normalize()], ) voicebox.say('Hello, world! How are you today?')"	0.0	t3_18tv650	reddit		
92	A Python monorepo template	Unknown	2023-12-29 16:55:20	https://www.reddit.com/r/Python/comments/18trmnq/a_python_monorepo_template/	Hey all! üëã Just wanted to share a Python monorepo template I've been working on. It's designed to streamline managing multiple packages in one place. I've incorporated tools like Poetry, Black, mypy, and Ruff for setup and linting, plus my personal touch with [Breadcrumbs](https://github.com/niqodea/breadcrumbs) for cleaner path management. Happy to hear your feedback or ideas! Check it out here: https://github.com/niqodea/python-monorepo	1.0	t3_18trmnq	reddit		
93	A Python implementation of Conway's Game of Life (Cellular Automaton)	Unknown	2023-12-29 15:56:03	https://www.reddit.com/r/Python/comments/18tq9ns/a_python_implementation_of_conways_game_of_life/	I am a student of both mathematics and computer science, so I coded up a terminal-based implementation of John Conway's Game of Life. Check it out here: [https://github.com/atiumcache/game\_of\_life](https://github.com/atiumcache/game_of_life) It is packaged as an executable for UNIX, so you can quickly get it playing. Or, just view the demo on the README.	1.0	t3_18tq9ns	reddit		
94	Saturday Daily Thread: Resource Request and Sharing! Daily Thread	Unknown	2023-12-30 00:00:19	https://www.reddit.com/r/Python/comments/18u1fep/saturday_daily_thread_resource_request_and/	"# Weekly Thread: Resource Request and Sharing üìö Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread! ## How it Works: 1. **Request**: Can't find a resource on a particular topic? Ask here! 2. **Share**: Found something useful? Share it with the community. 3. **Review**: Give or get opinions on Python resources you've used. ## Guidelines: * Please include the type of resource (e.g., book, video, article) and the topic. * Always be respectful when reviewing someone else's shared resource. ## Example Shares: 1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms. 2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures. 3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators. ## Example Requests: 1. **Looking for**: Video tutorials on web scraping with Python. 2. **Need**: Book recommendations for Python machine learning. Share the knowledge, enrich the community. Happy learning! üåü"	1.0	t3_18u1fep	reddit		
95	Pure Recipe is a CLI app to save or view online recipes in well-formatted markdown. No more ads!	Unknown	2023-12-28 22:51:15	https://www.reddit.com/r/Python/comments/18t726b/pure_recipe_is_a_cli_app_to_save_or_view_online/	I am a long-time cook and aspiring developer, so I made a command-line recipe viewer to bypass the ads and blogs that plague recipe websites. It can also save the recipes to markdown. You can even pass in a whole list of URLs to save a bunch of recipes at once. Similar to Paprika, except it is free/open-source and you can easily save and share the recipes in markdown format. Check it out on GitHub, I would appreciate any feedback/testers: [https://github.com/atiumcache/pure-recipe](https://github.com/atiumcache/pure-recipe)	9.0	t3_18t726b	reddit		
96	attrs iv: Zero-overhead Frozen attrs Classes	Unknown	2023-12-29 11:49:19	https://threeofwands.com/attra-iv-zero-overhead-frozen-attrs-classes/	Empty	0.0	t3_18tleqp	reddit		
97	Oreiller: An image library for easy Pillow manipulations.	 Python&OpenSource	2023-12-29 08:44:43	https://www.reddit.com/r/Python/comments/18til8l/oreiller_an_image_library_for_easy_pillow/	Really, [oreiller](https://www.google.com/search?q=oreiller) is the french word for a pillow. I always heard about the PIL fork, Pillow but never used it. When I finally used it, I found it to be tedious sometimes. Like including emojis in text and the general programming. I finally got around to create a small library WIP called oreiller \[[pypi](https://pypi.org/project/oreiller/) | [github](https://github.com/Abdur-RahmaanJ/oreiller)\]. &#x200B; Code demo &#x200B; https://preview.redd.it/r8ixcd8f579c1.png?width=682&format=png&auto=webp&s=3f137f150c3c1482bd38f5d1d8005fd56057e368	1.0	t3_18til8l	reddit		
98	I created a program to align thousands of selfies for daily picture videos!	Unknown	2023-12-29 02:08:34	https://www.reddit.com/r/Python/comments/18tbeet/i_created_a_program_to_align_thousands_of_selfies/	I started taking pictures 'everyday' in 2019 after seeing [Hugo's famous video](https://www.youtube.com/watch?v=65nfbW-27ps), but after aligning \~40 pictures I knew the process had to be automated. Since I barely knew python at the time, and I still find myself learning more and more everyday, it's taken a lot of on and off work, but now I have a script that can do what would've taken years of consistent effort in a few minutes. Even though another solution *kinda* exists, I'm super proud of it because it's mine (I say kinda because I couldn't get it to work for me). Here's the github repo with a lot of details on how it works: [https://github.com/Noah6544/Daily-Picture-Aligner](https://github.com/Noah6544/Daily-Picture-Aligner) Here's my video explanation: [https://www.youtube.com/watch?v=\_ow6GLv7VSA&](https://www.youtube.com/watch?v=_ow6GLv7VSA&) Please let me know ***any*** feedback you have!	1.0	t3_18tbeet	reddit		
99	A Better Way to Wrangle Figures Out of Jupyter Notebooks	Unknown	2023-12-29 07:24:08	https://www.reddit.com/r/Python/comments/18thcub/a_better_way_to_wrangle_figures_out_of_jupyter/	"*Stop wasting time saving plots manually ‚Äî automate it with an extra line of code!* Hopping in to share a bit of Python that's been in my everyday workflow for the last 2 years. Finally decided it would be worth the lift to put out there for others to use, too. I always get bogged down naming things --- and **saving visualizations out of notebooks after finishing up analysis work** is a particular sore spot. So, I wrote a one-off tool to use plotting arguments to automatically name plot outputs. It ended up getting reused over and over, and then eventually became *teeplot.* *teeplot* wraps plotting calls with logic that **automatically manages matplotlib file output**, picking **meaningful file names** based on the plotting function and semantic plotting variables. # Example This example shows a call to *seaborn*'s **lmplot** dispatched through **teeplot.tee** to save out the visualization as '*teeplots/col=time+hue=sex+viz=lmplot+x=total-bill+y=tip+ext={.pdf,.png}'.* Here's what a *teeplot*'ed notebook cell and output look like, # adapted from seaborn.pydata.org/generated/seaborn.FacetGrid.html import seaborn as sns from teeplot import teeplot as tp tp.tee(sns.lmplot, # plotter, then forwarded args/kwargs sns.load_dataset(""tips""), col=""time"", hue=""sex"", x=""total_bill"", y=""tip"") https://preview.redd.it/sj6f6u69q69c1.png?width=5880&format=png&auto=webp&s=4c684e13bd05336f710545298fb3ff436ffa02f1 >teeplots/col=time+hue=sex+viz=lmplot+x=total-bill+y=tip+ext=.pdfteeplots/col=time+hue=sex+viz=lmplot+x=total-bill+y=tip+ext=.png The idea here is to make the process of saving and cataloging plots more *efficient, systematic, and meaningful*, taking the hassle out of manual file management. # Further Information *teeplot* can be installed as python3 -m pip install teeplot The library has additional advanced features, as well, including an interface to globally configure visualization output file types (i.e., "".pdf"", "".png""), etc. You can read more in the project's [*usage guide*](https://github.com/mmore500/teeplot/blob/master/README.rst#usage) and [*API listing*](https://github.com/mmore500/teeplot/blob/master/README.rst#api). *disclaimer*: am library author"	0.0	t3_18thcub	reddit		
100	Egg-smol Python: A Pythonic Library for E-graphs	Saul Shanabrook	2023-05-07 15:35:17	http://arxiv.org/abs/2305.04311v1	E-graphs have emerged as a versatile data structure with applications in synthesis, optimization, and verification through techniques such as equality saturation. This paper introduces Python bindings for the experimental egg-smol library, which aims to bring the benefits of e-graphs to the Python ecosystem. The bindings offer a high-level, Pythonic API providing an accessible and familiar interface for Python users. By integrating e-graph techniques with Python, we hope to enable collaboration and innovation across various domains in the scientific computing and machine learning communities. We discuss the advantages of using Python bindings for both Python and existing egg-smol users, as well as possible future directions for development.			arxiv	[]	0.0
101	Making Python Code Idiomatic by Automatic Refactoring Non-Idiomatic Python Code with Pythonic Idioms	Zejun Zhang	2022-07-12 15:30:46	http://arxiv.org/abs/2207.05613v1	Compared to other programming languages (e.g., Java), Python has more idioms to make Python code concise and efficient. Although pythonic idioms are well accepted in the Python community, Python programmers are often faced with many challenges in using them, for example, being unaware of certain pythonic idioms or do not know how to use them properly. Based on an analysis of 7,638 Python repositories on GitHub, we find that non-idiomatic Python code that can be implemented with pythonic idioms occurs frequently and widely. Unfortunately, there is no tool for automatically refactoring such non-idiomatic code into idiomatic code. In this paper, we design and implement an automatic refactoring tool to make Python code idiomatic. We identify nine pythonic idioms by systematically contrasting the abstract syntax grammar of Python and Java. Then we define the syntactic patterns for detecting non-idiomatic code for each pythonic idiom. Finally, we devise atomic AST-rewriting operations and refactoring steps to refactor non-idiomatic code into idiomatic code. We test and review over 4,115 refactorings applied to 1,065 Python projects from GitHub, and submit 90 pull requests for the 90 randomly sampled refactorings to 84 projects. These evaluations confirm the high-accuracy, practicality and usefulness of our refactoring tool on real-world Python code. Our refactoring tool can be accessed at 47.242.131.128:5000.			arxiv	['Zhenchang Xing', 'Xin Xia', 'Xiwei Xu', 'Liming Zhu']	1.0
102	Modern Python at the Large Synoptic Survey Telescope	Tim Jenness	2017-12-01 19:04:46	http://arxiv.org/abs/1712.00461v1	The LSST software systems make extensive use of Python, with almost all of it initially being developed solely in Python 2. Since LSST will be commissioned when Python 2 is end-of-lifed it is critical that we have all our code support Python 3 before commissioning begins. Over the past year we have made significant progress in migrating the bulk of the code from the Data Management system onto Python 3. This paper presents our migration methodology, and the current status of the port, with our eventual aim to be running completely on Python 3 by early 2018. We also discuss recent modernizations to our Python codebase.			arxiv	[]	2.0
103	Python GUI Scripting Interface for Running Atomic Physics Applications	Amani Tahat	2011-06-05 01:11:08	http://arxiv.org/abs/1106.0868v1	We create a Python GUI scripting interface working under Windows in addition to (UNIX/Linux). The GUI has been built around the Python open-source programming language. We use the Python's GUI library that so called Python Mega Widgets (PMW) and based on Tkinter Python module (http://www.freenetpages.co.uk/hp/alan.gauld/tutgui.htm). The new GUI was motivated primarily by the desire of more updated operations, more flexibility incorporating future and current improvements in producing atomic data. Furthermore it will be useful for a variety of applications of atomic physics, plasma physics and astrophysics and will help in calculating various atomic properties.			arxiv	['Mofleh Tahat']	3.0
104	Towards Memory Safe Python Enclave for Security Sensitive Computation	Huibo Wang	2020-05-12 18:19:08	http://arxiv.org/abs/2005.05996v1	Intel SGX Guard eXtensions (SGX), a hardware-supported trusted execution environment (TEE), is designed to protect security-sensitive applications. However, since enclave applications are developed with memory unsafe languages such as C/C++, traditional memory corruption is not eliminated in SGX. Rust-SGX is the first toolkit providing enclave developers with a memory-language. However, Rust is considered a Systems language and has become the right choice for concurrent applications and web browsers. Many application domains such as Big Data, Machine Learning, Robotics, Computer Vision are more commonly developed in the python programming language. Therefore, Python application developers cannot benefit from secure enclaves like Intel SGX and rust-SGX. To fill this gap, we propose Python-SGX, which is a memory-safe SGX SDK providing enclave developers a memory-safe Python development environment. The key idea is to enable memory-safe Python language in SGX by solving the following key challenges: (1) defining a memory-safe Python interpreter (2)replacing unsafe elements of Python interpreter with safe ones,(3) achieving comparable performance to non-enclave Python applications, and (4) not introducing any unsafe new code or libraries into SGX. We propose to build Python-SGX with PyPy, a Python interpreter written by RPython, which is a subset of Python, and tame unsafe parts in PyPy by formal verification, security hardening, and memory safe language. We have implemented python-SGX and tested it with a series of benchmarks programs. Our evaluation results show that Python-SGX does not cause significant overhead.			arxiv	['Mingshen Sun', 'Qian Feng', 'Pei Wang', 'Tongxin Li', 'Yu Ding']	4.0
105	Porting the LSST Data Management Pipeline Software to Python 3	Tim Jenness	2016-11-02 19:48:34	http://arxiv.org/abs/1611.00751v1	The LSST data management science pipelines software consists of more than 100,000 lines of Python 2 code. LSST operations will begin after support for Python 2 has been dropped by the Python community in 2020, and we must therefore plan to migrate the codebase to Python 3. During the transition period we must also support our community of active Python 2 users and this complicates the porting significantly. We have decided to use the Python future package as the basis for our port to enable support for Python 2 and Python 3 simultaneously, whilst developing with a mindset more suited to Python 3. In this paper we report on the current status of the port and the difficulties that have been encountered.			arxiv	[]	5.0
106	A general approach for running Python codes in OpenFOAM using an embedded pybind11 Python interpreter	Simon Rodriguez	2022-03-30 15:25:03	http://arxiv.org/abs/2203.16394v1	As the overlap between traditional computational mechanics and machine learning grows, there is an increasing demand for straight-forward approaches to interface Python-based procedures with C++-based OpenFOAM. This article introduces one such general methodology, allowing the execution of Python code directly within an OpenFOAM solver without the need for Python code translation. The proposed approach is based on the lightweight library pybind11, where OpenFOAM data is transferred to an embedded Python interpreter for manipulation, and results are returned as needed. Following a review of related approaches, the article describes the approach, with a particular focus on data transfer between Python and OpenFOAM, executing Python scripts and functions, and practical details about the implementation in OpenFOAM. Three complementary test cases are presented to highlight the functionality and demonstrate the effect of different data transfer approaches: a Python-based velocity profile boundary condition; a Python-based solver for prototyping; and a machine learning mechanical constitutive law class for solids4foam which performs field calculations.			arxiv	['Philip Cardiff']	6.0
107	Python for education: the exact cover problem	Andrzej Kapanowski	2010-10-28 08:53:26	http://arxiv.org/abs/1010.5890v1	Python implementation of Algorithm X by Knuth is presented. Algorithm X finds all solutions to the exact cover problem. The exemplary results for pentominoes, Latin squares and Sudoku are given.			arxiv	[]	7.0
108	Teddy: Automatic Recommendation of Pythonic Idiom Usage For Pull-Based Software Projects	Purit Phan-udom	2020-09-05 12:54:57	http://arxiv.org/abs/2009.03302v1	Pythonic code is idiomatic code that follows guiding principles and practices within the Python community. Offering performance and readability benefits, Pythonic code is claimed to be widely adopted by experienced Python developers, but can be a learning curve to novice programmers. To aid with Pythonic learning, we create an automated tool, called Teddy, that can help checking the Pythonic idiom usage. The tool offers a prevention mode with Just-In-Time analysis to recommend the use of Pythonic idiom during code review and a detection mode with historical analysis to run a thorough scan of idiomatic and non-idiomatic code. In this paper, we first describe our tool and an evaluation of its performance. Furthermore, we present a case study that demonstrates how to use Teddy in a real-life scenario on an Open Source project. An evaluation shows that Teddy has high precision for detecting Pythonic idiom and non-Pythonic code. Using interactive visualizations, we demonstrate how novice programmers can navigate and identify Pythonic idiom and non-Pythonic code in their projects. Our video demo with the full interactive visualizations is available at https://youtu.be/vOCQReSvBxA.			arxiv	['Naruedon Wattanakul', 'Tattiya Sakulniwat', 'Chaiyong Ragkhitwetsagul', 'Thanwadee Sunetnanta', 'Morakot Choetkiertikul', 'Raula Gaikovina Kula']	8.0
109	Machine Learning using Stata/Python	Giovanni Cerulli	2021-03-03 10:31:44	http://arxiv.org/abs/2103.03122v1	We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting popular Machine Learning (ML) methods both in regression and classification settings. Using the recent Stata/Python integration platform (sfi) of Stata 16, these commands provide hyper-parameters' optimal tuning via K-fold cross-validation using greed search. More specifically, they make use of the Python Scikit-learn API to carry out both cross-validation and outcome/label prediction.			arxiv	[]	9.0
110	Using Python for Model Inference in Deep Learning	Zachary DeVito	2021-04-01 04:48:52	http://arxiv.org/abs/2104.00254v1	Python has become the de-facto language for training deep neural networks, coupling a large suite of scientific computing libraries with efficient libraries for tensor computation such as PyTorch or TensorFlow. However, when models are used for inference they are typically extracted from Python as TensorFlow graphs or TorchScript programs in order to meet performance and packaging constraints. The extraction process can be time consuming, impeding fast prototyping. We show how it is possible to meet these performance and packaging constraints while performing inference in Python. In particular, we present a way of using multiple Python interpreters within a single process to achieve scalable inference and describe a new container format for models that contains both native Python code and data. This approach simplifies the model deployment story by eliminating the model extraction step, and makes it easier to integrate existing performance-enhancing Python libraries. We evaluate our design on a suite of popular PyTorch models on Github, showing how they can be packaged in our inference format, and comparing their performance to TorchScript. For larger models, our packaged Python models perform the same as TorchScript, and for smaller models where there is some Python overhead, our multi-interpreter approach ensures inference is still scalable.			arxiv	['Jason Ansel', 'Will Constable', 'Michael Suo', 'Ailing Zhang', 'Kim Hazelwood']	10.0
111	Python Type Hints are Turing Complete	Ori Roth	2022-08-31 10:11:42	http://arxiv.org/abs/2208.14755v1	Grigore showed that Java generics are Turing complete by describing a reduction from Turing machines to Java subtyping. We apply Grigore's algorithm to Python type hints and deduce that they are Turing complete. In addition, we present an alternative reduction in which the Turing machines are simulated in real time, resulting in significantly lower compilation times. Our work is accompanied by a Python implementation of both reductions that compiles Turing machines into Python subtyping machines.			arxiv	[]	11.0
112	OMB-Py: Python Micro-Benchmarks for Evaluating Performance of MPI Libraries on HPC Systems	Nawras Alnaasan	2021-10-20 16:59:14	http://arxiv.org/abs/2110.10659v2	Python has become a dominant programming language for emerging areas like Machine Learning (ML), Deep Learning (DL), and Data Science (DS). An attractive feature of Python is that it provides easy-to-use programming interface while allowing library developers to enhance performance of their applications by harnessing the computing power offered by High Performance Computing (HPC) platforms. Efficient communication is key to scaling applications on parallel systems, which is typically enabled by the Message Passing Interface (MPI) standard and compliant libraries on HPC hardware. mpi4py is a Python-based communication library that provides an MPI-like interface for Python applications allowing application developers to utilize parallel processing elements including GPUs. However, there is currently no benchmark suite to evaluate communication performance of mpi4py -- and Python MPI codes in general -- on modern HPC systems. In order to bridge this gap, we propose OMB-Py -- Python extensions to the open-source OSU Micro-Benchmark (OMB) suite -- aimed to evaluate communication performance of MPI-based parallel applications in Python. To the best of our knowledge, OMB-Py is the first communication benchmark suite for parallel Python applications. OMB-Py consists of a variety of point-to-point and collective communication benchmark tests that are implemented for a range of popular Python libraries including NumPy, CuPy, Numba, and PyCUDA. Our evaluation reveals that mpi4py introduces a small overhead when compared to native MPI libraries. We plan to publicly release OMB-Py to benefit the Python HPC community.			arxiv	['Arpan Jain', 'Aamir Shafi', 'Hari Subramoni', 'Dhabaleswar K Panda']	12.0
113	Does Coding in Pythonic Zen Peak Performance? Preliminary Experiments of Nine Pythonic Idioms at Scale	Pattara Leelaprute	2022-03-28 04:05:54	http://arxiv.org/abs/2203.14484v1	In the field of data science, and for academics in general, the Python programming language is a popular choice, mainly because of its libraries for storing, manipulating, and gaining insight from data. Evidence includes the versatile set of machine learning, data visualization, and manipulation packages used for the ever-growing size of available data. The Zen of Python is a set of guiding design principles that developers use to write acceptable and elegant Python code. Most principles revolve around simplicity. However, as the need to compute large amounts of data, performance has become a necessity for the Python programmer. The new idea in this paper is to confirm whether writing the Pythonic way peaks performance at scale. As a starting point, we conduct a set of preliminary experiments to evaluate nine Pythonic code examples by comparing the performance of both Pythonic and Non-Pythonic code snippets. Our results reveal that writing in Pythonic idioms may save memory and time. We show that incorporating list comprehension, generator expression, zip, and itertools.zip_longest idioms can save up to 7,000 MB and up to 32.25 seconds. The results open more questions on how they could be utilized in a real-world setting. The replication package includes all scripts, and the results are available at https://doi.org/10.5281/zenodo.5712349			arxiv	['Bodin Chinthanet', 'Supatsara Wattanakriengkrai', 'Raula Gaikovina Kula', 'Pongchai Jaisri', 'Takashi Ishio']	13.0
114	Pydelay - a python tool for solving delay differential equations	V. Flunkert	2009-11-09 11:00:43	http://arxiv.org/abs/0911.1633v1	pydelay is a python library which translates a system of delay differential equations into C-code and simulates the code using scipy weave.			arxiv	['E. Schoell']	14.0
115	How fast can we make interpreted Python?	Russell Power	2013-06-25 17:57:00	http://arxiv.org/abs/1306.6047v2	Python is a popular dynamic language with a large part of its appeal coming from powerful libraries and extension modules. These augment the language and make it a productive environment for a wide variety of tasks, ranging from web development (Django) to numerical analysis (NumPy). Unfortunately, Python's performance is quite poor when compared to modern implementations of languages such as Lua and JavaScript. Why does Python lag so far behind these other languages? As we show, the very same API and extension libraries that make Python a powerful language also make it very difficult to efficiently execute. Given that we want to retain access to the great extension libraries that already exist for Python, how fast can we make it? To evaluate this, we designed and implemented Falcon, a high-performance bytecode interpreter fully compatible with the standard CPython interpreter. Falcon applies a number of well known optimizations and introduces several new techniques to speed up execution of Python bytecode. In our evaluation, we found Falcon an average of 25% faster than the standard Python interpreter on most benchmarks and in some cases about 2.5X faster.			arxiv	['Alex Rubinsteyn']	15.0
116	Performance of Python runtimes on a non-numeric scientific code	Riccardo Murri	2014-04-25 10:55:48	http://arxiv.org/abs/1404.6388v2	The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational homology of the moduli space of Riemann surfaces is an example of a non-numeric scientific code: most of the processing it does is generating graphs (represented by complex Python objects) and computing their isomorphisms (a triple of Python lists; again a nested data structure). These operations are repeated many times over: for example, the spaces and are triangulated by 4'583'322 and 747'664 graphs, respectively. This is an opportunity for every Python runtime to prove its strength in optimization. The purpose of this experiment was to assess the maturity of alternative Python runtimes, in terms of: compatibility with the language as implemented in CPython 2.7, and performance speedup. This paper compares the results and experiences from running FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython 0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.			arxiv	[]	16.0
117	Generating Python Code From Object-Z Specifications	A. F. Al Azzawi	2018-02-17 11:41:24	http://arxiv.org/abs/1802.06224v1	Object-Z is an object-oriented specification language which extends the Z language with classes, objects, inheritance and polymorphism that can be used to represent the specification of a complex system as collections of objects. There are a number of existing works that mapped Object-Z to C++ and Java programming languages. Since Python and Object-Z share many similarities, both are object-oriented paradigm, support set theory and predicate calculus moreover, Python is a functional programming language which is naturally closer to formal specifications, we propose a mapping from Object-Z specifications to Python code that covers some Object-Z constructs and express its specifications in Python to validate these specifications. The validations are used in the mapping covered preconditions, post-conditions, and invariants that are built using lambda function and Python's decorator. This work has found Python is an excellent language for developing libraries to map Object-Z specifications to Python.			arxiv	['M. Bettaz', 'H. M. Al-Refai']	17.0
118	Building a scalable python distribution for HEP data analysis	David Lange	2018-04-24 10:07:02	http://arxiv.org/abs/1804.08939v1	There are numerous approaches to building analysis applications across the high-energy physics community. Among them are Python-based, or at least Python-driven, analysis workflows. We aim to ease the adoption of a Python-based analysis toolkit by making it easier for non-expert users to gain access to Python tools for scientific analysis. Experimental software distributions and individual user analysis have quite different requirements. Distributions tend to worry most about stability, usability and reproducibility, while the users usually strive to be fast and nimble. We discuss how we built and now maintain a python distribution for analysis while satisfying requirements both a large software distribution (in our case, that of CMSSW) and user, or laptop, level analysis. We pursued the integration of tools used by the broader data science community as well as HEP developed (e.g., histogrammar, root_numpy) Python packages. We discuss concepts we investigated for package integration and testing, as well as issues we encountered through this process. Distribution and platform support are important topics. We discuss our approach and progress towards a sustainable infrastructure for supporting this Python stack for the CMS user community and for the broader HEP user community.			arxiv	[]	18.0
119	A Python Extension for the Massively Parallel Multiphysics Simulation Framework waLBerla	Martin Bauer	2015-11-23 15:06:47	http://arxiv.org/abs/1511.07261v1	We present a Python extension to the massively parallel HPC simulation toolkit waLBerla. waLBerla is a framework for stencil based algorithms operating on block-structured grids, with the main application field being fluid simulations in complex geometries using the lattice Boltzmann method. Careful performance engineering results in excellent node performance and good scalability to over 400,000 cores. To increase the usability and flexibility of the framework, a Python interface was developed. Python extensions are used at all stages of the simulation pipeline: They simplify and automate scenario setup, evaluation, and plotting. We show how our Python interface outperforms the existing text-file-based configuration mechanism, providing features like automatic nondimensionalization of physical quantities and handling of complex parameter dependencies. Furthermore, Python is used to process and evaluate results while the simulation is running, leading to smaller output files and the possibility to adjust parameters dependent on the current simulation state. C++ data structures are exported such that a seamless interfacing to other numerical Python libraries is possible. The expressive power of Python and the performance of C++ make development of efficient code with low time effort possible.			arxiv	['Florian Schornbaum', 'Christian Godenschwager', 'Matthias Markl', 'Daniela Anderl', 'Harald K√∂stler', 'Ulrich R√ºde']	19.0
120	The Dune Python Module	Andreas Dedner	2018-07-13 19:17:48	http://arxiv.org/abs/1807.05252v1	In this paper we present the new Dune-Python module which provides Python bindings for the Dune core, which is a C++ environment for solving partial differential equations. The aim of this new module is to firstly provide the general infrastructure for exporting realizations of statically polymorphic interfaces based on just-in-time compilation and secondly to provide bindings for the central interfaces of the dune core modules. In the first release we focus on the grid interface. Our aim is to only introduce a thin layer when passing objects into Python which can be removed when the object is passed back into a C++ algorithm. Thus no efficiency is lost and little additional code maintenance cost is incurred. To make the transition for Dune users to the Python environment straightforward the Python classes provide a very similar interface to their C++ counterparts. In addition, vectorized versions of many interfaces allow for more efficient code on the Python side. The infrastructure for exporting these interfaces and the resulting bindings for a Dune grid are explained in detail in this paper for both experienced Dune users and others interested in a flexible Python environment for implementing grid based schemes for solving partial differential equations.			arxiv	['Martin Nolte']	20.0
121	Image Processing in Python With Montage	John Good	2019-08-26 15:50:25	http://arxiv.org/abs/1908.09753v1	The Montage image mosaic engine has found wide applicability in astronomy research, integration into processing environments, and is an examplar application for the development of advanced cyber-infrastructure. It is written in C to provide performance and portability. Linking C/C++ libraries to the Python kernel at run time as binary extensions allows them to run under Python at compiled speeds and enables users to take advantage of all the functionality in Python. We have built Python binary extensions of the 59 ANSI-C modules that make up version 5 of the Montage toolkit. This has involved a turning the code into a C library, with driver code fully separated to reproduce the calling sequence of the command-line tools; and then adding Python and C linkage code with the Cython library, which acts as a bridge between general C libraries and the Python interface. We will demonstrate how to use these Python binary extensions to perform image processing, including reprojecting and resampling images, rectifying background emission to a common level, creation of image mosaics that preserve the calibration and astrometric fidelity of the input images, creating visualizations with an adaptive stretch algorithm, processing HEALPix images, and analyzing and managing image metadata.			arxiv	['G. Bruce Berriman']	21.0
122	An Analysis of Python's Topics, Trends, and Technologies Through Mining Stack Overflow Discussions	Hamed Tahmooresi	2020-04-14 02:59:16	http://arxiv.org/abs/2004.06280v1	Python is a popular, widely used, and general-purpose programming language. In spite of its ever-growing community, researchers have not performed much analysis on Python's topics, trends, and technologies which provides insights for developers about Python community trends and main issues. In this article, we examine the main topics related to this language being discussed by developers on one of the most popular Q\&A websites, Stack Overflow, as well as temporal trends through mining 2461876 posts. To be more useful for the software engineers, we study what Python provides as the alternative to popular technologies offered by common programming languages like Java. Our results indicate that discussions about Python standard features, web programming, and scientific programming. Programming in areas such as mathematics, data science, statistics, machine learning, natural language processing (NLP), and so forth. are the most popular areas in the Python community. At the same time, areas related to scientific programming are steadily receiving more attention from the Python developers.			arxiv	['Abbas Heydarnoori', 'Alireza Aghamohammadi']	22.0
123	Python Workflows on HPC Systems	Dominik Strassel	2020-12-01 09:51:12	http://arxiv.org/abs/2012.00365v1	The recent successes and wide spread application of compute intensive machine learning and data analytics methods have been boosting the usage of the Python programming language on HPC systems. While Python provides many advantages for the users, it has not been designed with a focus on multi-user environments or parallel programming - making it quite challenging to maintain stable and secure Python workflows on a HPC system. In this paper, we analyze the key problems induced by the usage of Python on HPC clusters and sketch appropriate workarounds for efficiently maintaining multi-user Python software environments, securing and restricting resources of Python jobs and containing Python processes, while focusing on Deep Learning applications running on GPU clusters.			arxiv	['Philipp Reusch', 'Janis Keuper']	23.0
124	Conflict-aware Inference of Python Compatible Runtime Environments with Domain Knowledge Graph	Wei Cheng	2022-01-18 14:55:00	http://arxiv.org/abs/2201.07029v1	Code sharing and reuse is a widespread use practice in software engineering. Although a vast amount of open-source Python code is accessible on many online platforms, programmers often find it difficult to restore a successful runtime environment. Previous studies validated automatic inference of Python dependencies using pre-built knowledge bases. However, these studies do not cover sufficient knowledge to accurately match the Python code and also ignore the potential conflicts between their inferred dependencies, thus resulting in a low success rate of inference. In this paper, we propose PyCRE, a new approach to automatically inferring Python compatible runtime environments with domain knowledge graph (KG). Specifically, we design a domain-specific ontology for Python third-party packages and construct KGs for over 10,000 popular packages in Python 2 and Python 3. PyCRE discovers candidate libraries by measuring the matching degree between the known libraries and the third-party resources used in target code. For the NP-complete problem of dependency solving, we propose a heuristic graph traversal algorithm to efficiently guarantee the compatibility between packages. PyCRE achieves superior performance on a real-world dataset and efficiently resolves nearly half more import errors than previous methods.			arxiv	['Xiangrong Zhu', 'Wei Hu']	24.0
125	Triangulating Python Performance Issues with Scalene	Emery D. Berger	2022-12-15 02:56:25	http://arxiv.org/abs/2212.07597v1	This paper proposes Scalene, a profiler specialized for Python. Scalene combines a suite of innovations to precisely and simultaneously profile CPU, memory, and GPU usage, all with low overhead. Scalene's CPU and memory profilers help Python programmers direct their optimization efforts by distinguishing between inefficient Python and efficient native execution time and memory usage. Scalene's memory profiler employs a novel sampling algorithm that lets it operate with low overhead yet high precision. It also incorporates a novel algorithm that automatically pinpoints memory leaks, whether within Python or across the Python-native boundary. Scalene tracks a new metric called copy volume, which highlights costly copying operations that can occur when Python silently converts between C and Python data representations, or between CPU and GPU. Since its introduction, Scalene has been widely adopted, with over 500,000 downloads to date. We present experience reports from developers who used Scalene to achieve significant performance improvements and memory savings.			arxiv	['Sam Stern', 'Juan Altmayer Pizzorno']	25.0
126	Python for education: permutations	Andrzej Kapanowski	2013-07-26 14:18:21	http://arxiv.org/abs/1307.7042v1	Python implementation of permutations is presented. Three classes are introduced: Perm for permutations, Group for permutation groups, and PermError to report any errors for both classes. The class Perm is based on Python dictionaries and utilize cycle notation. The methods of calculation for the perm order, parity, ranking and unranking are given. A random permutation generation is also shown. The class Group is very simple and it is also based on dictionaries. It is mainly the presentation of the permutation groups interface with methods for the group order, subgroups (normalizer, centralizer, center, stabilizer), orbits, and several tests. The corresponding Python code is contained in the modules perms and groups.			arxiv	[]	26.0
127	Python bindings for libcloudph++	Dorota Jarecka	2015-04-05 20:58:18	http://arxiv.org/abs/1504.01161v1	This technical note introduces the Python bindings for libcloudph++. The libcloudph++ is a C++ library of algorithms for representing atmospheric cloud microphysics in numerical models. The bindings expose the complete functionality of the library to the Python users. The bindings are implemented using the Boost.Python C++ library and use NumPy arrays. This note includes listings with Python scripts exemplifying the use of selected library components. An example solution for using the Python bindings to access libcloudph++ from Fortran is presented.			arxiv	['Sylwester Arabas', 'Davide Del Vento']	27.0
128	Yaps: Python Frontend to Stan	Guillaume Baudart	2018-12-06 01:24:29	http://arxiv.org/abs/1812.04125v1	Stan is a popular probabilistic programming language with a self-contained syntax and semantics that is close to graphical models. Unfortunately, existing embeddings of Stan in Python use multi-line strings. That approach forces users to switch between two different language styles, with no support for syntax highlighting or simple error reporting within the Stan code. This paper tackles the question of whether Stan could use Python syntax while retaining its self-contained semantics. The answer is yes, that can be accomplished by reinterpreting the Python syntax. This paper introduces Yaps, a new frontend to Stan based on reinterpreted Python. We tested Yaps on over a thousand Stan models and made it available open-source.			arxiv	['Martin Hirzel', 'Kiran Kate', 'Louis Mandel', 'Avraham Shinnar']	28.0
129	Pytrec_eval: An Extremely Fast Python Interface to trec_eval	Christophe Van Gysel	2018-05-04 03:37:03	http://arxiv.org/abs/1805.01597v2	We introduce pytrec_eval, a Python interface to the tree_eval information retrieval evaluation toolkit. pytrec_eval exposes the reference implementations of trec_eval within Python as a native extension. We show that pytrec_eval is around one order of magnitude faster than invoking trec_eval as a sub process from within Python. Compared to a native Python implementation of NDCG, pytrec_eval is twice as fast for practically-sized rankings. Finally, we demonstrate its effectiveness in an application where pytrec_eval is combined with Pyndri and the OpenAI Gym where query expansion is learned using Q-learning.			arxiv	['Maarten de Rijke']	29.0
130	Nonparametric Estimation of the Random Coefficients Model in Python	Emil Mendoza	2021-08-08 07:27:49	http://arxiv.org/abs/2108.03582v2	We present $\textbf{PyRMLE}$, a Python module that implements Regularized Maximum Likelihood Estimation for the analysis of Random Coefficient models. $\textbf{PyRMLE}$ is simple to use and readily works with data formats that are typical to Random Coefficient problems. The module makes use of Python's scientific libraries $\textbf{NumPy}$ and $\textbf{SciPy}$ for computational efficiency. The main implementation of the algorithm is executed purely in Python code which takes advantage of Python's high-level features.			arxiv	['Fabian Dunker', 'Marco Reale']	30.0
131	Running HMC Simulation with Python via QUDA	Shuhei Yamamoto	2022-12-13 15:40:29	http://arxiv.org/abs/2212.06657v1	Lyncs-API is a Python API for Lattice QCD applications. It is designed as a Python toolkit that allows the user to use and run various lattice QCD libraries while programming in Python. The goal is to provide the user an easy programming experience without scarifying performance across multiple platforms, by preparing a common framework for various softwares for lattice QCD calculations. As such, it contains interfaces to, e.g., c-lime, DDalphaAMG, tmLQCD, and QUDA. In this proceeding, we focus on a Lyncs interface to QUDA, named Lyncs-QUDA, and present a small tutorial on how to use this Python interface to perform a HMC simulation using QUDA.			arxiv	['Simone Bacchio', 'Jacob Finenrath']	31.0
132	Python client for Isabelle server	Boris Shminke	2022-12-09 12:05:28	http://arxiv.org/abs/2212.11173v1	We contribute a Python client for the Isabelle server, which gives researchers and students using Python as their primary programming language an opportunity to communicate with the Isabelle server through TCP directly from a Python script. Such an approach helps avoid the complexities of integrating the existing Python script with languages used for Isabelle development (ML and Scala). We also describe new features that appeared since the announcement of the first version of the client a year ago. Finally, we give examples of the client's applications in research and education and discuss known limitations and possible directions for future development.			arxiv	[]	32.0
133	ePython: An implementation of Python for the many-core Epiphany coprocessor	Nick Brown	2020-10-28 09:01:27	http://arxiv.org/abs/2010.14827v1	The Epiphany is a many-core, low power, low on-chip memory architecture and one can very cheaply gain access to a number of parallel cores which is beneficial for HPC education and prototyping. The very low power nature of these architectures also means that there is potential for their use in future HPC machines, however there is a high barrier to entry in programming them due to the associated complexities and immaturity of supporting tools. In this paper we present our work on ePython, a subset of Python for the Epiphany and similar many-core co-processors. Due to the limited on-chip memory per core we have developed a new Python interpreter and this, combined with additional support for parallelism, has meant that novices can take advantage of Python to very quickly write parallel codes on the Epiphany and explore concepts of HPC using a smaller scale parallel machine. The high level nature of Python opens up new possibilities on the Epiphany, we examine a computationally intensive Gauss-Seidel code from the programmability and performance perspective, discuss running Python hybrid on both the host CPU and Epiphany, and interoperability between a full Python interpreter on the CPU and ePython on the Epiphany. The result of this work is support for developing Python on the Epiphany, which can be applied to other similar architectures, that the community have already started to adopt and use to explore concepts of parallelism and HPC.			arxiv	[]	33.0
134	Characterizing Bugs in Python and R Data Analytics Programs	Shibbir Ahmed	2023-06-14 16:50:01	http://arxiv.org/abs/2306.08632v1	R and Python are among the most popular languages used in many critical data analytics tasks. However, we still do not fully understand the capabilities of these two languages w.r.t. bugs encountered in data analytics tasks. What type of bugs are common? What are the main root causes? What is the relation between bugs and root causes? How to mitigate these bugs? We present a comprehensive study of 5,068 Stack Overflow posts, 1,800 bug fix commits from GitHub repositories, and several GitHub issues of the most used libraries to understand bugs in R and Python. Our key findings include: while both R and Python have bugs due to inexperience with data analysis, Python see significantly larger data preprocessing bugs compared to R. Developers experience significantly more data flow bugs in R because intermediate results are often implicit. We also found changes and bugs in packages and libraries cause more bugs in R compared to Python while package or library misselection and conflicts cause more bugs in Python than R. While R has a slightly higher readability barrier for data analysts, the statistical power of R leads to a less number of bad performance bugs. In terms of data visualization, R packages have significantly more bugs than Python libraries. We also identified a strong correlation between comparable packages in R and Python despite their linguistic and methodological differences. Lastly, we contribute a large dataset of manually verified R and Python bugs.			arxiv	['Mohammad Wardat', 'Hamid Bagheri', 'Breno Dantas Cruz', 'Hridesh Rajan']	34.0
135	Simplifying Parallelization of Scientific Codes by a Function-Centric Approach in Python	Jon K. Nilsen	2010-02-03 12:31:14	http://arxiv.org/abs/1002.0705v1	The purpose of this paper is to show how existing scientific software can be parallelized using a separate thin layer of Python code where all parallel communication is implemented. We provide specific examples on such layers of code, and these examples may act as templates for parallelizing a wide set of serial scientific codes. The use of Python for parallelization is motivated by the fact that the language is well suited for reusing existing serial codes programmed in other languages. The extreme flexibility of Python with regard to handling functions makes it very easy to wrap up decomposed computational tasks of a serial scientific application as Python functions. Many parallelization-specific components can be implemented as generic Python functions, which may take as input those functions that perform concrete computational tasks. The overall programming effort needed by this parallelization approach is rather limited, and the resulting parallel Python scripts have a compact and clean structure. The usefulness of the parallelization approach is exemplified by three different classes of applications in natural and social sciences.			arxiv	['Xing Cai', 'Bjorn Hoyland', 'Hans Petter Langtangen']	35.0
136	DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets	Eric Horton	2019-05-27 11:23:29	http://arxiv.org/abs/1905.11127v1	Platforms like Stack Overflow and GitHub's gist system promote the sharing of ideas and programming techniques via the distribution of code snippets designed to illustrate particular tasks. Python, a popular and fast-growing programming language, sees heavy use on both sites, with nearly one million questions asked on Stack Overflow and 400 thousand public gists on GitHub. Unfortunately, around 75% of the Python example code shared through these sites cannot be directly executed. When run in a clean environment, over 50% of public Python gists fail due to an import error for a missing library. We present DockerizeMe, a technique for inferring the dependencies needed to execute a Python code snippet without import error. DockerizeMe starts with offline knowledge acquisition of the resources and dependencies for popular Python packages from the Python Package Index (PyPI). It then builds Docker specifications using a graph-based inference procedure. Our inference procedure resolves import errors in 892 out of nearly 3,000 gists from the Gistable dataset for which Gistable's baseline approach could not find and install all dependencies.			arxiv	['Chris Parnin']	36.0
137	OpenML-Python: an extensible Python API for OpenML	Matthias Feurer	2019-11-06 16:59:30	http://arxiv.org/abs/1911.02490v2	OpenML is an online platform for open science collaboration in machine learning, used to share datasets and results of machine learning experiments. In this paper we introduce OpenML-Python, a client API for Python, opening up the OpenML platform for a wide range of Python-based tools. It provides easy access to all datasets, tasks and experiments on OpenML from within Python. It also provides functionality to conduct machine learning experiments, upload the results to OpenML, and reproduce results which are stored on OpenML. Furthermore, it comes with a scikit-learn plugin and a plugin mechanism to easily integrate other machine learning libraries written in Python into the OpenML ecosystem. Source code and documentation is available at https://github.com/openml/openml-python/.			arxiv	['Jan N. van Rijn', 'Arlind Kadra', 'Pieter Gijsbers', 'Neeratyoy Mallik', 'Sahithya Ravi', 'Andreas M√ºller', 'Joaquin Vanschoren', 'Frank Hutter']	37.0
138	Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations and visualizations via ParaMonte::Python library	Amir Shahmoradi	2020-10-01 23:26:42	http://arxiv.org/abs/2010.00724v1	ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for sampling mathematical objective functions, in particular, the posterior distributions of parameters in Bayesian modeling and analysis in data science, Machine Learning, and scientific inference in general. In addition to providing access to fast high-performance serial/parallel Monte Carlo and MCMC sampling routines, the ParaMonte::Python library provides extensive post-processing and visualization tools that aim to automate and streamline the process of model calibration and uncertainty quantification in Bayesian data analysis. Furthermore, the automatically-enabled restart functionality of ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future restart of Monte Carlo simulations, should any interruptions happen. The ParaMonte::Python library is MIT-licensed and is permanently maintained on GitHub at https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.			arxiv	['Fatemeh Bagheri', 'Joshua Alexander Osborne']	38.0
139	Productivity, Portability, Performance: Data-Centric Python	Alexandros Nikolaos Ziogas	2021-07-01 15:51:18	http://arxiv.org/abs/2107.00555v2	Python has become the de facto language for scientific computing. Programming in Python is highly productive, mainly due to its rich science-oriented software ecosystem built around the NumPy module. As a result, the demand for Python support in High Performance Computing (HPC) has skyrocketed. However, the Python language itself does not necessarily offer high performance. In this work, we present a workflow that retains Python's high productivity while achieving portable performance across different architectures. The workflow's key features are HPC-oriented language extensions and a set of automatic optimizations powered by a data-centric intermediate representation. We show performance results and scaling across CPU, GPU, FPGA, and the Piz Daint supercomputer (up to 23,328 cores), with 2.47x and 3.75x speedups over previous-best solutions, first-ever Xilinx and Intel FPGA results of annotated Python, and up to 93.16% scaling efficiency on 512 nodes.			arxiv	['Timo Schneider', 'Tal Ben-Nun', 'Alexandru Calotoiu', 'Tiziano De Matteis', 'Johannes de Fine Licht', 'Luca Lavarini', 'Torsten Hoefler']	39.0
140	PyTracer: Automatically profiling numerical instabilities in Python	Yohan Chatelain	2021-12-21 20:22:34	http://arxiv.org/abs/2112.11508v2	Numerical stability is a crucial requirement of reliable scientific computing. However, despite the pervasiveness of Python in data science, analyzing large Python programs remains challenging due to the lack of scalable numerical analysis tools available for this language. To fill this gap, we developed PyTracer, a profiler to quantify numerical instability in Python applications. PyTracer transparently instruments Python code to produce numerical traces and visualize them interactively in a Plotly dashboard. We designed PyTracer to be agnostic to numerical noise model, allowing for tool evaluation through Monte-Carlo Arithmetic, random rounding, random data perturbation, or structured noise for a particular application. We illustrate PyTracer's capabilities by testing the numerical stability of key functions in both SciPy and Scikit-learn, two dominant Python libraries for mathematical modeling. Through these evaluations, we demonstrate PyTracer as a scalable, automatic, and generic framework for numerical profiling in Python.			arxiv	['Nigel Yong', 'Gregory Kiar', 'Tristan Glatard']	40.0
141	GAP-Gen: Guided Automatic Python Code Generation	Junchen Zhao	2022-01-19 06:32:47	http://arxiv.org/abs/2201.08810v2	Automatic code generation from natural language descriptions can be highly beneficial during the process of software development. In this work, we propose GAP-Gen, a Guided Automatic Python Code Generation method based on Python syntactic constraints and semantic constraints. We first introduce Python syntactic constraints in the form of Syntax-Flow, which is a simplified version of Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract Syntax Tree but maintaining crucial syntactic information of Python code. In addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable and function names consistently through out the code. In our work, rather than pretraining, we focus on modifying the finetuning process which reduces computational requirements but retains high generation performance on automatic Python code generation task. GAP-Gen fine-tunes the transformer based language models T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet, CodeSearchNet AdvTest and Code-Docstring Corpus from EdinburghNLP. Our experiments show that GAP-Gen achieves better results on automatic Python code generation task than previous works.			arxiv	['Yurun Song', 'Junlin Wang', 'Ian G. Harris']	41.0
142	Approaches to the Parallelization of Merge Sort in Python	Alexandra Yang	2022-11-26 18:26:30	http://arxiv.org/abs/2211.16479v1	The theory of divide-and-conquer parallelization has been well-studied in the past, providing a solid basis upon which to explore different approaches to the parallelization of merge sort in Python. Python's simplicity and extensive selection of libraries make it the most popular scientific programming language, so it is a fitting language in which to implement and analyze these algorithms. In this paper, we use Python packages multiprocessing and mpi4py to implement several different parallel merge sort algorithms. Experiments are conducted on an academic supercomputer, upon which benchmarks are performed using Cloudmesh. We find that hybrid multiprocessing merge sort outperforms several other algorithms, achieving a 1.5x speedup compared to the built-in Python sorted() and a 34x speedup compared to sequential merge sort. Our results provide insight into different approaches to implementing parallel merge sort in Python and contribute to the understanding of general divide-and-conquer parallelization in Python on both shared and distributed memory systems.			arxiv	[]	42.0
143	Faster or Slower? Performance Mystery of Python Idioms Unveiled with Empirical Evidence	Zejun Zhang	2023-01-30 03:28:24	http://arxiv.org/abs/2301.12633v1	The usage of Python idioms is popular among Python developers in a formative study of 101 performance-related questions of Python idioms on Stack Overflow, we find that developers often get confused about the performance impact of Python idioms and use anecdotal toy code or rely on personal project experience which is often contradictory in performance outcomes. There has been no large-scale, systematic empirical evidence to reconcile these performance debates. In the paper, we create a large synthetic dataset with 24,126 pairs of non-idiomatic and functionally-equivalent idiomatic code for the nine unique Python idioms identified in Zhang et al., and reuse a large real-project dataset of 54,879 such code pairs provided by Zhang et al. We develop a reliable performance measurement method to compare the speedup or slowdown by idiomatic code against non-idiomatic counterpart, and analyze the performance discrepancies between the synthetic and real-project code, the relationships between code features and performance changes, and the root causes of performance changes at the bytecode level. We summarize our findings as some actionable suggestions for using Python idioms.			arxiv	['Zhenchang Xing', 'Xin Xia', 'Xiwei Xu', 'Liming Zhu', 'Qinghua Lu']	43.0
144	Rapid Development of Interferometric Software Using MIRIAD and Python	Peter K. G. Williams	2012-03-01 22:07:31	http://arxiv.org/abs/1203.0330v1	"New and upgraded radio interferometers produce data at massive rates and will require significant improvements in analysis techniques to reach their promised levels of performance in a routine manner. Until these techniques are fully developed, productivity and accessibility in scientific programming environments will be key bottlenecks in the pipeline leading from data-taking to research results. We present an open-source software package, miriad-python, that allows access to the MIRIAD interferometric reduction system in the Python programming language. The modular design of MIRIAD and the high productivity and accessibility of Python provide an excellent foundation for rapid development of interferometric software. Several other projects with similar goals exist and we describe them and compare miriad-python to them in detail. Along with an overview of the package design, we present sample code and applications, including the detection of millisecond astrophysical transients, determination and application of nonstandard calibration parameters, interactive data visualization, and a reduction pipeline using a directed acyclic graph dependency model analogous to that of the traditional Unix tool ""make"". The key aspects of the miriad-python software project are documented. We find that miriad-python provides an extremely effective environment for prototyping new interferometric software, though certain existing packages provide far more infrastructure for some applications. While equivalent software written in compiled languages can be much faster than Python, there are many situations in which execution time is profitably exchanged for speed of development, code readability, accessibility to nonexpert programmers, quick interlinking with foreign software packages, and other virtues of the Python language."			arxiv	['Casey J. Law', 'Geoffrey C. Bower']	44.0
145	Toward Efficient Interactions between Python and Native Libraries	Jialiang Tan	2021-06-11 00:48:02	http://arxiv.org/abs/2107.00064v1	Python has become a popular programming language because of its excellent programmability. Many modern software packages utilize Python for high-level algorithm design and depend on native libraries written in C/C++/Fortran for efficient computation kernels. Interaction between Python code and native libraries introduces performance losses because of the abstraction lying on the boundary of Python and native libraries. On the one side, Python code, typically run with interpretation, is disjoint from its execution behavior. On the other side, native libraries do not include program semantics to understand algorithm defects. To understand the interaction inefficiencies, we extensively study a large collection of Python software packages and categorize them according to the root causes of inefficiencies. We extract two inefficiency patterns that are common in interaction inefficiencies. Based on these patterns, we develop PieProf, a lightweight profiler, to pinpoint interaction inefficiencies in Python applications. The principle of PieProf is to measure the inefficiencies in the native execution and associate inefficiencies with high-level Python code to provide a holistic view. Guided by PieProf, we optimize 17 real-world applications, yielding speedups up to 6.3$\times$ on application level.			arxiv	['Yu Chen', 'Zhenming Liu', 'Bin Ren', 'Shuaiwen Leon Song', 'Xipeng Shen', 'Xu Liu']	45.0
146	Improving Tese Case Generation for Python Native Libraries Through Constraints on Input Data Structures	Xin Zhang	2022-06-28 08:47:33	http://arxiv.org/abs/2206.13828v1	Modern Python projects execute computational functions using native libraries and give Python interfaces to boost execution speed; hence, testing these libraries becomes critical to the project's robustness. One challenge is that existing approaches use coverage to guide generation, but native libraries run as black boxes to Python code with no execution information. Another is that dynamic binary instrumentation reduces testing performance as it needs to monitor both native libraries and the Python virtual machine. To address these challenges, in this paper, we propose an automated test case generation approach that works at the Python code layer. Our insight is that many path conditions in native libraries are for processing input data structures through interacting with the VM. In our approach, we instrument the Python Interpreter to monitor the interactions between native libraries and VM, derive constraints on the structures, and then use the constraints to guide test case generation. We implement our approach in a tool named PyCing and apply it to six widely-used Python projects. The experimental results reveal that with the structure constraint guidance, PyCing can cover more execution paths than existing test cases and state-of-the-art tools. Also, with the checkers in the testing framework Pytest, PyCing can identify segmentation faults in 10 Python interfaces and memory leaks in 9. Our instrumentation strategy also has an acceptable influence on testing efficiency.			arxiv	['Xutong Ma', 'Jiwen Yan', 'Baoquan Cui', 'Jun Yan', 'Jian Zhang']	46.0
147	binary_c-python: A Python-based stellar population synthesis tool and interface to binary_c	D. D. Hendriks	2023-06-05 11:04:17	http://arxiv.org/abs/2306.02779v1	We present the software package binary_c-python which provides a convenient and easy-to-use interface to the binary_c framework, allowing the user to rapidly evolve individual systems and populations of stars. binary_c-python is available on Pip and on GitLab. binary_c-python contains many useful features to control and process the output of binary_c, like by providing binary_c-python with logging statements that are dynamically compiled and loaded into binary_c. Moreover, we have recently added standardised output of events like Roche-lobe overflow or double compact-object formation to binary_c, and automatic parsing and managing of that output in binary_c-python. binary_c-python uses multiprocessing to utilise all the cores on a particular machine, and can run populations with HPC cluster workload managers like HTCondor and Slurm, allowing the user to run simulations on large computing clusters. We provide documentation that is automatically generated based on docstrings and a suite of Jupyter notebooks. These notebooks consist of technical tutorials on how to use binary_c-python and use-case scenarios aimed at doing science. Much of binary_c-python is covered by unit tests to ensure reliability and correctness, and the test coverage is continually increased as the package is improved.			arxiv	['R. G. Izzard']	47.0
148	PyMsOfa: A Python Package for the Standards of Fundamental Astronomy (SOFA) Service	Jianghui Ji	2023-10-12 19:11:41	http://arxiv.org/abs/2310.08673v2	The Standards of Fundamental Astronomy (SOFA) is a service provided by the International Astronomical Union (IAU) that offers algorithms and software for astronomical calculations, which was released in two versions by FORTRAN 77 and ANSI C, respectively. In this work, we implement the python package PyMsOfa for SOFA service by three ways: (1) a python wrapper package based on a foreign function library for Python (ctypes), (2) a python wrapper package with the foreign function interface for Python calling C code (cffi), and (3) a python package directly written in pure python codes from SOFA subroutines. The package PyMsOfa has fully implemented 247 functions of the original SOFA routines. In addition, PyMsOfa is also extensively examined, which is exactly consistent with those test examples given by the original SOFA. This python package can be suitable to not only the astrometric detection of habitable planets of the Closeby Habitable Exoplanet Survey (CHES) mission (Ji et al. 2022), but also for the frontiers themes of black holes and dark matter related to astrometric calculations and other fields. The source codes are available via https://github.com/CHES2023/PyMsOfa.			arxiv	['Dongjie Tan', 'Chunhui Bao', 'Xiumin Huang', 'Shoucun Hu', 'Yao Dong', 'Su Wang']	48.0
149	Python for Education: Computational Methods for Nonlinear Systems	Christopher R. Myers	2007-04-24 18:55:17	http://arxiv.org/abs/0704.3182v1	We describe a novel, interdisciplinary, computational methods course that uses Python and associated numerical and visualization libraries to enable students to implement simulations for a number of different course modules. Problems in complex networks, biomechanics, pattern formation, and gene regulation are highlighted to illustrate the breadth and flexibility of Python-powered computational environments.			arxiv	['James. P. Sethna']	49.0
150	Implementation of Kalman Filter with Python Language	Mohamed Laaraiedh	2012-04-02 11:40:41	http://arxiv.org/abs/1204.0375v1	In this paper, we investigate the implementation of a Python code for a Kalman Filter using the Numpy package. A Kalman Filtering is carried out in two steps: Prediction and Update. Each step is investigated and coded as a function with matrix input and output. These different functions are explained and an example of a Kalman Filter application for the localization of mobile in wireless networks is given.			arxiv	[]	50.0
151	A Framework for Distributed Deep Learning Layer Design in Python	Clay McLeod	2015-10-25 21:04:12	http://arxiv.org/abs/1510.07303v1	In this paper, a framework for testing Deep Neural Network (DNN) design in Python is presented. First, big data, machine learning (ML), and Artificial Neural Networks (ANNs) are discussed to familiarize the reader with the importance of such a system. Next, the benefits and detriments of implementing such a system in Python are presented. Lastly, the specifics of the system are explained, and some experimental results are presented to prove the effectiveness of the system.			arxiv	[]	51.0
152	Want Drugs? Use Python	Micha≈Ç Nowotka	2016-07-01 19:02:36	http://arxiv.org/abs/1607.00378v1	We describe how Python can be leveraged to streamline the curation, modelling and dissemination of drug discovery data as well as the development of innovative, freely available tools for the related scientific community. We look at various examples, such as chemistry toolkits, machine-learning applications and web frameworks and show how Python can glue it all together to create efficient data science pipelines.			arxiv	['George Papadatos', 'Mark Davies', 'Nathan Dedman', 'Anne Hersey']	52.0
153	Geoplotlib: a Python Toolbox for Visualizing Geographical Data	Andrea Cuttone	2016-08-05 16:39:27	http://arxiv.org/abs/1608.01933v1	We introduce geoplotlib, an open-source python toolbox for visualizing geographical data. geoplotlib supports the development of hardware-accelerated interactive visualizations in pure python, and provides implementations of dot maps, kernel density estimation, spatial graphs, Voronoi tesselation, shapefiles and many more common spatial visualizations. We describe geoplotlib design, functionalities and use cases.			arxiv	['Sune Lehmann', 'Jakob Eg Larsen']	53.0
154	Powerbox: A Python package for creating structured fields with isotropic power spectra	Steven G. Murray	2018-08-27 00:21:57	http://arxiv.org/abs/1809.05030v1	Powerbox is a pure-Python package for creating and measuring structured fields with homogeneous and isotropic power spectra.			arxiv	[]	54.0
155	TimeGym: Debugging for Time Series Modeling in Python	Diogo Seca	2021-05-04 10:36:29	http://arxiv.org/abs/2105.01404v1	We introduce the TimeGym Forecasting Debugging Toolkit, a Python library for testing and debugging time series forecasting pipelines. TimeGym simplifies the testing forecasting pipeline by providing generic tests for forecasting pipelines fresh out of the box. These tests are based on common modeling challenges of time series. Our library enables forecasters to apply a Test-Driven Development approach to forecast modeling, using specified oracles to generate artificial data with noise.			arxiv	[]	55.0
156	MontePython: Implementing Quantum Monte Carlo using Python	J. K. Nilsen	2006-09-22 12:42:42	http://arxiv.org/abs/physics/0609191v1	We present a cross-language C++/Python program for simulations of quantum mechanical systems with the use of Quantum Monte Carlo (QMC) methods. We describe a system for which to apply QMC, the algorithms of variational Monte Carlo and diffusion Monte Carlo and we describe how to implement theses methods in pure C++ and C++/Python. Furthermore we check the efficiency of the implementations in serial and parallel cases to show that the overhead using Python can be negligible.			arxiv	[]	56.0
157	HOOMD-blue: A Python package for high-performance molecular dynamics and hard particle Monte Carlo simulations	Joshua A. Anderson	2013-08-26 13:56:04	http://arxiv.org/abs/1308.5587v2	HOOMD-blue is a particle simulation engine designed for nano- and colloidal-scale molecular dynamics and hard particle Monte Carlo simulations. It has been actively developed since March 2007 and available open source since August 2008. HOOMD-blue is a Python package with a high performance C++/CUDA backend that we built from the ground up for GPU acceleration. The Python interface allows users to combine HOOMD-blue with with other packages in the Python ecosystem to create simulation and analysis workflows. We employ software engineering practices to develop, test, maintain, and expand the code.			arxiv	['Jens Glaser', 'Sharon C. Glotzer']	57.0
158	Plyades: A Python Library for Space Mission Design	Helge Eichhorn	2016-07-01 18:53:15	http://arxiv.org/abs/1607.00849v1	Plyades: A Python Library for Space Mission Design Designing a space mission is a computation-heavy task. Software tools that conduct the necessary numerical simulations and optimizations are therefore indispensable. The usability of existing software, written in Fortran and MATLAB, suffers because of high complexity, low levels of abstraction and out-dated programming practices. We propose Python as a viable alternative for astrodynamics tools and demonstrate the proof-of-concept library Plyades which combines powerful features with Pythonic ease of use.			arxiv	['Reiner Anderl']	58.0
159	A Practical Python API for Querying AFLOWLIB	Conred W. Rosenbrock	2017-09-28 20:38:47	http://arxiv.org/abs/1710.00813v1	"Large databases such as aflowlib.org provide valuable data sources for discovering material trends through machine learning. Although a REST API and query language are available, there is a learning curve associated with the AFLUX language that acts as a barrier for new users. Additionally, the data is stored using non-standard serialization formats. Here we present a high-level API that allows immediate access to the aflowlib data using standard python operators and language features. It provides an easy way to integrate aflowlib data with other python materials packages such as ase and quippy, and provides automatic deserialization into numpy arrays and python objects. This package is available via ""pip install aflow""."			arxiv	[]	59.0
160	salmon: A Symbolic Linear Regression Package for Python	Alex Boyd	2019-11-02 04:42:28	http://arxiv.org/abs/1911.00648v3	One of the most attractive features of R is its linear modeling capabilities. We describe a Python package, salmon, that brings the best of R's linear modeling functionality to Python in a Pythonic way -- by providing composable objects for specifying and fitting linear models. This object-oriented design also enables other features that enhance ease-of-use, such as automatic visualizations and intelligent model building.			arxiv	['Dennis L. Sun']	60.0
161	pySiDR: Python Event Reconstruction for SiD	C. T. Potter	2020-02-13 22:43:25	http://arxiv.org/abs/2002.05804v1	Event reconstruction in the ILC community has typically relied on algorithms implemented in C++, a fast compiled language. However, the Python package pyLCIO provides a full interface to tracker and calorimeter hits stored in LCIO files, opening up the possibility to implement reconstruction algorithms in a language uniquely well suited to working with large lists of hits built with list comprehensions. Python, an interpreted language which can perform complex tasks with minimal code, also allows seamless integration with powerful machine learning tools developed recently. We discuss pySiDR, a Python package for SiD event reconstruction.			arxiv	[]	61.0
162	FitsGeo -- Python package for PHITS geometry development and visualization	Ivan Gordeev	2020-08-08 09:54:21	http://arxiv.org/abs/2008.03298v1	An easy way to define and visualize geometry for PHITS input files introduced. Suggested FitsGeo Python package helps to define surfaces as Python objects and manipulate them conveniently. VPython assists to view defined geometry interactively which boosts geometry development and helps with complicated cases. Every class that sets the surface object has methods with some extra properties. As well as geometry generation for PHITS input, additional modules developed for material and cell definition. Any user with a very basic knowledge of Python can define the geometry in a convenient way and use it in further research related to particle transport.			arxiv	[]	62.0
163	HDPython: A High Level Python Based Object-Oriented HDL Framework	R. Peschke	2020-11-05 02:43:50	http://arxiv.org/abs/2011.02626v2	We present a High-Level Python-based Hardware Description Language (HDPython), It uses Python as its source language and converts it to standard VHDL. Compared to other approaches of building converters from a high-level programming language into a hardware description language, this new approach aims to maintain an object-oriented paradigm throughout the entire process. Instead of removing all the high-level features from Python to make it into an HDL, this approach goes the opposite way. It tries to show how certain features from a high-level language can be implemented in an HDL, providing the corresponding benefits of high-level programming for the user.			arxiv	['K. Nishimura', 'G. Varner']	63.0
164	cellanneal: A User-Friendly Deconvolution Software for Omics Data	Lisa Buchauer	2021-10-15 17:14:58	http://arxiv.org/abs/2110.08209v1	We introduce cellanneal, a python-based software for deconvolving bulk RNA sequencing data. cellanneal relies on the optimization of Spearman's rank correlation coefficient between experimental and computational mixture gene expression vectors using simulated annealing. cellanneal can be used as a python package or via a command line interface, but importantly also provides a simple graphical user interface which is distributed as a single executable file for user convenience. The python package is available at https://github.com/LiBuchauer/cellanneal , the graphical software can be downloaded at http://shalevlab.weizmann.ac.il/resources .			arxiv	['Shalev Itzkovitz']	64.0
165	Asgl: A Python Package for Penalized Linear and Quantile Regression	√Ålvaro M√©ndez Civieta	2021-10-31 11:43:10	http://arxiv.org/abs/2111.00472v1	Asg is a Python package that solves penalized linear regression and quantile regression models for simultaneous variable selection and prediction, for both high and low dimensional frameworks. It makes very easy to set up and solve different types of lasso-based penalizations among which the asgl (adaptive sparse group lasso, that gives name to the package) is remarked. This package is built on top of cvxpy, a Python-embedded modeling language for convex optimization problems and makes extensive use of multiprocessing, a Python module for parallel computing that significantly reduces computation times of asgl.			arxiv	['M. Carmen Aguilera-Morillo', 'Rosa E. Lillo']	65.0
166	Scalpel: The Python Static Analysis Framework	Li Li	2022-02-24 00:27:56	http://arxiv.org/abs/2202.11840v1	Despite being the most popular programming language, Python has not yet received enough attention from the community. To the best of our knowledge, there is no general static analysis framework proposed to facilitate the implementation of dedicated Python static analyzers. To fill this gap, we design and implement such a framework (named Scalpel) and make it publicly available as an open-source project. The Scalpel framework has already integrated a number of fundamental static analysis functions (e.g., call graph constructions, control-flow graph constructions, alias analysis, etc.) that are ready to be reused by developers to implement client applications focusing on statically resolving dedicated Python problems such as detecting bugs or fixing vulnerabilities.			arxiv	['Jiawei Wang', 'Haowei Quan']	66.0
167	Modernizing the ESRF beamline application software architecture with generic Python modules	Jorg Klora	2002-10-16 13:27:22	http://arxiv.org/abs/cond-mat/0210344v1	We report on the modernization of the ESRF beamline application software with Python modules. The current building blocks used around the SPEC data acquisition software together with the new elements are presented.			arxiv	[]	67.0
168	Multi-Agent Programming Contest 2011 - The Python-DTU Team	J√∏rgen Villadsen	2011-10-01 15:03:52	http://arxiv.org/abs/1110.0105v1	We provide a brief description of the Python-DTU system, including the overall design, the tools and the algorithms that we plan to use in the agent contest.			arxiv	['Mikko Berggren Ettienne', 'Steen Vester']	68.0
169	Proceedings of the 7th European Conference on Python in Science (EuroSciPy 2014)	Pierre de Buyl	2014-12-22 15:47:51	http://arxiv.org/abs/1412.7030v1	These are the proceedings of the 7th European Conference on Python in Science, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).			arxiv	['Nelle Varoquaux']	69.0
170	PythonFOAM: In-situ data analyses with OpenFOAM and Python	Romit Maulik	2021-03-17 01:34:41	http://arxiv.org/abs/2103.09389v2	We outline the development of a general-purpose Python-based data analysis tool for OpenFOAM. Our implementation relies on the construction of OpenFOAM applications that have bindings to data analysis libraries in Python. Double precision data in OpenFOAM is cast to a NumPy array using the NumPy C-API and Python modules may then be used for arbitrary data analysis and manipulation on flow-field information. We highlight how the proposed wrapper may be used for an in-situ online singular value decomposition (SVD) implemented in Python and accessed from the OpenFOAM solver PimpleFOAM. Here, `in-situ' refers to a programming paradigm that allows for a concurrent computation of the data analysis on the same computational resources utilized for the partial differential equation solver. In addition, to demonstrate data-parallel analyses, we deploy a distributed SVD, which collects snapshot data across the ranks of a distributed simulation to compute the global left singular vectors. Crucially, both OpenFOAM and Python share the same message passing interface (MPI) communicator for this deployment which allows Python objects and functions to exchange NumPy arrays across ranks. Subsequently, we provide scaling assessments of this distributed SVD on multiple nodes of Intel Broadwell and KNL architectures for canonical test cases such as the large eddy simulations of a backward facing step and a channel flow at friction Reynolds number of 395. Finally, we demonstrate the deployment of a deep neural network for compressing the flow-field information using an autoencoder to demonstrate an ability to use state-of-the-art machine learning tools in the Python ecosystem.			arxiv	['Dimitrios Fytanidis', 'Bethany Lusch', 'Venkatram Vishwanath', 'Saumil Patel']	70.0
171	Proceedings of the 6th European Conference on Python in Science (EuroSciPy 2013)	Pierre de Buyl	2014-05-01 14:22:09	http://arxiv.org/abs/1405.0166v1	These are the proceedings of the 6th European Conference on Python in Science, EuroSciPy 2013, that was held in Brussels (21-25 August 2013).			arxiv	['Nelle Varoquaux']	71.0
172	Py-oopsi: the python implementation of the fast-oopsi algorithm	Benyuan Liu	2014-05-06 06:05:04	http://arxiv.org/abs/1405.6181v1	Fast-oopsi was developed by Joshua Vogelstein in 2009, which is now widely used to extract neuron spike activities from calcium fluorescence signals. Here, we propose detailed implementation of the fast-oopsi algorithm in python programming language. Some corrections are also made to the original fast-oopsi paper.			arxiv	[]	72.0
173	Python Crypto Misuses in the Wild	Anna-Katharina Wickert	2021-09-02 17:32:41	http://arxiv.org/abs/2109.01109v1	Background: Previous studies have shown that up to 99.59 % of the Java apps using crypto APIs misuse the API at least once. However, these studies have been conducted on Java and C, while empirical studies for other languages are missing. For example, a controlled user study with crypto tasks in Python has shown that 68.5 % of the professional developers write a secure solution for a crypto task. Aims: To understand if this observation holds for real-world code, we conducted a study of crypto misuses in Python. Method: We developed a static analysis tool that covers common misuses of 5 different Python crypto APIs. With this analysis, we analyzed 895 popular Python projects from GitHub and 51 MicroPython projects for embedded devices. Further, we compared our results with the findings of previous studies. Results: Our analysis reveals that 52.26 % of the Python projects have at least one misuse. Further, some Python crypto libraries API design helps developers from misusing crypto functions, which were much more common in studies conducted with Java and C code. Conclusion: We conclude that we can see a positive impact of the good API design on crypto misuses for Python applications. Further, our analysis of MicroPython projects reveals the importance of hybrid analyses.			arxiv	['Lars Baumg√§rtner', 'Florian Breitfelder', 'Mira Mezini']	73.0
174	An array-oriented Python interface for FastJet	Aryan Roy	2022-02-08 14:57:31	http://arxiv.org/abs/2202.03911v1	Analysis on HEP data is an iterative process in which the results of one step often inform the next. In an exploratory analysis, it is common to perform one computation on a collection of events, then view the results (often with histograms) to decide what to try next. Awkward Array is a Scikit-HEP Python package that enables data analysis with array-at-a-time operations to implement cuts as slices, combinatorics as composable functions, etc. However, most C++ HEP libraries, such as FastJet, have an imperative, one-particle-at-a-time interface, which would be inefficient in Python and goes against the grain of the array-at-a-time logic of scientific Python. Therefore, we developed fastjet, a pip-installable Python package that provides FastJet C++ binaries, the classic (particle-at-a-time) Python interface, and the new array-oriented interface for use with Awkward Array. The new interface streamlines interoperability with scientific Python software beyond HEP, such as machine learning. In one case, adopting this library along with other array-oriented tools accelerated HEP analysis code by a factor of 20. It was designed to be easily integrated with libraries in the Scikit-HEP ecosystem, including Uproot (file I/O), hist (histogramming), Vector (Lorentz vectors), and Coffea (high-level glue). We discuss the design of the fastjet Python library, integrating the classic interface with the array oriented interface and with the Vector library for Lorentz vector operations. The new interface was developed as open source.			arxiv	['Jim Pivarski', 'Chad Wells Freer']	74.0
175	Deep Learning: From Basics to Building Deep Neural Networks with Python	Milad Vazan	2022-04-22 11:57:19	http://arxiv.org/abs/2205.01069v1	This book is intended for beginners who have no familiarity with deep learning. Our only expectation from readers is that they already have the basic programming skills in Python.			arxiv	[]	75.0
176	The Awkward World of Python and C++	Manasvi Goyal	2023-03-03 20:33:50	http://arxiv.org/abs/2303.02205v1	There are undeniable benefits of binding Python and C++ to take advantage of the best features of both languages. This is especially relevant to the HEP and other scientific communities that have invested heavily in the C++ frameworks and are rapidly moving their data analyses to Python. Version 2 of Awkward Array, a Scikit-HEP Python library, introduces a set of header-only C++ libraries that do not depend on any application binary interface. Users can directly include these libraries in their compilation rather than linking against platform-specific libraries. This new development makes the integration of Awkward Arrays into other projects easier and more portable as the implementation is easily separable from the rest of the Awkward Array codebase. The code is minimal, it does not include all of the code needed to use Awkward Arrays in Python, nor does it include references to Python or pybind11. The C++ users can use it to make arrays and then copy them to Python without any specialized data types - only raw buffers, strings, and integers. This C++ code also simplifies the process of just-in-time (JIT) compilation in ROOT. This implementation approach solves some of the drawbacks, like packaging projects where native dependencies can be challenging. In this paper, we demonstrate the technique to integrate C++ and Python by using a header-only approach. We also describe the implementation of a new LayoutBuilder and a GrowableBuffer. Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposing Awkward Arrays to C++ without copying them are discussed.			arxiv	['Ianna Osborne', 'Jim Pivarski']	76.0
177	SlipCover: Near Zero-Overhead Code Coverage for Python	Juan Altmayer Pizzorno	2023-05-04 14:49:44	http://arxiv.org/abs/2305.02886v4	Coverage analysis is widely used but can suffer from high overhead. This overhead is especially acute in the context of Python, which is already notoriously slow (a recent study observes a roughly 30x slowdown vs. native code). We find that the state-of-the-art coverage tool for Python, coverage$.$py, introduces a median overhead of 180% with the standard Python interpreter. Slowdowns are even more extreme when using PyPy, a JIT-compiled Python implementation, with coverage$.$py imposing a median overhead of 1,300%. This performance degradation reduces the utility of coverage analysis in most use cases, including testing and fuzzing, and precludes its use in deployment. This paper presents SlipCover, a novel, near-zero overhead coverage analyzer for Python. SlipCover works without modifications to either the Python interpreter or PyPy. It first processes a program's AST to accurately identify all branches and lines. SlipCover then dynamically rewrites Python bytecodes to add lightweight instrumentation to each identified branch and line. At run time, SlipCover periodically de-instruments already-covered lines and branches. The result is extremely low overheads -- a median of just 5% -- making SlipCover suitable for use in deployment. We show its efficiency can translate to significant increases in the speed of coverage-based clients. As a proof of concept, we integrate SlipCover into TPBT, a targeted property-based testing system, and observe a 22x speedup.			arxiv	['Emery D Berger']	77.0
178	Cosmic Microwave Background Anisotropy Measurement From Python V	K. Coble	2001-12-21 01:09:38	http://arxiv.org/abs/astro-ph/0112506v2	We analyze observations of the microwave sky made with the Python experiment in its fifth year of operation at the Amundsen-Scott South Pole Station in Antarctica. After modeling the noise and constructing a map, we extract the cosmic signal from the data. We simultaneously estimate the angular power spectrum in eight bands ranging from large (l ~ 40) to small (l ~ 260) angular scales, with power detected in the first six bands. There is a significant rise in the power spectrum from large to smaller (l ~ 200) scales, consistent with that expected from acoustic oscillations in the early Universe. We compare this Python V map to a map made from data taken in the third year of Python. Python III observations were made at a frequency of 90 GHz and covered a subset of the region of the sky covered by Python V observations, which were made at 40 GHz. Good agreement is obtained both visually (with a filtered version of the map) and via a likelihood ratio test.			arxiv	['S. Dodelson', 'M. Dragovan', 'K. Ganga', 'L. Knox', 'J. Kovac', 'B. Ratra', 'T. Souradeep']	78.0
179	Solve the Master Equation by Python-An Introduction to the Python Computing Environment	Wei Fan	2011-03-02 00:46:20	http://arxiv.org/abs/1103.0325v4	A brief introduction to the Python computing environment is given. By solving the master equation encountered in quantum transport, we give an example of how to solve the ODE problems in Python. The ODE solvers used are the ZVODE routine in Scipy and the bsimp solver in GSL. For the former, the equation can be in its complex-valued form, while for the latter, it has to be rewritten to a real-valued form. The focus is on the detailed workflow of the implementation process, rather than on the syntax of the python language, with the hope to help readers simulate their own models in Python.			arxiv	['Yan Xu', 'Bing Chen', 'Qianqian Ye']	79.0
180	FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC libraries	Ashwin Vishnu Mohanan	2018-07-03 09:52:57	http://arxiv.org/abs/1807.01775v1	"The Python package fluidfft provides a common Python API for performing Fast Fourier Transforms (FFT) in sequential, in parallel and on GPU with different FFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFT framework which allows Python users to easily and efficiently perform FFT and the associated tasks, such as as computing linear operators and energy spectra. We describe the architecture of the package composed of C++ and Cython FFT classes, Python ""operator"" classes and Pythran functions. The package supplies utilities to easily test itself and benchmark the different FFT solutions for a particular case and on a particular machine. We present a performance scaling analysis on three different computing clusters and a microbenchmark showing that fluidfft is an interesting solution to write efficient Python applications using FFT."			arxiv	['Cyrille Bonamy', 'Pierre Augier']	80.0
181	Speeding simulation analysis up with yt and Intel Distribution for Python	Salvatore Cielo	2019-10-17 12:28:46	http://arxiv.org/abs/1910.07855v1	As modern scientific simulations grow ever more in size and complexity, even their analysis and post-processing becomes increasingly demanding, calling for the use of HPC resources and methods. yt is a parallel, open source post-processing python package for numerical simulations in astrophysics, made popular by its cross-format compatibility, its active community of developers and its integration with several other professional Python instruments. The Intel Distribution for Python enhances yt's performance and parallel scalability, through the optimization of lower-level libraries Numpy and Scipy, which make use of the optimized Intel Math Kernel Library (Intel-MKL) and the Intel MPI library for distributed computing. The library package yt is used for several analysis tasks, including integration of derived quantities, volumetric rendering, 2D phase plots, cosmological halo analysis and production of synthetic X-ray observation. In this paper, we provide a brief tutorial for the installation of yt and the Intel Distribution for Python, and the execution of each analysis task. Compared to the Anaconda python distribution, using the provided solution one can achieve net speedups up to 4.6x on Intel Xeon Scalable processors (codename Skylake).			arxiv	['Luigi Iapichino', 'Fabio Baruffa']	81.0
182	Scalene: Scripting-Language Aware Profiling for Python	Emery D. Berger	2020-06-06 14:43:09	http://arxiv.org/abs/2006.03879v2	"Existing profilers for scripting languages (a.k.a. ""glue"" languages) like Python suffer from numerous problems that drastically limit their usefulness. They impose order-of-magnitude overheads, report information at too coarse a granularity, or fail in the face of threads. Worse, past profilers---essentially variants of their counterparts for C---are oblivious to the fact that optimizing code in scripting languages requires information about code spanning the divide between the scripting language and libraries written in compiled languages. This paper introduces scripting-language aware profiling, and presents Scalene, an implementation of scripting-language aware profiling for Python. Scalene employs a combination of sampling, inference, and disassembly of byte-codes to efficiently and precisely attribute execution time and memory usage to either Python, which developers can optimize, or library code, which they cannot. It includes a novel sampling memory allocator that reports line-level memory consumption and trends with low overhead, helping developers reduce footprints and identify leaks. Finally, it introduces a new metric, copy volume, to help developers root out insidious copying costs across the Python/library boundary, which can drastically degrade performance. Scalene works for single or multi-threaded Python code, is precise, reporting detailed information at the line granularity, while imposing modest overheads (26%--53%)."			arxiv	[]	82.0
183	Extending Python for Quantum-Classical Computing via Quantum Just-in-Time Compilation	Thien Nguyen	2021-05-10 21:11:21	http://arxiv.org/abs/2105.04671v1	Python is a popular programming language known for its flexibility, usability, readability, and focus on developer productivity. The quantum software community has adopted Python on a number of large-scale efforts due to these characteristics, as well as the remote nature of near-term quantum processors. The use of Python has enabled quick prototyping for quantum code that directly benefits pertinent research and development efforts in quantum scientific computing. However, this rapid prototyping ability comes at the cost of future performant integration for tightly-coupled CPU-QPU architectures with fast-feedback. Here we present a language extension to Python that enables heterogeneous quantum-classical computing via a robust C++ infrastructure for quantum just-in-time (QJIT) compilation. Our work builds off the QCOR C++ language extension and compiler infrastructure to enable a single-source, quantum hardware-agnostic approach to quantum-classical computing that retains the performance required for tightly coupled CPU-QPU compute models. We detail this Pythonic extension, its programming model and underlying software architecture, and provide a robust set of examples to demonstrate the utility of our approach.			arxiv	['Alexander J. McCaskey']	83.0
184	An Empirical Study of Automated Unit Test Generation for Python	Stephan Lukasczyk	2021-11-09 08:54:33	http://arxiv.org/abs/2111.05003v2	Various mature automated test generation tools exist for statically typed programming languages such as Java. Automatically generating unit tests for dynamically typed programming languages such as Python, however, is substantially more difficult due to the dynamic nature of these languages as well as the lack of type information. Our Pynguin framework provides automated unit test generation for Python. In this paper, we extend our previous work on Pynguin to support more aspects of the Python language, and by studying a larger variety of well-established state of the art test-generation algorithms, namely DynaMOSA, MIO, and MOSA. Furthermore, we improved our Pynguin tool to generate regression assertions, whose quality we also evaluate. Our experiments confirm that evolutionary algorithms can outperform random test generation also in the context of Python, and similar to the Java world, DynaMOSA yields the highest coverage results. However, our results also demonstrate that there are still fundamental remaining issues, such as inferring type information for code without this information, currently limiting the effectiveness of test generation for Python.			arxiv	['Florian Kroi√ü', 'Gordon Fraser']	84.0
185	An Exploratory Study on the Predominant Programming Paradigms in Python Code	Robert Dyer	2022-09-05 08:03:20	http://arxiv.org/abs/2209.01817v1	Python is a multi-paradigm programming language that fully supports object-oriented (OO) programming. The language allows writing code in a non-procedural imperative manner, using procedures, using classes, or in a functional style. To date, no one has studied what paradigm(s), if any, are predominant in Python code and projects. In this work, we first define a technique to classify Python files into predominant paradigm(s). We then automate our approach and evaluate it against human judgements, showing over 80% agreement. We then analyze over 100k open-source Python projects, automatically classifying each source file and investigating the paradigm distributions. The results indicate Python developers tend to heavily favor OO features. We also observed a positive correlation between OO and procedural paradigms and the size of the project. And despite few files or projects being predominantly functional, we still found many functional feature uses.			arxiv	['Jigyasa Chauhan']	85.0
186	A Data Set of Generalizable Python Code Change Patterns	Akalanka Galappaththi	2023-04-11 04:59:26	http://arxiv.org/abs/2304.04983v1	Mining repetitive code changes from version control history is a common way of discovering unknown change patterns. Such change patterns can be used in code recommender systems or automated program repair techniques. While there are such tools and datasets exist for Java, there is little work on finding and recommending such changes in Python. In this paper, we present a data set of manually vetted generalizable Python repetitive code change patterns. We create a coding guideline to identify generalizable change patterns that can be used in automated tooling. We leverage the mined change patterns from recent work that mines repetitive changes in Python projects and use our coding guideline to manually review the patterns. For each change, we also record a description of the change and why it is applied along with other characteristics such as the number of projects it occurs in. This review process allows us to identify and share 72 Python change patterns that can be used to build and advance Python developer support tools.			arxiv	['Sarah Nadi']	86.0
187	Scalable Demand-Driven Call Graph Generation for Python	Yixuan Yan	2023-05-10 07:40:05	http://arxiv.org/abs/2305.05949v1	Call graph generation is the foundation of inter-procedural static analysis. PyCG is the state-of-the-art approach for generating call graphs for Python programs. Unfortunately, PyCG does not scale to large programs when adapted to whole-program analysis where dependent libraries are also analyzed. Further, PyCG does not support demand-driven analysis where only the reachable functions from given entry functions are analyzed. Moreover, PyCG is flow-insensitive and does not fully support Python's features, hindering its accuracy. To overcome these drawbacks, we propose a scalable demand-driven approach for generating call graphs for Python programs, and implement it as a prototype tool Jarvis. Jarvis maintains an assignment graph (i.e., points-to relations between program identifiers) for each function in a program to allow reuse and improve scalability. Given a set of entry functions as the demands, Jarvis generates the call graph on-the-fly, where flow-sensitive intra-procedural analysis and inter-procedural analysis are conducted in turn. Our evaluation on a micro-benchmark of 135 small Python programs and a macro-benchmark of 6 real-world Python applications has demonstrated that Jarvis can significantly improve PyCG by at least 67% faster in time, 84% higher in precision, and at least 10% higher in recall.			arxiv	['Kaifeng Huang', 'Bihuan Chen', 'Zixin Tao', 'Xin Peng']	87.0
188	Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for Tetrad Causal Search	Joseph D. Ramsey	2023-08-13 16:29:05	http://arxiv.org/abs/2308.07346v1	We give novel Python and R interfaces for the (Java) Tetrad project for causal modeling, search, and estimation. The Tetrad project is a mainstay in the literature, having been under consistent development for over 30 years. Some of its algorithms are now classics, like PC and FCI; others are recent developments. It is increasingly the case, however, that researchers need to access the underlying Java code from Python or R. Existing methods for doing this are inadequate. We provide new, up-to-date methods using the JPype Python-Java interface and the Reticulate Python-R interface, directly solving these issues. With the addition of some simple tools and the provision of working examples for both Python and R, using JPype and Reticulate to interface Python and R with Tetrad is straightforward and intuitive.			arxiv	['Bryan Andrews']	88.0
189	High performance Python for direct numerical simulations of turbulent flows	Mikael Mortensen	2016-02-11 08:12:37	http://arxiv.org/abs/1602.03638v1	Direct Numerical Simulations (DNS) of the Navier Stokes equations is an invaluable research tool in fluid dynamics. Still, there are few publicly available research codes and, due to the heavy number crunching implied, available codes are usually written in low-level languages such as C/C++ or Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS code that nearly matches the performance of C++ for thousands of processors and billions of unknowns. We also describe a version optimized through Cython, that is found to match the speed of C++. The solvers are written from scratch in Python, both the mesh, the MPI domain decomposition, and the temporal integrators. The solvers have been verified and benchmarked on the Shaheen supercomputer at the KAUST supercomputing laboratory, and we are able to show very good scaling up to several thousand cores. A very important part of the implementation is the mesh decomposition (we implement both slab and pencil decompositions) and 3D parallel Fast Fourier Transforms (FFT). The mesh decomposition and FFT routines have been implemented in Python using serial FFT routines (either NumPy, pyFFTW or any other serial FFT module), NumPy array manipulations and with MPI communications handled by MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT in Python for a slab mesh decomposition using 4 lines of compact Python code, for which the parallel performance on Shaheen is found to be slightly better than similar routines provided through the FFTW library. For a pencil mesh decomposition 7 lines of code is required to execute a transform.			arxiv	['Hans Petter Langtangen']	89.0
190	PyCG: Practical Call Graph Generation in Python	Vitalis Salis	2021-02-28 18:49:25	http://arxiv.org/abs/2103.00587v1	"Call graphs play an important role in different contexts, such as profiling and vulnerability propagation analysis. Generating call graphs in an efficient manner can be a challenging task when it comes to high-level languages that are modular and incorporate dynamic features and higher-order functions. Despite the language's popularity, there have been very few tools aiming to generate call graphs for Python programs. Worse, these tools suffer from several effectiveness issues that limit their practicality in realistic programs. We propose a pragmatic, static approach for call graph generation in Python. We compute all assignment relations between program identifiers of functions, variables, classes, and modules through an inter-procedural analysis. Based on these assignment relations, we produce the resulting call graph by resolving all calls to potentially invoked functions. Notably, the underlying analysis is designed to be efficient and scalable, handling several Python features, such as modules, generators, function closures, and multiple inheritance. We have evaluated our prototype implementation, which we call PyCG, using two benchmarks: a micro-benchmark suite containing small Python programs and a set of macro-benchmarks with several popular real-world Python packages. Our results indicate that PyCG can efficiently handle thousands of lines of code in less than a second (0.38 seconds for 1k LoC on average). Further, it outperforms the state-of-the-art for Python in both precision and recall: PyCG achieves high rates of precision ~99.2%, and adequate recall ~69.9%. Finally, we demonstrate how PyCG can aid dependency impact analysis by showcasing a potential enhancement to GitHub's ""security advisory"" notification service using a real-world example."			arxiv	['Thodoris Sotiropoulos', 'Panos Louridas', 'Diomidis Spinellis', 'Dimitris Mitropoulos']	90.0
191	PyArmadillo: a streamlined linear algebra library for Python	Jason Rumengan	2021-04-22 15:13:33	http://arxiv.org/abs/2104.11120v4	PyArmadillo is a linear algebra library for the Python language, with the aim of closely mirroring the programming interface of the widely used Armadillo C++ library, which in turn is deliberately similar to Matlab. PyArmadillo hence facilitates algorithm prototyping with Matlab-like syntax directly in Python, and relatively straightforward conversion of PyArmadillo-based Python code into performant Armadillo-based C++ code. The converted code can be used for purposes such as speeding up Python-based programs in conjunction with pybind11, or the integration of algorithms originally prototyped in Python into larger C++ codebases. PyArmadillo provides objects for matrices and cubes, as well as over 200 associated functions for manipulating data stored in the objects. Integer, floating point and complex numbers are supported. Various matrix factorisations are provided through integration with LAPACK, or one of its high performance drop-in replacements such as Intel MKL or OpenBLAS. PyArmadillo is open-source software, distributed under the Apache 2.0 license; it can be obtained at https://pyarma.sourceforge.io or via the Python Package Index in precompiled form.			arxiv	['Terry Yue Zhuo', 'Conrad Sanderson']	91.0
192	Python for Smarter Cities: Comparison of Python libraries for static and interactive visualisations of large vector data	Gregor Herda	2022-02-26 10:23:29	http://arxiv.org/abs/2202.13105v1	Local governments, as part of 'smart city' initiatives and to promote interoperability, are increasingly incorporating open-source software into their data management, analysis, and visualisation workflows. Python, with its concise and natural syntax, presents a low barrier to entry for municipal staff without computer science backgrounds. However, with regard to geospatial visualisations in particular, the range of available Python libraries has diversified to such an extent that identifying candidate libraries for specific use cases is a challenging undertaking. This study therefore assesses prominent, actively-developed visualisation libraries in the Python ecosystem with respect to their suitability for producing visualisations of large vector datasets. A simple visualisation task common in urban development is used to produce near-identical thematic maps across static and an interactive 'tracks' of comparison. All short-listed libraries were able to generate the sample map products for both a small and larger dataset. Code complexity differed more strongly for interactive visualisations. Formal and informal documentation channels are highlighted to outline available resources for flattening learning curves. CPU runtimes for the Python-based portion of the process chain differed starkly for both tracks, pointing to avenues for further research. These results demonstrate that the Python ecosystem offers local governments powerful tools, free of vendor lock-in and licensing fees, to produce performant and consistently formatted visualisations for both internal and public distribution.			arxiv	['Robert McNabb']	92.0
193	An Empirical Study of Fault Localization in Python Programs	Mohammad Rezaalipour	2023-05-31 13:21:30	http://arxiv.org/abs/2305.19834v2	Despite its massive popularity as a programming language, especially in novel domains like data science programs, there is comparatively little research about fault localization that targets Python. Even though it is plausible that several findings about programming languages like C/C++ and Java -- the most common choices for fault localization research -- carry over to other languages, whether the dynamic nature of Python and how the language is used in practice affect the capabilities of classic fault localization approaches remain open questions to investigate. This paper is the first large-scale empirical study of fault localization on real-world Python programs and faults. Using Zou et al.'s recent large-scale empirical study of fault localization in Java as the basis of our study, we investigated the effectiveness (i.e., localization accuracy), efficiency (i.e., runtime performance), and other features (e.g., different entity granularities) of seven well-known fault-localization techniques in four families (spectrum-based, mutation-based, predicate switching, and stack-trace based) on 135 faults from 13 open-source Python projects from the BugsInPy curated collection. The results replicate for Python several results known about Java, and shed light on whether Python's peculiarities affect the capabilities of fault localization. The replication package that accompanies this paper includes detailed data about our experiments, as well as the tool FauxPy that we implemented to conduct the study.			arxiv	['Carlo A. Furia']	93.0
194	Does Python Smell Like Java? Tool Support for Design Defect Discovery in Python	Nicole Vavrov√°	2017-03-31 12:47:50	http://arxiv.org/abs/1703.10882v1	The context of this work is specification, detection and ultimately removal of detectable harmful patterns in source code that are associated with defects in design and implementation of software. In particular, we investigate five code smells and four antipatterns previously defined in papers and books. Our inquiry is about detecting those in source code written in Python programming language, which is substantially different from all prior research, most of which concerns Java or C-like languages. Our approach was that of software engineers: we have processed existing research literature on the topic, extracted both the abstract definitions of nine design defects and their concrete implementation specifications, implemented them all in a tool we have programmed and let it loose on a huge test set obtained from open source code from thousands of GitHub projects. When it comes to knowledge, we have found that more than twice as many methods in Python can be considered too long (statistically extremely longer than their neighbours within the same project) than in Java, but long parameter lists are seven times less likely to be found in Python code than in Java code. We have also found that Functional Decomposition, the way it was defined for Java, is not found in the Python code at all, and Spaghetti Code and God Classes are extremely rare there as well. The grounding and the confidence in these results comes from the fact that we have performed our experiments on 32'058'823 lines of Python code, which is by far the largest test set for a freely available Python parser. We have also designed the experiment in such a way that it aligned with prior research on design defect detection in Java in order to ease the comparison if we treat our own actions as a replication. Thus, the importance of the work is both in the unique open Python grammar of highest quality, tested on millions of lines of code, and in the design defect detection tool which works on something else than Java.			arxiv	['Vadim Zaytsev']	94.0
195	Python I, II, and III CMB Anisotropy Measurement Constraints on Open and Flat-Lambda CDM Cosmogonies	Graca Rocha	1999-05-11 18:16:35	http://arxiv.org/abs/astro-ph/9905127v1	We use Python I, II, and III cosmic microwave background anisotropy data to constrain cosmogonies. We account for the Python beamwidth and calibration uncertainties. We consider open and spatially-flat-Lambda cold dark matter cosmogonies, with nonrelativistic-mass density parameter Omega_0 in the range 0.1--1, baryonic-mass density parameter Omega_B in the range (0.005--0.029) h^{-2}, and age of the universe t_0 in the range (10--20) Gyr. Marginalizing over all parameters but Omega_0, the combined Python data favors an open (spatially-flat-Lambda) model with Omega_0 simeq 0.2 (0.1). At the 2 sigma confidence level model normalizations deduced from the combined Python data are mostly consistent with those drawn from the DMR, UCSB South Pole 1994, ARGO, MAX 4 and 5, White Dish, and SuZIE data sets.			arxiv	['Radoslaw Stompor', 'Ken Ganga', 'Bharat Ratra', 'Stephen R. Platt', 'Naoshi Sugiyama', 'Krzysztof M. Gorski']	95.0
196	PyNetMet: Python tools for efficient work with networks and metabolic models	D. Gamermann	2012-11-30 09:25:06	http://arxiv.org/abs/1211.7196v1	Background: The study of genome-scale metabolic models and their underlying networks is one of the most important fields in systems biology. The complexity of these models and their description makes the use of computational tools an essential element in their research. Therefore there is a strong need of efficient and versatile computational tools for the research in this area. Results: In this manuscript we present PyNetMet, a Python library of tools to work with networks and metabolic models. These are open-source free tools for use in a Python platform, which adds considerably versatility to them when compared with their desktop software similars. On the other hand these tools allow one to work with different standards of metabolic models (OptGene and SBML) and the fact that they are programmed in Python opens the possibility of efficient integration with any other already existing Python tool. Conclusions: PyNetMet is, therefore, a collection of computational tools that will facilitate the research work with metabolic models and networks.			arxiv	['A. Montagud', 'R. A. Jaime Infante', 'J. Triana', 'P. F. de C√≥rdoba', 'J. F. Urchuegu√≠a']	96.0
197	A Python-based Post-processing Toolset For Seismic Analyses	Steve Brasier	2014-12-19 16:09:16	http://arxiv.org/abs/1412.6410v1	This paper discusses the design and implementation of a Python-based toolset to aid in assessing the response of the UK's Advanced Gas Reactor nuclear power stations to earthquakes. The seismic analyses themselves are carried out with a commercial Finite Element solver, but understanding the raw model output this produces requires customised post-processing and visualisation tools. Extending the existing tools had become increasingly difficult and a decision was made to develop a new, Python-based toolset. This comprises of a post-processing framework (aftershock) which includes an embedded Python interpreter, and a plotting package (afterplot) based on numpy and matplotlib. The new toolset had to be significantly more flexible and easier to maintain than the existing code-base, while allowing the majority of development to be carried out by engineers with little training in software development. The resulting architecture will be described with a focus on exploring how the design drivers were met and the successes and challenges arising from the choices made.			arxiv	['Fred Pollard']	97.0
198	Rabacus: A Python Package for Analytic Cosmological Radiative Transfer Calculations	Gabriel Altay	2015-02-10 07:03:42	http://arxiv.org/abs/1502.02798v2	We describe Rabacus, a Python package for calculating the transfer of hydrogen ionizing radiation in simplified geometries relevant to astronomy and cosmology. We present example solutions for three specific cases: 1) a semi-infinite slab gas distribution in a homogeneous isotropic background, 2) a spherically symmetric gas distribution with a point source at the center, and 3) a spherically symmetric gas distribution in a homogeneous isotropic background. All problems can accommodate arbitrary spectra and density profiles as input. The solutions include a treatment of both hydrogen and helium, a self-consistent calculation of equilibrium temperatures, and the transfer of recombination radiation. The core routines are written in Fortran 90 and then wrapped in Python leading to execution speeds thousands of times faster than equivalent routines written in pure Python. In addition, all variables have associated units for ease of analysis. The software is part of the Python Package Index and the source code is available on Bitbucket at https://bitbucket.org/galtay/rabacus . In addition, installation instructions and a detailed users guide are available at http://pythonhosted.org//rabacus .			arxiv	['John Wise']	98.0
199	Weighted graph algorithms with Python	A. Kapanowski	2015-04-29 12:20:20	http://arxiv.org/abs/1504.07828v1	Python implementation of selected weighted graph algorithms is presented. The minimal graph interface is defined together with several classes implementing this interface. Graph nodes can be any hashable Python objects. Directed edges are instances of the Edge class. Graphs are instances of the Graph class. It is based on the adjacency-list representation, but with fast lookup of nodes and neighbors (dict-of-dict structure). Other implementations of this class are also possible. In this work, many algorithms are implemented using a unified approach. There are separate classes and modules devoted to different algorithms. Three algorithms for finding a minimum spanning tree are implemented: the Boruvka's algorithm, the Prim's algorithm (three implementations), and the Kruskal's algorithm. Three algorithms for solving the single-source shortest path problem are implemented: the dag shortest path algorithm, the Bellman-Ford algorithm, and the Dijkstra's algorithm (two implementations). Two algorithms for solving all-pairs shortest path problem are implemented: the Floyd-Warshall algorithm and the Johnson's algorithm. All algorithms were tested by means of the unittest module, the Python unit testing framework. Additional computer experiments were done in order to compare real and theoretical computational complexity. The source code is available from the public GitHub repository.			arxiv	['≈Å. Ga≈Çuszka']	99.0
