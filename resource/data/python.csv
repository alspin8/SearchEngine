	title	author	date	url	text	comment_count	fullname	type	co_authors	api_index
0	Sunday Daily Thread: What's everyone working on this week?	Unknown	2024-01-07 00:00:09	https://www.reddit.com/r/Python/comments/190e683/sunday_daily_thread_whats_everyone_working_on/	# Weekly Thread: What's Everyone Working On This Week? 🛠️ Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to! ## How it Works: 1. **Show & Tell**: Share your current projects, completed works, or future ideas. 2. **Discuss**: Get feedback, find collaborators, or just chat about your project. 3. **Inspire**: Your project might inspire someone else, just as you might get inspired here. ## Guidelines: * Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome. * Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here. ## Example Shares: 1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate! 2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better. 3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier! Let's build and grow together! Share your journey and learn from others. Happy coding! 🌟	11.0	t3_190e683	reddit		
1	Wednesday Daily Thread: Beginner questions	Unknown	2024-01-10 00:00:08	https://www.reddit.com/r/Python/comments/192tx0l/wednesday_daily_thread_beginner_questions/	# Weekly Thread: Beginner Questions 🐍 Welcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you. ## How it Works: 1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here! 2. **Community Support**: Get answers and advice from the community. 3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources. ## Guidelines: * This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link). ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **What is the difference between a list and a tuple?** 2. **How do I read a CSV file in Python?** 3. **What are Python decorators and how do I use them?** 4. **How do I install a Python package using pip?** 5. **What is a virtual environment and why should I use one?** Let's help each other learn Python! 🌟	2.0	t3_192tx0l	reddit		
2	PEP 736 – Shorthand syntax for keyword arguments at invocation	Unknown	2024-01-10 09:50:22	https://www.reddit.com/r/Python/comments/1934p64/pep_736_shorthand_syntax_for_keyword_arguments_at/	"A new PEP has been posted: https://peps.python.org/pep-0736/ It proposes to introduce the syntax: year = 1982 title = ""Blade Runner"" director = ""Ridley Scott"" func(year=, title=, director=) As shorthand for: func(year=year, title=title, director=director) So, if variable name and keyword argument name are identical, you wouldn't need to repeat it with the new proposed syntax."	43.0	t3_1934p64	reddit		
3	Why hardware providers never provide APIs or code samples in Python?	Unknown	2024-01-10 06:25:56	https://www.reddit.com/r/Python/comments/1931p64/why_hardware_providers_never_provide_apis_or_code/	Why hardware companies never provide an API in Python ? I'm currently working on a Kiosk machine project that'll have to deal with a bill acceptor, bill despinser and some other serial port hardware. They always provide C# and/or C++ dll and Java code samples and API packages. But never anything for Python. Does anyone have a clue why is that and if it possible to somehow use those C++ dlls in my Python code. Thanks in advance.	11.0	t3_1931p64	reddit		
4	NumPy 2 is coming: preventing breakage, updating your code	Unknown	2024-01-09 20:55:23	https://www.reddit.com/r/Python/comments/192pccr/numpy_2_is_coming_preventing_breakage_updating/	NumPy 2 is a new major release, with a release candidate coming out February 1st 2024, and a final release a month or two later. Importantly, it’s backwards incompatible; not in a major way, but enough that some work [https://pythonspeed.com/articles/numpy-2/](https://pythonspeed.com/articles/numpy-2/) &#x200B;	9.0	t3_192pccr	reddit		
5	Breaking news: Python 3.13 gets a JIT compiler that will enable big optimizations in the future.	Unknown	2024-01-09 09:50:07	https://www.reddit.com/r/Python/comments/192b53m/breaking_news_python_313_gets_a_jit_compiler_that/	Exciting news here: https://tonybaloney.github.io/posts/python-gets-a-jit.html This is just the first step for Python to enable optimizations not possible now. Do not expect much from it since this is a first step to optimization. In the future this JIT will enable further performance improvements not possible now.	15.0	t3_192b53m	reddit		
6	Annotating args and kwargs in Python	Unknown	2024-01-09 12:21:46	https://www.reddit.com/r/Python/comments/192di4j/annotating_args_and_kwargs_in_python/	I tend to avoid *args and **kwargs in Python as they often obscure public APIs. But I'm glad that it's now at least possible to annotate them somewhat precisely. https://rednafi.com/python/annotate_args_and_kwargs/	8.0	t3_192di4j	reddit		
7	Vine Archiver 2.0 [Python]	Unknown	2024-01-10 00:10:50	https://www.reddit.com/r/Python/comments/192u67e/vine_archiver_20_python/	I created this tool to archive any vine account/user possible. https://github.com/Ghosty-Tongue/Vine-Archiver-2.0	1.0	t3_192u67e	reddit		
8	State pattern in Python in Todoist -> Habitica One Way Sync app	Unknown	2024-01-09 16:40:40	https://www.reddit.com/r/Python/comments/192iz5b/state_pattern_in_python_in_todoist_habitica_one/	Hello fellow Pythonistas.A few years ago, I created a tool for myself in Python for scoring points in [Habitica](https://habitica.com/) from completed task in [Todoist](https://todoist.com). I really like both tools but I wanted to keep track of tasks only in one place (preferably Todoist). At the end of last year, I got the tool to a state, where it was not an utter embarrassment and would like to share it with everyone. Even if you're not familiar with either of the tools, you might be still interested in seeing an implementation of the [State](https://refactoring.guru/design-patterns/state) design pattern [in the wild](https://github.com/radeklat/todoist-habitica-sync/blob/main/src/main.py). One of the unfortunate side-effects of using this pattern in Python is the bi-directional import of both the State and the Context. Which leads to everything being in one file to avoid import cycles. Please see [Todoist Habitica Sync on GitHub](https://github.com/radeklat/todoist-habitica-sync) for more information about the tool and usage/installation instructions. If you'll use it and/or like it, please consider giving it a star on GitHub 🙏	0.0	t3_192iz5b	reddit		
9	The biggest leap forward for HTTP clients in years	Unknown	2024-01-09 14:43:13	https://www.reddit.com/r/Python/comments/192g9bl/the_biggest_leap_forward_for_http_clients_in_years/	"If I would enumerate to you: - HTTP/2 by default - HTTP/3 - DNS over HTTPS, DNS over QUIC, DNS over TLS - OS truststore, trust your operating system, not Certifi, e.g. no more custom CA bundle to inject when working at a company - OCSP Certificate Revocation Verification - In-memory certificates (CAs, and mTLS) - Network settings fine-tuning, liberty to choose IPv4, IPv6, protocols, interface to bind to, ... - Advanced connection timings inspection - Multiplexed Connection - DNSSEC! - Async ... And more. would you be able to leverage all of those with ease? ```python import niquests responses = [] with niquests.Session(resolver=""doh+google://"", multiplexed=True, disable_ipv6=True) as s: responses.append(s.get(""https://pie.dev/delay/1"")) responses.append(s.get(""https://pie.dev/delay/1"")) print(responses) s.gather() print(responses) ``` _This piece of code takes 1 second to fetch those two requests. In the given beat, resolve hostname using DNS-over-HTTPS, exclude IPv6, negotiates http3 in a flash, in a pure synchronous context, without async, without thread, and with a single connection._ Trying to be able to leverage those aspects without a consequent effort is impossible. Requests spirit should have endured. Meaning ease of use, high level client, no need to re learn everything or at least partially. ```python import niquests import asyncio async def main() -> None: async with niquests.AsyncSession(resolver=""doh+google://"") as s: r = await s.get(""https://pie.dev/delay/1"") print(r) if __name__ == ""__main__"": asyncio.run(main()) ``` Everything showcased here is already available, on the reach of: **One click, one command, and one CTRL+H. Literally.** - Source: [github.com/jawah/niquests](https://github.com/jawah/niquests) - Documentation: [niquests.readthedocs.io](https://niquests.readthedocs.io/en/latest/) - Live Demo: [replit.com/niquests](https://replit.com/@ahmedtahri4/Python#main.py) - Article: [10 reasons you should quit your HTTP client](https://medium.com/dev-genius/10-reasons-you-should-quit-your-http-client-98fd4c94bef3) For the ending note, Some of you may think: ""Oh that's great.. but [place reasoning here]"" Most of the time, the reasoning are: - Too few people uses it - Too few stars - I can't change, habits die hard For the two first cases, know that around 400 years ago, only a handful of scientists did have the courage to say that earth revolve around the sun. **The numbers do not lead to the truth.** As for the last one, it is a simple calculus of what do you gain versus the effort required to move, actually almost none, thanks to the backward compatibility with Requests. Finally, if you didn't see any reasons to act on it and remain where you are, know that your support to Niquests will benefit to you no matter what, encouraging competition on a _(very restricted)_ market almost always push them to do better."	9.0	t3_192g9bl	reddit		
10	Easiest Python Equivalent of MATLAB's App Designer?	Unknown	2024-01-09 12:51:45	https://www.reddit.com/r/Python/comments/192e0gj/easiest_python_equivalent_of_matlabs_app_designer/	I tend to use a lot of MATLAB for numerical modeling/signal processing purposes, and it's basically the standard in my field. But I also use a lot of Python where relevant and needed as well, mostly for ML purposes. I've started to churn out some Matlab apps via AppDesigner for visualization, but I'm feeling a bit limited and want something that's Python-based since I do ML in python. What would be an good place to start? I have decent Python knowledge and OOP principles, but I'd ideally like something that is relatively simple and won't require me to get into the weeds too much. (Not sure if this is a reasonable ask). I've been considering Python Shiny, but are there other things out there?	5.0	t3_192e0gj	reddit		
11	Visualizing Software Complexity with a 3D Force-Directed Graph	Unknown	2024-01-09 17:37:56	https://www.reddit.com/r/Python/comments/192ket2/visualizing_software_complexity_with_a_3d/	Hello everyone! I want to share a project for which Python support was just added recently: [https://github.com/gabotechs/dep-tree](https://github.com/gabotechs/dep-tree) This is a tool that allows users to visualize the complexity of a code base using a 3D force-directed graph: * It will take a Python executable/library's entrypoint and calculate it's dependencies based on the import statements. * It will recursively crawl the import statements looking for more import statements in the imported files, building recursively a file dependency graph. * It will render the graph using a force-directed layout, and all the crawled files will be placed in a three-dimensional space simulating some attraction/repulsion forces based on the dependencies between them. * There's already some samples using well known open-source projects that are quite surprising: * [langchain](https://dep-tree-explorer.vercel.app/api?repo=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flangchain&entrypoint=libs%2Flangchain%2Flangchain%2F__init__.py) * [tensorflow](https://dep-tree-explorer.vercel.app/api?repo=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow&entrypoint=tensorflow%2Fpython%2Fkeras%2Fmodels.py) * [numpy](https://dep-tree-explorer.vercel.app/api?repo=https%3A%2F%2Fgithub.com%2Fnumpy%2Fnumpy&entrypoint=numpy%2F__init__.py) * [pytorch](https://dep-tree-explorer.vercel.app/api?repo=https%3A%2F%2Fgithub.com%2Fpytorch%2Fpytorch&entrypoint=torch%2Fnn%2F__init__.py) I wrote a blog post about it if you want to dive deeper: [link](https://dev.to/gabotechs/about-software-complexity-569d) Hope you liked it!	0.0	t3_192ket2	reddit		
12	Polars now has a pola-rs/polars-xdt repository	:pandas_Logo: pandas Core Dev 	2024-01-09 12:02:41	https://www.reddit.com/r/Python/comments/192d6k5/polars_now_has_a_polarspolarsxdt_repository/	The main Polars repository has \`.dt.\` namespace with basic datetime functionality. There's now another repository in the pola-rs GitHub org [https://github.com/pola-rs/polars-xdt](https://github.com/pola-rs/polars-xdt) which contains a plugin with some extra datetime functionality in a \`.xdt\` namespace It contains (and will contains) useful datetime functionality (e.g. \`to\_julian\_date\` / business day arithmetic / \`strftime\` with different locales) which doesn't quite fit into the main Polars repository. (This was previously \`polars-business\`, but the scope has been expanded and brought into the Polars org)	0.0	t3_192d6k5	reddit		
13	UltiBI quick and easy Pivot Tables UI	Unknown	2024-01-09 08:50:42	https://www.reddit.com/r/Python/comments/192aaxm/ultibi_quick_and_easy_pivot_tables_ui/	"# Quick and easy way to create pivot tables, filter, override, and group data without writing any code. Checkout [utiBI](https://github.com/ultima-ib/ultima). Comes with a comprehensive [userguide](https://ultimabi.uk/ultibi-frtb-book/). ```shell pip install ultibi ``` ```python import ultibi as ul import polars as pl df = pl.read_csv(""titanic.csv"") ds = ul.DataSet.from_frame(df) ds.ui() ``` Built for production usage, it delivers an ergonomic Python API leveraging on Typescript, Rust's Polars and Actix. In addition, you can: * Define your own Aggregations in Python or Rust. * Load data from a DataFrame or DataBase. pyhton pivot pivottable polars rust"	0.0	t3_192aaxm	reddit		
14	Why Python is slow and how to make it faster	Unknown	2024-01-08 08:39:19	https://www.reddit.com/r/Python/comments/191gmtm/why_python_is_slow_and_how_to_make_it_faster/	As there was a recent discussion on Python's speed, here is a collection of some good articles discussing about Python's speed and why it poses extra challenges to be fast as CPU instructions/executed code. * Pycon talk: [Anthony Shaw - Why Python is slow](https://www.youtube.com/watch?v=I4nkgJdVZFA) * Pycon talk: [Mark Shannon - How we are making CPython faster](https://www.youtube.com/watch?v=wyty6sFMWI0) * [Python 3.13 will ship with --enable-jit, --disable-gil](https://twitter.com/anthonypjshaw/status/1744144186478375373) * [Python performance: it’s not just the interpreter](https://blog.kevmod.com/2020/05/19/python-performance-its-not-just-the-interpreter/) * [Cinder: Instagram's performance-oriented Python fork](https://twitter.com/anthonypjshaw/status/1744144186478375373) Also remember, the raw CPU speed rarely matters, as many workloads are IO-bound, network-bound, or a performance question is irrelevant... or: Python trades some software development cost for increased hardware cost. In these cases, Python extensions and specialised libraries can do the heavy lifting outside the interpreter (PyArrow, Polards, Pandas, Numba, etc.).	27.0	t3_191gmtm	reddit		
15	Python Web3 Development #1 - Building dApps with Python	Unknown	2024-01-09 13:39:10	https://www.reddit.com/r/Python/comments/192ewzp/python_web3_development_1_building_dapps_with/	Hi everyone! Sharing this tutorial series kickstarted by Tech with Tim, in which he'll walk us all through building dApps with Python and Cartesi, for any Python devs figuring out their way into blockchain development. This is how we can port our code onto the blockchain and build dApps with off-chain verifiable execution without complexities or the need for Solidity. Check this out and feel free to share your thoughts! Is this series something you’d be interested in following? https://youtu.be/tE-8bG35VNw?si=sVESb9Ioz84TKd3p	1.0	t3_192ewzp	reddit		
16	SQLAlchemy Migrations: Goodbye, Alembic. Hello, Atlas	Unknown	2024-01-08 13:08:54	https://www.reddit.com/r/Python/comments/191kuqx/sqlalchemy_migrations_goodbye_alembic_hello_atlas/	Hey Everyone It's been a few years since I last posted here. I wanted to share a very cool project my team has been cooking over the last couple of weeks that I think you might find interesting. **tl;dr** [Atlas](https://atlasgo.io) is a database schema-as-code tool (like Terraform for Databases), you can now use Atlas to automatically manage your SQLAlchemy database schemas. If you're interested in how here's [the guide](https://atlasgo.io/guides/orms/sqlalchemy). **wait, but why** Alembic is a fine migration tool (actually way better than what's available in most languages) - so why build an alternative? Alembic, contrary to many migration tools, does a fairly decent job of automatic migration planning. Having used it in the past, I was always annoyed by a few facts: 1. It does not cover many cases ([docs](https://alembic.sqlalchemy.org/en/latest/autogenerate.html#what-does-autogenerate-detect-and-what-does-it-not-detect)) 2. It requires a connection to a database that contains the *current schema* to 3. It does not support many database objects 4. I wanted one tool for many teams (regardless of which programming lang they use) In addition, many things are out of scope for an ORM migration tool: Terraform, Kubernetes, CI for detecting risky changes, etc. We tried to address all of these + some more with Atlas **feedback** If you try it out, I would love to get your thoughts and feedback on this.	11.0	t3_191kuqx	reddit		
17	Build CLIs as wheels	Unknown	2024-01-08 15:35:23	https://www.reddit.com/r/Python/comments/191nvo1/build_clis_as_wheels/	I built a small tool that can be used as CLI or SDK. It allows you to distribute any binary (preferably CLIs) as a wheel. This way you can easily reference and integrate external tools in your scripts and tooling. Simply installing a python package. It also provides you with a wrapper package so you can use it right away with subprocess wrapped inside. Working example can be found in https://github.com/timo-reymann/deterministic-zip :) https://github.com/timo-reymann/python-binary-wheel-builder	3.0	t3_191nvo1	reddit		
18	Data Structures and Information Retrieval	Unknown	2024-01-09 10:58:31	https://www.reddit.com/r/Python/comments/192c51v/data_structures_and_information_retrieval/	Data Structures and Information Retrieval in Python is an introduction to data structures and algorithms using a web search engine as a motivating example. It is based in part on Think Data Structures, which uses Java. [https://allendowney.github.io/DSIRP/](https://allendowney.github.io/DSIRP/) &#x200B;	0.0	t3_192c51v	reddit		
19	Tuesday Daily Thread: Advanced questions	Unknown	2024-01-09 00:00:09	https://www.reddit.com/r/Python/comments/1920avu/tuesday_daily_thread_advanced_questions/	# Weekly Wednesday Thread: Advanced Questions 🐍 Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices. ## How it Works: 1. **Ask Away**: Post your advanced Python questions here. 2. **Expert Insights**: Get answers from experienced developers. 3. **Resource Pool**: Share or discover tutorials, articles, and tips. ## Guidelines: * This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday. * Questions that are not advanced may be removed and redirected to the appropriate thread. ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **How can you implement a custom memory allocator in Python?** 2. **What are the best practices for optimizing Cython code for heavy numerical computations?** 3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?** 4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?** 5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?** 6. **What are some advanced use-cases for Python's decorators?** 7. **How can you achieve real-time data streaming in Python with WebSockets?** 8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?** 9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?** 10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)** Let's deepen our Python knowledge together. Happy coding! 🌟	0.0	t3_1920avu	reddit		
20	[WIP] Pyglet Pen, a GUI extension for Pyglet (Feedback)	Unknown	2024-01-08 23:21:18	https://www.reddit.com/r/Python/comments/191zdx4/wip_pyglet_pen_a_gui_extension_for_pyglet_feedback/	"Hey folks, I wanted to share a project I've been working on over the last few weeks.In short, it is an extension to Pyglet to allow easier creation of commonly used UI elements (e.g. buttons, text inputs) and lay them out on-screen. I love Pyglet, but every project I end up writing code for similar widgets and code to help me organise them; so I started collating it all into a neat library; hence, Pyglet Pen. Pyglet Pen implements \`Views\`, which are basically just a container for a batch and collection of things added to that batch for rendering, and their respective \`Layout\`. There's a subclassed Window to help manage & switch the current \`View\`. A set of \`Layouts\` which manage the organisation of a collection of \`Widgets\` and \`Elements\`, so far I've implemented a Stack, Floating and Grid layout. \`Widgets\` which are, well... GUI widgets; so far I've only implemented buttons and some basic text displays. I'm due to start adding dropdowns, inputs, etc. I've also made a decision to proxy the Pyglet basic renderables, rather than subclassing them; which makes the implementation a little more fiddly. I made this decision to have more control over their interface and to side-step having to deep-dive into their implementation and step on any method-toes. I'm looking for some early feedback, as I've maybe made some choices in the design I normally maybe wouldn't have. In particular, there is a lot of subclassing going on with base class containing a metaclass. I won't lie, it does sometimes give me headaches. My original reasoning was that, since most ""things"" end up getting rendered in a window, in one way or another, they should all have similar attributes (x, y, width, height)... And (almost) everything needs to be, er, ""subscribable"" and ""interactable"". Anyway, here's an idea of what it looks like so far: [https://github.com/NixonInnes/pyglet-pen/blob/main/docs/images/pyglet\_pen\_example.gif](https://github.com/NixonInnes/pyglet-pen/blob/main/docs/images/pyglet_pen_example.gif) &#x200B; And the repo can be found here: [https://github.com/NixonInnes/pyglet-pen](https://github.com/NixonInnes/pyglet-pen) &#x200B; Please let me know what you think; I'm open to suggestions. *Please note, it is still very much a hobby-project and work-in-progress, so it's not all together very tidy - don't look at the commits 😅 and there are undoubtably still remnants of ""debugging code"" in there!* Thanks!"	1.0	t3_191zdx4	reddit		
21	did someone hit pycharm with a brick?	Unknown	2024-01-08 00:42:11	https://www.reddit.com/r/Python/comments/1917rxi/did_someone_hit_pycharm_with_a_brick/	i keep finding stupid little bugs like false-positives in code-inspection, auto-import failing to find symbols in eg a sister module, all kinds of minor irritata (should be a word so i made it so) that i'm sure were not there before... its possible im writing more complex code and so making more obscure errors than i used to, but it feels like they're moving too quickly and missing stuff. elephant in the post is i suppose most of their dev work is currently on the ai assistant which i paid for and uninstalled after a week. it's terrible. copilot-which i also pay for -also has major issues, like chat keeps crashing the ide,...i get way better help by copy-pasting to gpt4 in browser. i feel everyone is releasing minimum viable product in the mad ai goldrush, and basic shit is going to hell. rant ends	31.0	t3_1917rxi	reddit		
22	Advanced Magic Methods in Python To Customize Classes Conveniently	Unknown	2024-01-08 09:18:28	https://www.reddit.com/r/Python/comments/191h6ys/advanced_magic_methods_in_python_to_customize/	Magic methods, also named special methods or dunder methods, whose name starts and ends with a double underscore, offer powerful, convenient ways to customize Python classes, enhance functionality, and simplify our coding experience. [This article](https://medium.com/techtofreedom/9-advanced-magic-methods-in-python-to-customize-classes-conveniently-a1f50fa4b53e?sk=7de16950f316b56d1dfb351d8aadc2d8) will delve into the 9 most useful and ingeniously designed ones of them.	4.0	t3_191h6ys	reddit		
23	Reimagining Web APIs - Multilingual/ Rusty Web Servers ft Robyn	:robyn-logo: Robyn Maintainer	2024-01-08 12:07:14	https://www.reddit.com/r/Python/comments/191js4v/reimagining_web_apis_multilingual_rusty_web/	Hello Everyone ! 👋 We have launched the latest version of Robyn, which introduces a unique way of adding Rust code to Python APIs. It now seamlessly incorporates Rust code within Python APIs, DIRECTLY! 🐍+🦀 = ✨ For the unaware - [Robyn](https://github.com/sparckles/robyn) is one of the fastest Python web frameworks with a Rust Runtime. I have jotted down some opinions on this topic, on how this feature can grant us access to some unexplored possibilities. This post delves into the challenges of Python in heavy-load scenarios and how Rust, with its performance capabilities, can be a game-changer. The blog covers the journey from identifying the issue to the innovative solution Robyn offers, blending Python's ease with Rust(and PyO3)’s efficiency. Check it out here: Reimagining Web APIs - Multilingual/Rusty Web Servers -- [https://sanskar.wtf/posts/future-of-web-apis](https://sanskar.wtf/posts/future-of-web-apis) Robyn - https://github.com/sparckles/robyn Do let me know what you folks think of it 😀	1.0	t3_191js4v	reddit		
24	A library for deep learning and reinforcement learning	Unknown	2024-01-08 11:21:01	https://www.reddit.com/r/Python/comments/191j15u/a_library_for_deep_learning_and_reinforcement/	Hello everyone, I wrote a machine learning library that implements parallel training based on the multiprocessing module. I haven’t done enough testing yet. Is anyone interested in testing its parallel training performance? https://github.com/NoteDance/Note	1.0	t3_191j15u	reddit		
25	abacus - double entry accounting system, new release 0.8.5 and documentation website	Unknown	2024-01-08 02:41:40	https://www.reddit.com/r/Python/comments/191ad5d/abacus_double_entry_accounting_system_new_release/	Hi all! I made a new release of \`abacus\` accounting tool and a new documentation site built with mkdocs-material: [https://epogrebnyak.github.io/abacus/](https://epogrebnyak.github.io/abacus/) The tool so far can be used to demonstrate solutions for textbook excercises in accounting, it works as a Python package and command-line tool (via click). Entire accountign cycle can be done with just serveral commands: \`abacus init\`, \`abacus post\`, \`abacus close\` and \`abacus report\`, results saved into two files chart.json and entries.linejson. Specifically new in this version is the rework of chart of accounts and account class system. The base is \`Enum\` of five account types, and \`TAccount\`, which is an abstract base class with two children DebitAccount and CreditAccount. There is not that much an accounting system should do in principle other than manipulating these accounts. The entrire flow of data in the project was \[str\] -> Chart -> Ledger -> \[Entries\] -> Ledger -> Statement. [core.py](https://core.py) has all of this logic and is under 1k lines of code. [https://github.com/epogrebnyak/abacus/blob/dfd6fd4b794626db8854571dec43db23360abe97/abacus/core.py](https://github.com/epogrebnyak/abacus/blob/dfd6fd4b794626db8854571dec43db23360abe97/abacus/core.py#L37-L44) &#x200B; &#x200B;	0.0	t3_191ad5d	reddit		
26	Experience with Pycharm AI assistant? Is it worth the $?	Unknown	2024-01-08 00:13:01	https://www.reddit.com/r/Python/comments/19174cs/experience_with_pycharm_ai_assistant_is_it_worth/	How useful is the Pycharm AI assistant? How much does it help a junior or mid-level developer? Do senior developers find it useful at all? I'm considering getting for my team (1 junior, 1 mid, 1 senior dev). What can I use to convince management its wort the cost?	14.0	t3_19174cs	reddit		
27	Monday Daily Thread: Project ideas!	Unknown	2024-01-08 00:00:08	https://www.reddit.com/r/Python/comments/1916taf/monday_daily_thread_project_ideas/	"# Weekly Thread: Project Ideas 💡 Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you. ## How it Works: 1. **Suggest a Project**: Comment your project idea—be it beginner-friendly or advanced. 2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code. 3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration. ## Guidelines: * Clearly state the difficulty level. * Provide a brief description and, if possible, outline the tech stack. * Feel free to link to tutorials or resources that might help. # Example Submissions: ## Project Idea: Chatbot **Difficulty**: Intermediate **Tech Stack**: Python, NLP, Flask/FastAPI/Litestar **Description**: Create a chatbot that can answer FAQs for a website. **Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM) # Project Idea: Weather Dashboard **Difficulty**: Beginner **Tech Stack**: HTML, CSS, JavaScript, API **Description**: Build a dashboard that displays real-time weather information using a weather API. **Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8) ## Project Idea: File Organizer **Difficulty**: Beginner **Tech Stack**: Python, File I/O **Description**: Create a script that organizes files in a directory into sub-folders based on file type. **Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/) Let's help each other grow. Happy coding! 🌟"	2.0	t3_1916taf	reddit		
28	DIY SaaS with Python & Streamlit	Unknown	2024-01-07 19:38:01	https://www.reddit.com/r/Python/comments/1910de9/diy_saas_with_python_streamlit/	I've been trying to turn my data science scripts into a full-blown SaaS, and I wanted to share my process and some helpful tidbits. I recently dove into building a SaaS web app using Python, Streamlit, MongoDB, and Stripe. Here's a distilled version [of the guide that got me started](https://medium.com/gitconnected/build-a-data-science-saas-app-with-just-python-a-streamlit-guide-240e0a56fc86) and my experience so far. **Getting Started with Streamlit and Python:** Streamlit is a godsend for Python developers who want to create web apps without the frontend hassle. It lets you focus on the Python stuff while taking care of the UI elements. Start by installing Streamlit and exploring its functionalities with simple apps. **Building the Core Features:** Here's what you'll be piecing together: **User Authentication with MongoDB:** This is your first step into making your app secure and personalized. Start by setting up a MongoDB cluster (Atlas is a good start). You'll need to handle user registration, login, and session management. Python's 'pymongo' library will be your bridge to interact with MongoDB. **Email Verification:** A crucial step for validating users. You'll typically use a third-party service to send emails and then update the user's status in your database once they confirm. **Handling Subscriptions with Stripe:** If you plan to monetize your app, integrating a payment system like Stripe is essential. Begin with setting up a Stripe account and then use their API to create subscription plans and handle payments. Python's 'stripe' package will be useful here. **Data Science Tools with GPT-3.5:** This is where the fun begins. Using OpenAI's GPT-3.5, you'll add features like language translation and text summarization. You'll interact with the OpenAI API and process the data to provide these services. **Step by Step:** **Set Up Your Environment:** Make sure Python, pip, and all necessary packages like 'streamlit', 'pymongo', and 'stripe' are installed. **Layout Your App with Streamlit:** Use Streamlit's widgets to create the user interface. You'll have sections for user registration/login, text input for the GPT-3.5 tools, and subscription management. **Integrate MongoDB:** Write functions to connect to your MongoDB database for user registration and authentication. You'll store user details and manage sessions here. **Email Verification Logic:** Set up a method to send verification emails to users and a route in your app to handle the confirmation logic. **Subscription Management with Stripe:** Use Stripe's API to create and manage subscriptions. You'll need to handle webhook events for subscription updates. **Incorporate GPT-3.5 Features:** Utilize OpenAI's API to add your data science tools. Ensure you handle the API responses correctly and present the results in your app. **Testing and Iterating:** As you build, constantly test each component. Streamlit allows you to see changes in real-time, which is great for tweaking and fixing issues on the go. **Deployment:** Once you're happy with your app, you can deploy it using various services. Streamlit sharing is a straightforward option for small-scale apps. For something more robust, look into services like Heroku or AWS. I wrote up a [full guide here](https://medium.com/gitconnected/build-a-data-science-saas-app-with-just-python-a-streamlit-guide-240e0a56fc86?sk=89b0d73ad134b809e0e831b7f6e3f3ca) for folks interested.	4.0	t3_1910de9	reddit		
29	How to deploy Flask to AWS?!	Unknown	2024-01-08 16:07:51	https://www.reddit.com/r/Python/comments/191omn8/how_to_deploy_flask_to_aws/	Hi Python Enthusiasts! If you have a Flask/Fastapi/Django Project Running locally and thinking about **deploying to AWS**, and you don’t want to put the applications into containers, you have 2 options 1. **Create an AWS AppRunner Service**, this is the easier and more simple solution, but it cost you more 1. AppRunner not just host your application but will setup an automated deployment pipeline, on each commit you can deploy the application 2. AppRunner also provides TLS/SSL certificates out of the Box 3. You can find more details in the following [**Video**](https://www.youtube.com/watch?v=t2d3CGkPXQI) 2. **Create an EC2 and a Service** 1. If you have a little experience working with Virtual Machines, this option might be also feasible for you 2. You need to create a Linux/Windows Service, configuring a reverse proxy, issuing TLS Certificates, Copying the code to the EC2 3. You can find more details in the following [**Video**](https://www.youtube.com/watch?v=VFTeLN0J9Lw) If you want to run containers or chose a different vendor that is also another option, all of them have their advantages and drawbacks. Architecture is about Trade-Offs.	7.0	t3_191omn8	reddit		
30	Create Your First Real Estate Lead-Capturing Chatbot Using Voiceflow and Python Flask	Unknown	2024-01-07 21:29:21	https://www.reddit.com/r/Python/comments/19134q2/create_your_first_real_estate_leadcapturing/	In this tutorial, I introduce VoiceFlow, a chatbot development platform. The blog post is all about creating a real estate lead-capturing chat using Python Flask as a backend API. You can learn more about it by visiting the [blog post](https://blog.adnansiddiqi.me/create-your-first-real-estate-lead-capturing-chatbot-using-voiceflow-and-python-flask/) about it.	1.0	t3_19134q2	reddit		
31	BeautifulSoup Tutorial: Tennis Web Scraping Project	Unknown	2024-01-07 21:52:55	https://www.reddit.com/r/Python/comments/1913pwb/beautifulsoup_tutorial_tennis_web_scraping_project/	Hi everyone! I created a 15-minute video that will show you how to **scrape data** from a website and save that into your **local computer**. I'll be using the **FOX Sports** website, and I'll be scraping their **tennis rankings**. I'll show you **BeautifulSoup methods** to scrape the data and **Pandas methods** to create a new dataframe from the data that I scraped. I also provided a **GitHub link** in the video description, so you can copy my code if you want. [https://youtu.be/6hKyDSx6xo8](https://youtu.be/6hKyDSx6xo8) I hope you find this tutorial helpful!	1.0	t3_1913pwb	reddit		
32	How to write a python decorator (and why)	Unknown	2024-01-06 11:19:32	https://www.reddit.com/r/Python/comments/18zxxak/how_to_write_a_python_decorator_and_why/	tldr; Decorators are a nice way to wrap functions in other functions and re-use code [https://www.jaredbwelch.com/blog/How\_to\_write\_a\_python\_decorator\_and\_why](https://www.jaredbwelch.com/blog/How_to_write_a_python_decorator_and_why)	13.0	t3_18zxxak	reddit		
33	Astronomy / Space Science: Working on meteor data	git push -f	2024-01-06 17:53:49	https://www.reddit.com/r/Python/comments/1905n4g/astronomy_space_science_working_on_meteor_data/	"Hey everyone, I started with a new ""Space Science with Python"" tutorial and would like to share it with you. It is about tiny dust particles entering our atmosphere: meteors. Thankfully, the International Astronomical Union (IAU) provides free-accessible datasets with almost 1 Million meteors. These data contain physical and dynamical properties like the brightness of the meteor, its original orbit around the Sun and the appearance coordinates on the sky. If you are interested, there data is here: [https://ceres.ta3.sk/iaumdcdb/home/catalog/video](https://ceres.ta3.sk/iaumdcdb/home/catalog/video) But if you are not that deep into this space-scientific field: I started to create some Jupyter Notebooks to work with the data. The objective of my tutorial: first, understanding the meteor physics and then I'll create a Variational Autoencoder based meteor shower detection model. Anyway, if you are interested, here is the code: [https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/tree/main/Project-Meteor-Science](https://github.com/ThomasAlbin/Astroniz-YT-Tutorials/tree/main/Project-Meteor-Science) And the corresponding tutorial playlist, and yes, my videos are not fancy YouTube professional productions, I am just a guy sharing his passion with the world: [https://www.youtube.com/watch?v=5FK3dTrW\_Fc&list=PLNvIBWkEdZ2g3ifrQ6O06fkeetf8e1NDg](https://www.youtube.com/watch?v=5FK3dTrW_Fc&list=PLNvIBWkEdZ2g3ifrQ6O06fkeetf8e1NDg) Cheers, Thomas"	4.0	t3_1905n4g	reddit		
34	gguf_modeldb - I've created a package for handling llama2 gguf model data and models	Unknown	2024-01-07 05:06:14	https://www.reddit.com/r/Python/comments/190kbov/gguf_modeldb_ive_created_a_package_for_handling/	GH: [https://github.com/laelhalawani/gguf\_modeldb](https://github.com/laelhalawani/gguf_modeldb) | PYPI: [https://pypi.org/project/gguf-modeldb/](https://pypi.org/project/gguf-modeldb/) This tool *in an alpha version* helps to manage model data and gguf files. It features a built-in library of 56 total quantizations of several of the best open source instruct models (dolphin, mistral, mixtral, solar, zephyr), with preconfigured formatting information ready to be searched and downloaded with one line of code. It can work globally for all the projects within an environment, or offer a separate gguf model db for each project. It's a well documented and optimized package. Available for download on pypi with `pip install gguf-modeldb==0.0.1a2` It can be used easily with packages like llama-cpp-python to offload everything related to model handling. After installing, import ```python from gguf_modeldb import ModelDB ``` and that's all you need to get started with the best gguf models on huggingface. ```python mdb = ModelDB() gguf_path = mdb.find_model('zephyr','q2').download_gguf() ``` Beyond the 56 built-in tested verified models with correct tags configured, with a single url to a hugginface repo page you can add many more models. The repo link must lead to a page containing links ending with '.gguf' (such as those offered in the repos by the legend TheBloke i.e. https://huggingface.co/TheBloke/CodeLlama-7B-GGUF). You should probably also provide a few additional optional but recommended arguments such as user/ai/system tags, description and keywords and the model data will be there ready for you when you need it. *If you know another platform(s) that hands out gguf models plz let me know* The `ModelData` class provides an object warpper for the data in the `ModelDB` with usfeful methods that automate and abstract away less fun tasks such as downloading the gguf files `model_data.downlad_gguf()` or even just checking if the file is downloaded `model_data.is_downloaded()`. All methods have docstrings and there's an api documentation so if you've got a minute please have a look there for some examples.	2.0	t3_190kbov	reddit		
35	One billion row challenge	Unknown	2024-01-05 21:23:44	https://www.reddit.com/r/Python/comments/18zi0o5/one_billion_row_challenge/	Just saw this repo trending and thought of doing this in different languages, e.g. Python. [https://github.com/gunnarmorling/1brc](https://github.com/gunnarmorling/1brc) Do you know if it's already available?	10.0	t3_18zi0o5	reddit		
36	FlaskyLMS - A Simple Leave Management System in Flask with Google Calendar Integration	Unknown	2024-01-06 11:30:19	https://www.reddit.com/r/Python/comments/18zy385/flaskylms_a_simple_leave_management_system_in/	A simple leave management tool that I built for myself a while ago. Now sharing on GitHub. Not the most pretty looking and lacks many bells and whistles but still gets the main job done xD * User-friendly leave request process: Employees can easily submit leave requests through a simple and intuitive interface. * Admin approval and rejection: Admins can review leave requests, approve or reject them, and provide feedback if needed. * Email notifications: Both employees and admins receive timely email notifications for new requests, approvals, and rejections. * Google Calendar integration: Approved leaves are automatically added as events to the admin's Google Calendar, ensuring visibility. Try or give your feedback: https://github.com/Suleman-Elahi/FlaskyLMS	0.0	t3_18zy385	reddit		
37	"2,000 free sign ups available for the ""Automate the Boring Stuff with Python"" online course. (Jan 2024)"	"Author of ""Automate the Boring Stuff"""	2024-01-05 21:51:36	https://www.reddit.com/r/Python/comments/18ziobn/2000_free_sign_ups_available_for_the_automate_the/	"If you want to learn to code, I've released 2,000 free sign ups for my course following my Automate the Boring Stuff with Python book (each has 1,000 sign ups, use the other one if one is sold out): *The sign ups are all used up, but you can still watch all the videos for free. Read below! ~~https:// udemy. com/course/automate/?couponCode=JAN2024FREE~~ ~~https:// udemy. com/course/automate/?couponCode=JAN2024FREE2~~ If you are reading this after the sign ups are used up, you can always find [the first 15 of the course's 50 videos are free on YouTube if you want to preview them.](https://www.youtube.com/watch?v=1F_OgqRuSdI&list=PL0-84-yl1fUnRuXGFe_F7qSH1LEnn9LkW) YOU CAN ALSO WATCH THE VIDEOS WITHOUT SIGNING UP FOR THE COURSE. All of the videos on the course webpage have ""preview"" turned on. Scroll down to find and click ""Expand All Sections"" and then click the preview link. You won't have access to the forums and other materials, but you can watch the videos. **NOTE: Be sure to BUY the course for $0, and not sign up for Udemy's subscription plan. The subscription plan is free for the first seven days and then they charge you. It's selected by default. If you are on a laptop and can't click the BUY checkbox, try shrinking the browser window. Some have reported it works in mobile view.** **I'm also working on another Udemy course** that follows my recent book ""Beyond the Basic Stuff with Python"". So far I have [the first 15 of the planned 56 videos done. You can watch them for free on YouTube.](https://www.youtube.com/watch?v=kSrnLbioN6w&list=PL0-84-yl1fUmeV_2bBSguF_S0TVZk8wow&index=1) **Frequently Asked Questions:** (*read this before posting questions*) * This course is for beginners and assumes no previous programming experience, but the second half is useful for experienced programmers who want to learn about various third-party Python modules. * If you don't have time to take the course now, that's fine. Signing up gives you lifetime access so you can work on it at your own pace. * This Udemy course covers roughly the same content as the 1st edition book (the book has a little bit more, but all the basics are covered in the online course), which you can read for free online at https://inventwithpython.com * The 2nd edition of Automate the Boring Stuff with Python is free online: https://automatetheboringstuff.com/2e/ * I do plan on updating the Udemy course, but it'll take a while because I have other book projects I'm working on. If you sign up for this Udemy course, you'll get the updated content automatically once I finish it. It won't be a separate course. * It's totally fine to start on the first edition and then read the second edition later. I'll be writing a blog post to guide first edition readers to the parts of the second edition they should read. * **You're not too old to learn to code. You don't need to be ""good at math"" to be good at coding.** * Signing up is the first step. Actually finishing the course is the next. :) [There are several ways to get/stay motivated.](https://www.reddit.com/r/learnprogramming/wiki/faq#wiki_how_can_i_get.2Fstay_motivated_to_learn_programming.3F) I suggest getting a ""gym buddy"" to learn with. Check out /r/ProgrammingBuddies"	6.0	t3_18ziobn	reddit		
38	MiniFirehose - A lightweight data buffering and delivery system	Unknown	2024-01-06 14:10:55	https://www.reddit.com/r/Python/comments/1900se3/minifirehose_a_lightweight_data_buffering_and/	Hi everyone! I wanted to share a project I made in just a week. It's called MiniFirehose (somewhat similar to AWS Firehose). It's a really simple tool for managing data, kind of like Kafka or MQTT but much easier to use and lighter on resources. With MiniFirehose, you can collect messages and send them to places like your local filesystem or Amazon S3. It's not complicated to set up, and it's great if you're working on something small and don't need a big system. Since I made it pretty quickly, there might be some small bugs. If you try it and have any ideas on how to make it better, I'd love to hear from you. Or, if you know other tools like this, let me know! so I don't spend much time on it. You can check it out here: \[[mini-firehose](https://github.com/waqar-ahmed/mini-firehose)\]. I'm looking forward to hearing what you think! Thanks!	1.0	t3_1900se3	reddit		
39	I wrote envolved: a library to make reading and parsing environment variables effortless	Unknown	2024-01-06 11:26:33	https://www.reddit.com/r/Python/comments/18zy14i/i_wrote_envolved_a_library_to_make_reading_and/	"[github](https://github.com/bentheiii/envolved), [readthedocs](https://envolved.readthedocs.io/en/latest/) Envolved is a python library I've been working on for some time, to help with programs that need to read a lot of complex environment variables. We've been using it at the company I work for with a lot of success so I think it's ready to show to the world. Basically it works around having ""environment variables"" as constant entities that can be retrieved at any time (similar to `contextvars`). This allows us to test different configurations easily, as well as making it easy to retrieve exactly which environment variables the program uses. I'd love to know what everyone thinks of it, any suggestions and feedback are welcome!"	1.0	t3_18zy14i	reddit		
40	Summon a Genie🧞‍♂️ (Function Decorator) to Generate Agent Powered Function in Runtime	Unknown	2024-01-07 04:04:27	https://www.reddit.com/r/Python/comments/190j5le/summon_a_genie_function_decorator_to_generate/	"As a developer, have you ever dreamed about writing some definitions and annotation in code then ""boom!"" all in a sudden, some genies 🧞‍♂️ come out and make all your wishes happen? Notice that: **the genies do not write the code for you, instead they just _finish the work_ for you!** Now Agently framework present a brand new feature **""agent auto function decorator""** for you! Use @<agent instance>.auto_func to decorate your function and feel the magic! Combining the tools-using abilities we enhanced the Agently agents recently, just open your mind and let's see how fantasy work you can let the agents help you to do. **Installation** ```shell pip install -U Agently ``` **Demo Code**: You can let a search agent to help you find definition on the internet ```python import Agently # create a search agent search_agent = ( Agently.create_agent() .set_settings(""model.OpenAI.auth"", { ""api_key"": """" }) ) # equip search agent with tool ""search_definition"" search_agent.use_public_tools(""search_definition"") # define your function: input arguments, output data structure requirement, function purpose # then use decorator to call search agent to help @search_agent.auto_func def find_definition(concept_keyword:str) -> {""source"": (""String"", ), ""definition"": (""String"", )}: """"""Search your knowledge or the internet to find out the definition of {concept_keyword}."""""" return # do not need to complete the function coding # just call it and get your result result = find_definition(""OpenAI"") ``` Result: ```python {'source': 'Wikipedia', 'definition': ""OpenAI is a U.S. artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the declared intention of developing 'safe and beneficial' artificial general intelligence, which it defines as 'highly autonomous systems that outperform humans at most economically valuable work'.""} ``` You can also let a calculate agent to help you calculate result from natural language input or equation string ```python import Agently # of course, you can use Google Gemini to drive the agent too calculate_agent = ( Agently.create_agent() .set_settings(""current_model"", ""Google"") .set_settings(""model.Google.auth"", { ""api_key"": """" }) ) calculate_agent.use_public_tools(""calculate"") @calculate_agent.auto_func def calculate_from_str(equation: str) -> { ""steps"": [(""String"", ""one calculate step"")], ""value"": (""Float"", ) }: """"""return calculation result of {equation}."""""" return print(calculate_from_str(""3+5✕(8+2)-2⁒2"")) ``` Result: ```python {'steps': ['3 + 5 * (8 + 2) - 2 / 2', '3 + 5 * 10 - 2 / 2', '3 + 50 - 2 / 2', '3 + 50 - 1', '53 - 1', '52'], 'value': 52.0} ``` **More Details:** [Open Jupyter document to try more demos about this show case](https://github.com/Maplemx/Agently/blob/main/playground/generate_agent_powered_function_in_runtime_using_decorator.ipynb) **Project HomePage:** https://github.com/Maplemx/Agently , ⭐️ if you like it~ 🙏 **Explore More Show Cases of Agently:** [Visit Our Playground](https://github.com/Maplemx/Agently/blob/main/playground)"	1.0	t3_190j5le	reddit		
41	Elden Ring Bot	Unknown	2024-01-06 02:02:58	https://www.reddit.com/r/Python/comments/18zohpo/elden_ring_bot/	"Hey there, I've been working on my take at the Elden Ring Bot concept, and would like to share it with the community. It works by processing stacks of frames captured from the game and the sequence of actions last taken, and outputs a distribution probability over all the available actions, from which the next action is picked. The bot runs for a predefined number of steps, after which the run is scored based on damage taken, stamina and mana used, damage dealt and world exploration. The bot's ""brain"" aka the set of parameters used for the data processing step, is updated using a variant of particle swarm optimization I implemented myself. The heavy load is all done in numpy, with a couple helper tools in pandas, opencv and PIL. In case anyone is interested in checking it out, here's the github link: [Jalabhar's Elden Bot](https://github.com/Jalabhar/Elden_Bot) I'll be pleased to hear any suggestions and questions you might have. Disclaimer: I have already posted about it a few months ago, but since then I have made significant changes and improvements, so I felt like it made sense to post about it once again"	0.0	t3_18zohpo	reddit		
42	VisioNomicon - GPT-4V Smart Image Renamer	Unknown	2024-01-06 02:20:59	https://www.reddit.com/r/Python/comments/18zovd6/visionomicon_gpt4v_smart_image_renamer/	VisioNomicon is a powerful Python-based command-line utility tool designed to rename image files using the capabilities of GPT-4. Descriptive filenames are generated based on a user given template and the content of the image. Try it out, and let me know what you guys think! All the details can be found at: [https://github.com/rehanzo/VisioNomicon](https://github.com/rehanzo/VisioNomicon)	0.0	t3_18zovd6	reddit		
43	Event Driven vs Loop Driven what's your preference?	Unknown	2024-01-05 06:33:25	https://www.reddit.com/r/Python/comments/18z08uh/event_driven_vs_loop_driven_whats_your_preference/	Streamlit is loop driven it runs every time any thing change on the app, is it performance issue for you? do you prefer Event driven framework against loop driven?	11.0	t3_18z08uh	reddit		
44	MineSweeper Game in Python and Tkinter	Unknown	2024-01-05 16:32:02	https://www.reddit.com/r/Python/comments/18zaz6v/minesweeper_game_in_python_and_tkinter/	I made a MineSweeper game using Python and Tkinter. Code: https://github.com/DataWizual/MineSweeper Here's the video explaining how I did it: https://www.youtube.com/watch?v=uYv26qoHLN0	3.0	t3_18zaz6v	reddit		
45	Saving Metadata When Using Python Decorators | Jacob Padilla	Unknown	2024-01-05 19:16:22	https://www.reddit.com/r/Python/comments/18zexf0/saving_metadata_when_using_python_decorators/	Wrapping one object over another can result in the loss of valuable metadata; that's why using the functools.wraps decorator is crucial when developing your own Python decorators. In this [article](https://jacobpadilla.com/articles/Functools-Deep-Dive), explore the intricacies of functools.wraps and how it works under the hood!	1.0	t3_18zexf0	reddit		
46	Draw2Img: A simple web UI for interactive text-guided image to image generation via SDXL-Turbo, intended for any age and level of expertise.	Unknown	2024-01-05 18:06:30	https://www.reddit.com/r/Python/comments/18zd9dx/draw2img_a_simple_web_ui_for_interactive/	With the release of SDXL-Turbo in late Nov 2023, it became feasible to perform text-guided image to image generation in real-time on a consumer grade GPU. Inspired by this progress and my little cousins' artwork, I put together a web app that integrates an interactive canvas & paint tool with the capabilities of SDXL-Turbo. The project is called Draw2Img, and I want to share it here in the hopes that you or your family enjoys it as much as we have. What makes this project unique is the combination of: 1) a simple and accessible web based UI for younger or non-technical users 2) the stunning speed & quality of image generation 3) user friendly & LAN party ready (easy to run, multiple concurrent users supported) Thanks in advance for your feedback and support, cheers! https://github.com/GradientSurfer/Draw2Img	0.0	t3_18zd9dx	reddit		
47	Saturday Daily Thread: Resource Request and Sharing! Daily Thread	Unknown	2024-01-06 00:00:18	https://www.reddit.com/r/Python/comments/18zlr3i/saturday_daily_thread_resource_request_and/	"# Weekly Thread: Resource Request and Sharing 📚 Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread! ## How it Works: 1. **Request**: Can't find a resource on a particular topic? Ask here! 2. **Share**: Found something useful? Share it with the community. 3. **Review**: Give or get opinions on Python resources you've used. ## Guidelines: * Please include the type of resource (e.g., book, video, article) and the topic. * Always be respectful when reviewing someone else's shared resource. ## Example Shares: 1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms. 2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures. 3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators. ## Example Requests: 1. **Looking for**: Video tutorials on web scraping with Python. 2. **Need**: Book recommendations for Python machine learning. Share the knowledge, enrich the community. Happy learning! 🌟"	1.0	t3_18zlr3i	reddit		
48	Is style transfer possible in python without downloading heavy packages?	Unknown	2024-01-06 04:43:26	https://www.reddit.com/r/Python/comments/18zroew/is_style_transfer_possible_in_python_without/	I found this project called arbitrary style transfer in the browser using tensorflow.js: https://reiinakano.com/arbitrary-image-stylization-tfjs/ (source code: https://github.com/reiinakano/arbitrary-image-stylization-tfjs) This style transfer works in the browser without uploading anything in server, it just installs a smaller version of inception v3 model to transfer style from any image. You just have to select the images from your disk and it stylizes the image. Though I have found python repositories for arbitrary style transfer but they require lots of things to setup like torch, tensoflow, network models, training datasets and also needs a gpu. Moreover I don't want to use google collab, I want something light weight like that website, but in python so that I can use it in offline mode. (with that low size inception v3 model only) In short I want some fast style transfer without downloading any heavy python packages on my system. Comment if you have any project links...	3.0	t3_18zroew	reddit		
49	PyWindowsScreenCapture, Tool for efficient screen capturing on Windows	Unknown	2024-01-05 17:34:58	https://www.reddit.com/r/Python/comments/18zcht6/pywindowsscreencapture_tool_for_efficient_screen/	"I stepping into the world of C programming with my latest project, ""Windows Screen Capture DLL,"" and its Python wrapper, ""PyWindowsScreenCapture."" This project represents not just a tool for efficient screen capturing on Windows but also my journey in learning and improving my C programming skills. \*\*About the Project:\*\* \- \*\*Windows Screen Capture DLL\*\*: A dynamic link library I developed to push the boundaries of screen capture performance on Windows platforms. \- \*\*PyWindowsScreenCapture\*\*: A Python wrapper that provides an easy-to-use interface to the DLL, making it accessible for Python developers. \*\*Key Features:\*\* \- Optimized for performance, potentially outperforming MSS (Python Screen Capture). \- Multi-monitor support, capturing high-resolution screens efficiently. \- Designed with simplicity and minimal dependencies in mind. The motivation behind this project was not only to create a high-performance tool but also to challenge myself and enhance my understanding of C programming. As my first serious foray into C, I'm keen on receiving feedback, suggestions, and contributions from the community to help me grow as a developer. While this project is still in its beta phase, I am proud of what I've accomplished and am excited to see how it can evolve with community input. Whether you're interested in high-speed screen capturing or have insights into C development, I welcome your thoughts and contributions. You can check out the project and contribute here: \- DLL: https://github.com/offerrall/WindowsScreenCapture \- Python Wrapper: https://github.com/offerrall/PyWindowsScreenCapture I’m looking forward to your feedback and suggestions. Thank you for being a part of my programming journey!"	0.0	t3_18zcht6	reddit		
50	Traktstats without premium	Unknown	2024-01-05 16:05:50	https://www.reddit.com/r/Python/comments/18zachx/traktstats_without_premium/	Hi Everyone, I wanted to share my python project, this python [program](https://github.com/Ahmedazim7804/trakt_vip_stats) uses trakt and tmdb api to generate all-time-stats like the official feature of trakt which requires subscription. You can then use [this app](https://github.com/Ahmedazim7804/traktstats_app) to view those stats visually. if you have any feedback, i would love to hear it. Edit :- English is not my first language, so excuse any grammer mistake.	1.0	t3_18zachx	reddit		
51	LLama.cpp AI reddit poster / commenter	Unknown	2024-01-05 15:51:39	https://www.reddit.com/r/Python/comments/18za06z/llamacpp_ai_reddit_poster_commenter/	These two scripts use llama.cpp but note - rename the llama.cpp main.exe file to main2.exe or change the bits in the code to main.exe . You can change the AI model in the code when it runs the main2.exe to a gguf model of your choice. Both ask what subreddit you want to post to and with what prompt. The scripts use reddit API which you have to have. I dunno about the reddit AI policy. I tested it on a subreddit called Hergidonia I made up to play with it. Install the modules in the beginning of the script and llama.cpp and it should work fine if the main.exe is in the folder you run it and the ai model points to your gguf model. https://pastebin.com/yqTq1aMt	1.0	t3_18za06z	reddit		
52	API Logic Server - Kafka Application Integration	Unknown	2024-01-05 03:15:19	https://www.reddit.com/r/Python/comments/18ywi8a/api_logic_server_kafka_application_integration/	API Logic Server is an open source Python project that creates executable web app projects instantly from da database, with a single CLI command -- a JSON:API with Swagger, and a multi-page multi-table Admin App. SQLAlchemy classes are created automatically. Customize the project in your IDE using Python and rules. Rules are spreadsheet-like assertions expressed in Python, implementing role-based row-level security, and multi-table constraint and derivation logic for database integrity. You can extend the API with standard Flask and SQLAlchemy. Application Integration is supported via APIs and Kafka Message handling. Consulting and Training are available. Links: * \[Docs\]([https://apilogicserver.github.io/Docs/](https://apilogicserver.github.io/Docs/)) - includes 5 min video * \[Application Integration\]([https://apilogicserver.github.io/Docs/Sample-Integration/](https://apilogicserver.github.io/Docs/Sample-Integration/)) * \[Rules\]([https://apilogicserver.github.io/Docs/Logic-Why/](https://apilogicserver.github.io/Docs/Logic-Why/)) * \[API\]([https://apilogicserver.github.io/Docs/API/](https://apilogicserver.github.io/Docs/API/)) * \[Admin Web App\](https://apilogicserver.github.io/Docs/Admin-Tour/)	2.0	t3_18ywi8a	reddit		
53	Statically enforcing frozen data classes in Python	Unknown	2024-01-04 11:54:33	https://www.reddit.com/r/Python/comments/18ybepc/statically_enforcing_frozen_data_classes_in_python/	Wrote a quick TIL on how to statically enforce frozen data classes in Python. Had to resort to crowd sourcing & good ol' stackoverflow to figure this one out since LLMs were of no help: https://rednafi.com/python/statically_enforcing_frozen_dataclasses/	6.0	t3_18ybepc	reddit		
54	GGUF LLAMA AI - Package for simplified text generation with Llama models quantized to GGUF format	Unknown	2024-01-04 17:25:39	https://www.reddit.com/r/Python/comments/18yijbp/gguf_llama_ai_package_for_simplified_text/	I'm looking for some developer who'd be interested in helping develop this simple project that tries to maximally simplify gguf models deployment on cpu to make this tech more accessible [https://github.com/laelhalawani/glai](https://github.com/laelhalawani/glai) It is a llama-ccp wrapper that simplifies use of llama based models.It features a built in ModelDB with json entries that can be used to automatically download and deploy quantized gguf models from hf.Then there are to classes AutoAI and EasyAI.The frist one takes min of 3 arguments including search query or path or url and max tokens and max input tokens. And that's all that's needed to load the model for inference. The later allows configuration of the model in few simple steps. Giving more granular control, while still prioritizing simplicity. There's a bunch of examples and detailed documentation already. The project is also published on pypi \`pip install glai\`	2.0	t3_18yijbp	reddit		
55	Friday Daily Thread: r/Python Meta and Free-Talk Fridays	Unknown	2024-01-05 00:01:09	https://www.reddit.com/r/Python/comments/18ys8mu/friday_daily_thread_rpython_meta_and_freetalk/	# Weekly Thread: Meta Discussions and Free Talk Friday 🎙️ Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related! ## How it Works: 1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community. 2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community. 3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting. ## Guidelines: * All topics should be related to Python or the /r/python community. * Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy). ## Example Topics: 1. **New Python Release**: What do you think about the new features in Python 3.11? 2. **Community Events**: Any Python meetups or webinars coming up? 3. **Learning Resources**: Found a great Python tutorial? Share it here! 4. **Job Market**: How has Python impacted your career? 5. **Hot Takes**: Got a controversial Python opinion? Let's hear it! 6. **Community Ideas**: Something you'd like to see us do? tell us. Let's keep the conversation going. Happy discussing! 🌟	2.0	t3_18ys8mu	reddit		
56	Clickstream Aggregation in Python with Redis	Unknown	2024-01-04 18:07:01	https://www.reddit.com/r/Python/comments/18yjjow/clickstream_aggregation_in_python_with_redis/	This is a tutorial article on how you can use Redis PubSub capabilities with the Python streaming library Bytewax to aggregate clickstreams in Python. &#x200B; https://redis.com/blog/redis-driven-dataflow-for-clickstream-aggregation-with-bytewax/	0.0	t3_18yjjow	reddit		
57	Why Python is slower than Java?	Unknown	2024-01-03 09:44:10	https://www.reddit.com/r/Python/comments/18xfmq2/why_python_is_slower_than_java/	Sorry for the stupid question, I just have strange question. If CPython interprets Python source code and saves them as byte-code in .pyc and java does similar thing only with compiler, In next request to code, interpreter will not interpret source code ,it will take previously interpreted .pyc files , why python is slower here? Both PVM and JVM will read previously saved byte code then why JVM executes much faster than PVM? Sorry for my english , let me know if u don't understand anything. I will try to explain	42.0	t3_18xfmq2	reddit		
58	Check Out Flasknotes - A Flask Note-Taking Web App!	Unknown	2024-01-04 04:13:13	https://www.reddit.com/r/Python/comments/18y3x63/check_out_flasknotes_a_flask_notetaking_web_app/	**Hey Python enthusiasts!** I'm excited to share my latest project, Flasknotes - a simple web-based note-taking application built using Flask and MySQL. This project boasts various features, including role-based authentication, CRUD operations, and the ability to mark your favorite notes. **Project Links:** * **GitHub Repository:** [Flasknotes GitHub Repo](https://github.com/ghandylan/flask-notes) * **Live Demo:** [Flasknotes Demo](https://flasknotes.pythonanywhere.com/home)	2.0	t3_18y3x63	reddit		
59	Fast and secure routing development and OpenAPI bindings in sanic, flask, tornado, starlette	Unknown	2024-01-04 07:59:38	https://www.reddit.com/r/Python/comments/18y7t6j/fast_and_secure_routing_development_and_openapi/	I created a library - [pait](https://github.com/so1n/pait), which is compatible with multiple Python web frameworks. At the same time, it has absorbed some excellent designs from FastAPI. Through pait, you can quickly and safely develop routing functions and view OpenAPI data.	0.0	t3_18y7t6j	reddit		
60	Ezsynth -- Ebsynth Video Stylization as a Python Library.	Unknown	2024-01-04 01:58:49	https://www.reddit.com/r/Python/comments/18y13rv/ezsynth_ebsynth_video_stylization_as_a_python/	Hey all! I've been working on this project on and off for a few months, and for the most part, its pretty stable at this point.If you're familiar with the program ebsynth, you'll be right at home with Ezsynth.Ezsynth is a recreation of the ebsynth video stylization process, through the use of: - a) The ebsynth.dll source code, interfaced through ctypes, - b) RAFT Optical Flow, and - C) PhyCV physics based edge detection. Ultimately the goal was to create a simple, pythonic way to achieve a similar output to the ebsynth program. Most current methods involve GUI mapping, etc, in order to make ebsynth work with python. Ezsynth is a full recreation of the original ebsynth paper, offering both the original method of stylization, and updated versions using RAFT and various PhyCV features. I've only been programming since April, most of my work is done by coming up with workflows, writing pseudo code, and then bouncing back and forth with GPT 4 on how to accomplish what I want. Check it [here](https://github.com/Trentonom0r3/Ezsynth), and I apologize for any noob mistakes or things you may find-- I'm still learning! A demo of what it does can be found [here](https://github.com/Trentonom0r3/Ezsynth/blob/a3981fa3169fb076284fba432f239017e3d7e021/ezsynthdemo.mp4)=	2.0	t3_18y13rv	reddit		
61	Simple keylogger made in Python	Unknown	2024-01-04 09:25:36	https://www.reddit.com/r/Python/comments/18y92tw/simple_keylogger_made_in_python/	Here is the repo: [https://github.com/Migue8gl/Python-scripts](https://github.com/Migue8gl/Python-scripts) I am open to criticism on what I can improve in this small project. Over time I would like to create more Python scripts touching on different areas.I have to say that. I'm not new to programming and I'm not new to Python either, but I'm sure I have some things wrong that can be fixed.	1.0	t3_18y92tw	reddit		
62	Thursday Daily Thread: Python Careers, Courses, and Furthering Education!	Unknown	2024-01-04 00:00:07	https://www.reddit.com/r/Python/comments/18xydsg/thursday_daily_thread_python_careers_courses_and/	# Weekly Thread: Professional Use, Jobs, and Education 🏢 Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**. --- ## How it Works: 1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles. 2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources. 3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally. --- ## Guidelines: - This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar. - Keep discussions relevant to Python in the professional and educational context. --- ## Example Topics: 1. **Career Paths**: What kinds of roles are out there for Python developers? 2. **Certifications**: Are Python certifications worth it? 3. **Course Recommendations**: Any good advanced Python courses to recommend? 4. **Workplace Tools**: What Python libraries are indispensable in your professional work? 5. **Interview Tips**: What types of Python questions are commonly asked in interviews? --- Let's help each other grow in our careers and education. Happy discussing! 🌟	1.0	t3_18xydsg	reddit		
63	Knuckledragger: Experimenting with a Python Proof Assistant	Unknown	2024-01-03 16:19:24	https://www.reddit.com/r/Python/comments/18xn6ne/knuckledragger_experimenting_with_a_python_proof/	Hi, An idea I've toyed around for a while is how to chain together inferences of automated theorem provers like z3py into larger developments. I've started putting fingers to keyboard. The point is to make something accessible to a larger, less specialized audience and to target mathematics akin to that in sympy, so I'm very interested in feedback about what works for people. * Blog post: https://www.philipzucker.com/python-itp/ * Very WIP repo: https://github.com/philzook58/knuckledragger	2.0	t3_18xn6ne	reddit		
64	Will Code for Free	Unknown	2024-01-04 17:29:14	https://www.reddit.com/r/Python/comments/18yimj6/will_code_for_free/	So, I've learned an ass-load about Python and I think I have a pretty good grasp on even some of the more advanced concepts, but I desperately need to apply what I've learned. Does anyone have anything I can be of assistance with in return for just the hands-on experience? Any suggestions where I should go to maybe find people who could use my assistance? I willing to freakin' work for free. &#x200B; Update: I really appreciate the responses. I've definitely worked on some of my own stuff, but I know I could learn a lot more and faster working with others. I'm doing my best to get back to everyone who offered. Thank you again everyone.	40.0	t3_18yimj6	reddit		
65	Pydantic has too much deprecation, making it difficult to keep up with updates and maintaining the code. Lots of functionality has been renamed, and some are removed during v1→v2 transition. Even sample code from November 2023 is deprecated now! Are there better alternatives?	Unknown	2024-01-03 19:15:33	https://www.reddit.com/r/Python/comments/18xrc1y/pydantic_has_too_much_deprecation_making_it/	Almost all tutorials I see online (and ChatGPT's knowledge base) teach you Pydantic v1. There are numerous things that are deprecated during transition to v2 (@root_validator, @validator, using 'always', etc. are all gone now.). I even found a code example on its Github from November 2023 which now throws an error, saying that FieldValidationInfo is deprecated now, use <new_thing> instead... I wanted to use something to validate user inputs to my API, but getting Pydantic right and then keeping it updated has been too much unnecessary work, which makes me wonder if you have also faced this problem and what your solution is?	27.0	t3_18xrc1y	reddit		
66	An AI Python Web app to analyze resumes	Unknown	2024-01-04 17:08:09	https://www.reddit.com/r/Python/comments/18yi41b/an_ai_python_web_app_to_analyze_resumes/	Hey r/python, say goodbye to tedious resume evaluations – https://resume-analyzer.ploomberapp.io/. 🌐 What do you guys think? I wanted to supercharge my hiring process and make smarter decisions in a snap. I've connected this code, based on Open AI and on Streamlit. This Python code is open-sourced and is available in the [GitHub repo](https://github.com/gopiashokan/AI-Powered-Resume-Analyzer-and-LinkedIn-Scraper-with-Selenium). I've hosted it on Ploomber Cloud.	8.0	t3_18yi41b	reddit		
67	Okay, I have this genuine question, why does Python allow hashing functions?	Unknown	2024-01-02 23:58:18	https://www.reddit.com/r/Python/comments/18x4kw6/okay_i_have_this_genuine_question_why_does_python/	So I was working on my programming language and was taking inspiration from Python, and realized that Python allows hashing functions and you can have functions As keys, this is what confuses me here what is the use of this, and how do they do it to begin with? Like do they have something like a dictionary data structure that has Python objects as keys? That sounds like it's memory inefficient. &#x200B;	11.0	t3_18x4kw6	reddit		
68	PyJigsaw: A Digital Jigsaw Puzzle Factory	Unknown	2024-01-03 10:48:14	https://www.reddit.com/r/Python/comments/18xglbx/pyjigsaw_a_digital_jigsaw_puzzle_factory/	I created a jigsaw puzzle constructor which uses mostly Python with a small assist from Inkscape. You can create SVG puzzle sets and templates programmatically, which could be useful as part of a jigsaw puzzle app (my original intention for it). I've shelved the wider project but the constructor was in a decent place, so decided to tidy it up and package it. Repo and install instructions are available on my [GitHub](https://github.com/tomdeabreucodes/PyJig). If you're interested in a slightly longer post with some additional background, I also put a post up about it [here](https://tomdeabreu.uk/posts/jigsaw-puzzle-cut-template-svg/). [blank cut template](https://preview.redd.it/esielejcf7ac1.png?width=1320&format=png&auto=webp&s=2c9ceb9e18c5c5ffa4c4b07bbfcf6963b35138f5) &#x200B; [Applied cut on image](https://preview.redd.it/0b5i72uef7ac1.png?width=1320&format=png&auto=webp&s=229a039f2fc9363060698044eccbd6833f524af1) &#x200B;	0.0	t3_18xglbx	reddit		
69	llama.cpp GGUF inference in a couple lines of code	Unknown	2024-01-03 14:09:54	https://www.reddit.com/r/Python/comments/18xk9eo/llamacpp_gguf_inference_in_a_couple_lines_of_code/	&#x200B; https://preview.redd.it/l4r0ne7tf8ac1.png?width=1296&format=png&auto=webp&s=932ff628716371aa4770e574df9134d30c2bc9f5 [txtai](https://github.com/neuml/txtai) has a unified LLM pipeline that can load Hugging Face models, llama.cpp GGUF files and LLM APIs. The example above downloads a GGUF file from the Hugging Face Hub and runs inference with the model. See this article for more: [https://neuml.hashnode.dev/integrate-llm-frameworks](https://neuml.hashnode.dev/integrate-llm-frameworks)	1.0	t3_18xk9eo	reddit		
70	Python GUI framework for windows applications and embedded systems.	Unknown	2024-01-03 04:52:15	https://www.reddit.com/r/Python/comments/18xav2l/python_gui_framework_for_windows_applications_and/	A few months ago I saw someone posting maybe here or in another subreddit about a Python framework for making GUIs. I distinctly remember that it can be used to make guis for embedded systems as well as something similar to windows apps. Unfortunately, I forgot the name of it and can't seem to find that post anywhere. Does anyone have any clues as to what this framework is called? &#x200B; Many thanks\~	13.0	t3_18xav2l	reddit		
71	Polars DataFrames now have a `.plot` namespace!	:pandas_Logo: pandas Core Dev 	2024-01-02 16:32:49	https://www.reddit.com/r/Python/comments/18wti72/polars_dataframes_now_have_a_plot_namespace/	As of Polars 0.20.3, you can use \`polars.DataFrame.plot\` to visualise your data. The plotting logic isn't in Polars itself, but in hvplot (so you'll need that installed too) &#x200B; Here's some examples of what you can do: https://preview.redd.it/h8fhtnvi02ac1.png?width=693&format=png&auto=webp&s=5a299bac0df26575f3a4efa071707061cea719c4 https://preview.redd.it/k2071pvi02ac1.png?width=728&format=png&auto=webp&s=3ed2ce9e07f39b7c694f4dc8648647bed34daa60 https://preview.redd.it/r8t6oovi02ac1.png?width=680&format=png&auto=webp&s=907461be7c05fdd63b1b469cd8fd5c24c2b9741d https://preview.redd.it/bm8yuqvi02ac1.png?width=742&format=png&auto=webp&s=358da56c5c3e2d13bbf3576e655f3bc7b6e9d24a https://preview.redd.it/mi0udtvi02ac1.png?width=734&format=png&auto=webp&s=160f01651d2723742630cb5af50a90c74972c8d4	11.0	t3_18wti72	reddit		
72	I made an IDE using PyQt6 [UPDATE]	Unknown	2024-01-02 14:40:27	https://www.reddit.com/r/Python/comments/18wqxkm/i_made_an_ide_using_pyqt6_update/	&#x200B; [Editor](https://preview.redd.it/b79eg796g1ac1.png?width=1763&format=png&auto=webp&s=851ec11f48cc38652f96e4a515241dde89cf1705) [Markdown Editing](https://preview.redd.it/pi26k767g1ac1.png?width=1920&format=png&auto=webp&s=5eea5ff8f5f595a238a1010fb643183251306965) Highlighted Features: * Supports up to 30 languages w Syntax highlighting * auto complete * split pane markdown editor * terminal with Aura Text specific commands and also terminal history * plugin support * autocomplete (you can literally theme anything) GitHub: [https://github.com/rohankishore/Aura-Text](https://github.com/rohankishore/Aura-Text)	5.0	t3_18wqxkm	reddit		
73	"""Python For Developers"" course materials: code, mindmaps, assignments"	Unknown	2024-01-03 06:05:50	https://www.reddit.com/r/Python/comments/18xc8nf/python_for_developers_course_materials_code/	"Hello, Python community! I'm a Software Developer with more than a decade of experience in Python, and like many experienced developers, I often thought about how can I efficiently share my knowledge with my colleagues, and about a year ago I started working on my [Python for Developers](https://github.com/yuchdev/python) course materials. The course is advertised as ""created by developer for developers"", it assumes no knowledge of Python, but reasonable experience with other programming languages, an understanding of programming concepts such as algorithm complexity, design of classes and functions, IO and exceptions, and it does not include the most very basic stuff which is honestly quire irritating for developers who came from other languages. The completed part at the moment includes 15 lectures 1.5-2 hours each, mindmaps for every lecture to improve understanding, and now I'm working on the practical part. I approached the work very seriously, went through tens of books and other educational sources to collect and organize Python concepts from basic to advanced, and honestly think it's very hard now to find now another Python course with the same level of depth and attention to detail. I accept any reasonable contribution from the community, also I'd be happy to consider cooperation with any programming bootcamps and training centers, at the moment I'm available practically full-time for the possible test run of the course."	0.0	t3_18xc8nf	reddit		
74	🍀 How to Create Stunning Music Posters in Seconds: Introducing BeatPrints!	Unknown	2024-01-02 14:06:26	https://www.reddit.com/r/Python/comments/18wq7ru/how_to_create_stunning_music_posters_in_seconds/	&#x200B; https://preview.redd.it/2ae0jplk91ac1.png?width=1280&format=png&auto=webp&s=d6c6b7276f42dac753eb309e47fa6b12f49a1672 **Ever wondered how to create music posters like the ones you see on Pinterest?** 🎨 Maybe you've wanted something aesthetic to jazz up your Instagram stories or noticed your walls looking a tad empty? Perhaps you're the collector type or simply love decking out your space with artistic vibes? Look no further—introducing BeatPrints! 🎨 **What's BeatPrints?** BeatPrints is your one-stop tool for crafting eye-catching music posters that stand out! It's your gateway to generate custom, beautiful posters that capture the essence of your favorite music track from Spotify. **🤷 Why you want to use it?** * **Ease of Use:** Say goodbye to complex design software—BeatPrints makes poster creation straightforward and fun! * **Aesthetic Appeal:** Create posters perfect that's for Instagram, Pinterest, or maybe sprucing up your living space. * **Versatility:** Whether you're a collector, a decorator, or just love stylish visuals, BeatPrints has you covered. 🔗 **GitHub Project Link:** [BeatPrints on GitHub](https://github.com/TrueMyst/BeatPrints) Let BeatPrints transform your favourites music tracks into stunning posters! 🎨✨	1.0	t3_18wq7ru	reddit		
75	VLPC2.py released.	Unknown	2024-01-03 03:01:31	https://www.reddit.com/r/Python/comments/18x8n7j/vlpc2py_released/	https://izecksohn.com/pedro/python/VLPC2/VLPC2.py I needed an encryption script for very large binary files. So I created this. It was tested on PDF only. Please test it and report your experience.	0.0	t3_18x8n7j	reddit		
76	PyPy has moved to GitHub	pmatti - mattip was taken	2024-01-01 19:19:08	https://www.reddit.com/r/Python/comments/18w45u2/pypy_has_moved_to_github/	PyPy has moved its development efforts from Mercurial + Heptapod to Git + GitHub. Read more about it [here](https://www.pypy.org/posts/2023/12/pypy-moved-to-git-github.html)	7.0	t3_18w45u2	reddit		
77	Good pytube alternative?	Unknown	2024-01-02 20:44:17	https://www.reddit.com/r/Python/comments/18wzsg8/good_pytube_alternative/	I was using pytube to download my Shazam library and, well, it worked; but the AdBlock blocker in YouTube broke everything. Pytube cannot skip the ads, but is actively downloading them. Pytube seems discontinued. Does somebody know about a good alternative, or do I have to live without my downloader?	3.0	t3_18wzsg8	reddit		
78	Wednesday Daily Thread: Beginner questions	Unknown	2024-01-03 00:00:10	https://www.reddit.com/r/Python/comments/18x4mfq/wednesday_daily_thread_beginner_questions/	# Weekly Thread: Beginner Questions 🐍 Welcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you. ## How it Works: 1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here! 2. **Community Support**: Get answers and advice from the community. 3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources. ## Guidelines: * This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link). ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **What is the difference between a list and a tuple?** 2. **How do I read a CSV file in Python?** 3. **What are Python decorators and how do I use them?** 4. **How do I install a Python package using pip?** 5. **What is a virtual environment and why should I use one?** Let's help each other learn Python! 🌟	1.0	t3_18x4mfq	reddit		
79	i made a ChatGPT bot for Telegram	Unknown	2024-01-02 14:06:58	https://www.reddit.com/r/Python/comments/18wq86m/i_made_a_chatgpt_bot_for_telegram/	This project utilizing the new Assistant OpenAl API. link to source: https://github.com/andykras/gptbot Bot is built using the async features of aiogram and AsyncOpenAl, showcasing modern asynchronous programming in Python.	1.0	t3_18wq86m	reddit		
80	Arrest v0.1.5 is released! Including a lot of new improvements based on the community feedback!	Unknown	2024-01-02 05:45:30	https://www.reddit.com/r/Python/comments/18whybi/arrest_v015_is_released_including_a_lot_of_new/	Hi everyone! I am really happy to announce Arrest [v0.1.5](https://pypi.org/project/arrest/) after the overwhelming number of feedback from the community in my last post here. A brief overview of the changes made: &#x200B; * Added support for most of the httpx arguments (i.e., cookies, auth, transport, cert, etc) as kwargs in both service and resource initializations. * Added backoff retries for all the http calls being made with configurable max retries (set as environment variable) * Add a new decorator for a resource instance \`.handler(...)\` where you can specify the subpath from the resource and define your own custom function. The function is injected with a reference to the resource instance, and the complete url for easier access. The function can be triggered as a free function but also is registered under the resource instance, so can be invoked via \`resource\_name.func\_name(...)\` * Added support for passing your own \`httpx.AsyncClient\` instance to either service or resource. (can also be a subclass of \`httpx.AsyncClient\`) For more details, please check out the [docs](https://s-bose.github.io/arrest/). [Github repo](https://github.com/s-bose/arrest) for anyone who wants to take a look! Thank you to everyone whose feedback made these changes happen. I'd appreciate it if you could let me know of anything else that might be helpful to be implemented!	1.0	t3_18whybi	reddit		
81	Build amazing AI projects with Google’s Gemini models and Python	Unknown	2024-01-02 15:49:46	https://www.reddit.com/r/Python/comments/18wshab/build_amazing_ai_projects_with_googles_gemini/	Hi everyone, I’m excited to share with you my repository of Python projects and ideas that use Google’s latest and most powerful generative AI models: Gemini-pro and Gemini-pro-vision. These models can perform various tasks such as text-to-speech conversion, interactive chat, image and video processing, and content generation. With my repository, you can: * Convert any text into natural-sounding speech with Gemini-pro * Chat with a friendly and engaging AI assistant powered by Gemini-pro-chat * Recognize and analyze images and videos with Gemini-pro-vision * Generate diverse and dynamic content such as poems, stories, code, essays, and more with Gemini-pro My repository also provides educational insights and project ideas for students and researchers who want to learn more about Google’s Gemini models and their applications. You can explore the limitless possibilities of AI with Gemini and embark on a journey of innovation and discovery. If you are interested, please check out my repository here: [https://github.com/GitCoder052023/Build-with-Gemini](https://github.com/GitCoder052023/Build-with-Gemini) I would love to hear your feedback and suggestions on how to improve my projects and ideas. Feel free to leave a comment or open an issue on GitHub. Thank you for your time and attention. I hope you enjoy building amazing AI projects with Gemini and Python. 😊	0.0	t3_18wshab	reddit		
82	I made a program that solves mazes from images!	Unknown	2024-01-01 15:41:08	https://www.reddit.com/r/Python/comments/18vz81t/i_made_a_program_that_solves_mazes_from_images/	It was made in Python, except for one file that was written in Cython. You can read more about it here -> [https://github.com/triskj0/maze-solver](https://github.com/triskj0/maze-solver) I'll be glad some of you guys check it out, and maybe even try it for yourself! I am, of course, open to any suggestions on how to continue improving it. Have a nice day, everyone!	3.0	t3_18vz81t	reddit		
83	Hypercorn 0.16.0 released - a WSGI/ASGI server supporting HTTP 1, 2, 3 and Websockets	Unknown	2024-01-01 14:07:49	https://www.reddit.com/r/Python/comments/18vxfyu/hypercorn_0160_released_a_wsgiasgi_server/	Hypercorn is a WSGI and ASGI server that supports HTTP/1, HTTP/2, HTTP/3, and WebSockets. It also supports asyncio, uvloop, and trio worker classes. This release: - Adds ProxyFixMiddleware to make it much easier to run Hypercorn behind a proxy with the headers pointing at the client rather than the proxy. - A max_requests config that forces workers to restart when hit. This helps with memory leaks as the restart frees any leaked memory. - A max keep alive requests config that limits the requests per kept-alive connection. This mitigates the HTTP/2 rapid reset attack in the same manner as Nginx. - Finally fixes many bugs. [Read more](https://github.com/pgjones/hypercorn/blob/main/CHANGELOG.rst).	3.0	t3_18vxfyu	reddit		
84	Hey Guys! Just went looking back at older projects and found this one, its a level editor/maker!	Unknown	2024-01-02 00:47:48	https://www.reddit.com/r/Python/comments/18wbx3k/hey_guys_just_went_looking_back_at_older_projects/	It is a 2d level maker that taught me more about how pygame works, now I use Godot but I really appreciate this project for how much it taught me. Just wanted feedback, I know it looks bad being just colored squares but the code is really were I think I did the best. I dunno I dont code for a living, perhaps its pathetic and worthy of public shamming, let me know what you guys think. [link](https://github.com/GithubUserNotABot/Level-maker/blob/main/main.py)	2.0	t3_18wbx3k	reddit		
85	PDFSyntax, a new Python API library to inspect and update PDF files	Unknown	2024-01-01 20:35:21	https://www.reddit.com/r/Python/comments/18w5zj3/pdfsyntax_a_new_python_api_library_to_inspect_and/	Hi! This is my pet project, written from scratch because there is so much to discover and learn in the process. The focus is on API simplicity and incremental updates (a PDF feature that is often overlooked). Progress is slow because I do not have much spare time to work on this. This ALPHA quality software is far from finished but I would love to hear some feedback and feature requests. Here is the link to the project on GitHub: [https://github.com/desgeeko/pdfsyntax](https://github.com/desgeeko/pdfsyntax) Regards	1.0	t3_18w5zj3	reddit		
86	What is SLOW_SUM in the CPython source code?	Unknown	2024-01-01 11:39:31	https://www.reddit.com/r/Python/comments/18vv3aa/what_is_slow_sum_in_the_cpython_source_code/	File: `Python/bltinmodule.c` ([link to precise line](https://github.com/python/cpython/blob/471aa752415029c508693fa7971076f5148022a6/Python/bltinmodule.c#L2551C9-L2551C17)) While reading CPython's source code I came across the `SLOW_SUM` symbol, but I couldn't find its definition. `SLOW_SUM` is referenced only once in the entire CPython source code, so I couldn't find any information on why it exists. From the source code, I understand that it's a compiler flag that disables an optimization when performing sums on numeric types through the `sum()` built-in function. However, why would you pass `SLOW_SUM` to the compiler to disable optimized sums on numeric types? I don't know if this is the right place to ask such a specific question. If it's not, can you point me to the right forum?	3.0	t3_18vv3aa	reddit		
87	Arezzo: Automatic polyphonic piano music transcription in Python	Unknown	2024-01-01 23:38:59	https://www.reddit.com/r/Python/comments/18wacbi/arezzo_automatic_polyphonic_piano_music/	[https://github.com/Kat9-123/Arezzo](https://github.com/Kat9-123/Arezzo) Through the power of Machine Learning™ this program can take an audio file of (polyphonic) piano music and generate the corresponding sheet music! The code is dodgy in places, and not very well documented. As this was a school project, I didn't spend as much time as I'd have liked to refine it, because I simply ran out of time and steam. Especially the bits added last are very messy. Still, the UX is great, with a bunch of features easily accessible through a config file and command line switches. This is my first project using ML and audio processing, so that may explain why it lacks in some departments. So does it work? Sure, but not very well. Marginally worse than the free\* options I found online. *testing/results/TEST\_RESULTS\_V1.csv* contains some stats. It does have quite some limitations, as is doesn't recognise rests, tempo changes (like rubato), dynamics, articulations, upbeats and more. These limitations are bad, but not catastrophic. Oh and it actually generates MIDI files and uses MuseScore4 to generate the sheet music PDF's, but it does actually find key, tempo and time signature. \**Not really of course* **Please give feedback! :D**	0.0	t3_18wacbi	reddit		
88	Tuesday Daily Thread: Advanced questions	Unknown	2024-01-02 00:00:09	https://www.reddit.com/r/Python/comments/18watqc/tuesday_daily_thread_advanced_questions/	# Weekly Wednesday Thread: Advanced Questions 🐍 Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices. ## How it Works: 1. **Ask Away**: Post your advanced Python questions here. 2. **Expert Insights**: Get answers from experienced developers. 3. **Resource Pool**: Share or discover tutorials, articles, and tips. ## Guidelines: * This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday. * Questions that are not advanced may be removed and redirected to the appropriate thread. ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **How can you implement a custom memory allocator in Python?** 2. **What are the best practices for optimizing Cython code for heavy numerical computations?** 3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?** 4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?** 5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?** 6. **What are some advanced use-cases for Python's decorators?** 7. **How can you achieve real-time data streaming in Python with WebSockets?** 8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?** 9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?** 10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)** Let's deepen our Python knowledge together. Happy coding! 🌟	0.0	t3_18watqc	reddit		
89	Yet another multidirectory/multirepository git runner.	Unknown	2024-01-01 19:43:45	https://www.reddit.com/r/Python/comments/18w4quj/yet_another_multidirectorymultirepository_git/	Hi, I made this thing for git: [https://github.com/jasursadikov/mud](https://github.com/jasursadikov/mud) This tool allows you to run git commands in multiple repositories simultaneously. I was using other tools like that but mine has some features that I was looking for: 1. Asyncronous commands running 2. Nerd fonts to have some pretty view 3. Status table that shows what is going on with all repos that I have 4. Aliases, so I can safe 0.03125ms by avoiding typing long commands 5. Filtering. This tool can filter repos by branch/tag/modified/diverged 6. Global config and local configs.	1.0	t3_18w4quj	reddit		
90	I made a video showcasing the projects in 2023 using Python and Pygame!	Unknown	2024-01-01 09:49:27	https://www.reddit.com/r/Python/comments/18vtkcs/i_made_a_video_showcasing_the_projects_in_2023/	You can watch it here - [https://youtu.be/o6ISmnLqVDQ](https://youtu.be/o6ISmnLqVDQ) Source code for most of the project is available on my [GitHub page](https://github.com/robomarchello) Happy New Year everyone! And this is one of the projects: [pressure soft body simulation](https://i.redd.it/872nmxhrts9c1.gif)	1.0	t3_18vtkcs	reddit		
91	Do You Ever del?	Unknown	2023-12-31 20:48:20	https://www.reddit.com/r/Python/comments/18vgrc9/do_you_ever_del/	I've been coding in Python for years, mostly backend web-based stuff, but almost never `del` anything. Has anyone ever found interesting or compelling places to use it?	64.0	t3_18vgrc9	reddit		
92	Discover Your Personality Traits with Persai: A Python Package for detecting Big Five personality	Unknown	2024-01-02 17:46:06	https://www.reddit.com/r/Python/comments/18wvb6d/discover_your_personality_traits_with_persai_a/	Greetings everyone, I'm excited to introduce you to Persai, a Python package designed to provide deep insights into your personality. Using the Big Five personality traits model, Persai can analyze your Twitter posts and give you a unique perspective on your personality. All you have to do is input the tweets.js file you get when you export your Twitter data, and Persai will return your Big Five data. The technology behind Persai is GPT-4, and it's based on the findings from the paper “Is ChatGPT a Good Personality Recognizer? A Preliminary Study”. For more information about Persai, you can check out the GitHub repository here: https://github.com/yachty66/persai To delve deeper into what Persai can do, visit the website: https://www.persai.org/ Let's embark on this journey of self-discovery together! 🧭💼	2.0	t3_18wvb6d	reddit		
93	URL-Shorter with Python	Unknown	2024-01-01 16:55:06	https://www.reddit.com/r/Python/comments/18w0tw8/urlshorter_with_python/	Hi everyoen, I want to introduce my latest project, URL-Shorter; You can deploy your own url-shorter service with that repository. [https://github.com/uysalserkan/url-shorter](https://github.com/uysalserkan/url-shorter)	0.0	t3_18w0tw8	reddit		
94	chrono24 - a simple API wrapper for watch enthusiasts 🕒	Unknown	2024-01-01 04:57:33	https://www.reddit.com/r/Python/comments/18vpdsd/chrono24_a_simple_api_wrapper_for_watch/	"The [Chrono24](https://www.chrono24.com/) [API wrapper](https://github.com/irahorecka/chrono24/) is designed for watch enthusiasts in the Python community. This library offers in-depth access to Chrono24's watch listings. `pip install chrono24`, and explore brands and listings using simple Python commands: import chrono24 for listing in chrono24(query=""Rolex DateJust"").search(): print(listing) Dive into one of the biggest timepiece markets with [chrono24](https://github.com/irahorecka/chrono24) &#x200B; **Edit:** Given the constructive feedback from u/striata, the new API is as follows: import chrono24 for listing in chrono24.query(""Rolex DateJust"").search(): print(listing)"	1.0	t3_18vpdsd	reddit		
95	DocFlow - Document Management API	Unknown	2023-12-31 17:27:51	https://www.reddit.com/r/Python/comments/18vcjrw/docflow_document_management_api/	🚀 Excited to announce the release of DocFlow - a Document Management API! I have been working on this project from quite some tie now. And learnt a lot. Writing this post, just to share how year ended for me. DocFlow is build using u/FastAPI, PostgreSQL, AWS S3, and Docker. It provides document's Upload, Download, Organization, Searching, Versioning, Sharing, Access Control List, Deletion, Archiving, Authentication and Authorization. The complete documentation of the API and ways to test and run DocFlow is mentioned on the GitHub Repository. 🖇️ [Here](https://github.com/jiisanda/docflow) 📩 I invite you to the repo, to do a code review, suggest changes and collaborate over the Discussions of [DocFlow](https://github.com/jiisanda/docflow/discussions). Happy Coding 🙆‍♂️! **#DocFLow** **#DocumentManagement** **#API** **#release** **#github** **#fastapi** **#aws** **#docker** **#postgresql** **#awsservices** **#python** [DocFlow](https://preview.redd.it/nlqs5ypm0o9c1.png?width=500&format=png&auto=webp&s=bf8aa96aa81771c6208703844c4f9e004d7259e9)	3.0	t3_18vcjrw	reddit		
96	Monday Daily Thread: Project ideas!	Unknown	2024-01-01 00:00:08	https://www.reddit.com/r/Python/comments/18vkgtu/monday_daily_thread_project_ideas/	"# Weekly Thread: Project Ideas 💡 Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you. ## How it Works: 1. **Suggest a Project**: Comment your project idea—be it beginner-friendly or advanced. 2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code. 3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration. ## Guidelines: * Clearly state the difficulty level. * Provide a brief description and, if possible, outline the tech stack. * Feel free to link to tutorials or resources that might help. # Example Submissions: ## Project Idea: Chatbot **Difficulty**: Intermediate **Tech Stack**: Python, NLP, Flask/FastAPI/Litestar **Description**: Create a chatbot that can answer FAQs for a website. **Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM) # Project Idea: Weather Dashboard **Difficulty**: Beginner **Tech Stack**: HTML, CSS, JavaScript, API **Description**: Build a dashboard that displays real-time weather information using a weather API. **Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8) ## Project Idea: File Organizer **Difficulty**: Beginner **Tech Stack**: Python, File I/O **Description**: Create a script that organizes files in a directory into sub-folders based on file type. **Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/) Let's help each other grow. Happy coding! 🌟"	2.0	t3_18vkgtu	reddit		
97	Stockstir is a tool written in Python that lets you get stock information from any script at no cost - Version 2 is officially out!	Unknown	2023-12-31 00:53:09	https://www.reddit.com/r/Python/comments/18uuyjr/stockstir_is_a_tool_written_in_python_that_lets/	"Hello again! A few days ago I showcased my Stockstir project which I had made a while ago. You can refer to that thread [here](https://www.reddit.com/r/Python/comments/18sxqsc/stockstir_is_a_python_project_that_lets_you_get/). V2 is out! You can take a look at the [documentation](https://stockstir.readthedocs.io/en/latest/index.html) for up-to-date information on the new functions, enhancements, and fixes in the project. Also, the project link is here: [Stockstir Link](https://github.com/PatzEdi/Stockstir) As far as additions and suggestions which were made on the previous thread, Stockstir V2 now has a complete fail-safe system that uses more than one provider. It also has initial integration of an Alpha Vantage API (to be further developed still, now it is just an initial integration), and new options to gather prices and other stock info through CNBC and their JSON format API (Thank you to [Gr1pp717](https://www.reddit.com/user/Gr1pp717/) for that information!). As far as the quick usage, nothing has changed: ``` import Stockstir price = Stockstir.getSinglePrice(""ticker/stockSymbol"") print(price) ``` With the new provider system, the default provider is still CNBC. However, you can set a provider manually (There are three as of now) like so: ``` from Stockstir import Providers Providers.provider_number = 1 # Here, you can put any number that is between 0 and 2, as there are three providers now. The default remains 0. ``` The new fail-safe system automatically picks other providers in case one fails, bringing more reliability to the library as a whole. If you want to manually check if providers are working, you can do this: ``` from Stockstir import Providers Providers.runProviderChecks() ``` Hope you enjoy! Edit: Some suggestions/improvements have already been suggested in one of the comments below, thank you so much for that information, super useful! Here is the [link of the improvements that will come soon to Stockstir V2](https://www.reddit.com/r/Python/comments/18uuyjr/comment/kfnju1d/?utm_source=share&utm_medium=web2x&context=3)"	5.0	t3_18uuyjr	reddit		
98	I Created a game (kind of)	Unknown	2023-12-31 16:07:45	https://www.reddit.com/r/Python/comments/18vattd/i_created_a_game_kind_of/	I created a practice app to practice wordle (more specifically Duotrigordle), and I was wondering if anyone would be interested in playing it/testing it. Here's the github: [https://github.com/dcjvliet/Duotrigordle](https://github.com/dcjvliet/Duotrigordle) The code's pretty messy, but it's all open source and I figured I might as well share it. If you do decide to play it, feel free to leave feedback here.	0.0	t3_18vattd	reddit		
99	Transfer YouTube History from One Channel to Another Channel Using Python	Unknown	2023-12-30 20:54:06	https://www.reddit.com/r/Python/comments/18upgvh/transfer_youtube_history_from_one_channel_to/	*Transfer YouTube History from One Account to Another Account Using Python.* **Information:** There is no direct way to transport YouTube history from one account to another; you have to use Python to do it. It will take some time. - I've created a Python script that automates the transfer for you; it will take 10 seconds for each link. **Advice:** Be aware that you will need to monitor the transport because YouTube will detect unusual traffic, and it will sign out all your logged-in accounts. Therefore, I ADVISE YOU TO SAVE YOUR PASSWORD if you don't know it. **Preparation:** 1. Visual Studio Code 2. Google Chrome browser 3. MS Excel **Exporting youtube history:** 1. Go to [https://takeout.google.com](https://takeout.google.com/) 2. Choose the account (or brand account if you have more than one YouTube channel). 3. Click Deselect all. Check only: YouTube and YouTube Music section (Scroll to the end). 4. Click multiple formats: Scroll to history and change HTML to JSON, hit Ok. 5. Click All YouTube data included: Deselect all and choose only history. 6. Click next step. 7. Create export. 8. It will be sent to your email. 9. Create an empty folder called YoutubeHistory. This folder is for running every Python script that I will provide. 10. Drag and drop the watch-history.json file into the YoutubeHistory folder. **Convert JSON file to txt file using python:** 1. Create python script named: , save it in the YoutubeHistory folder. 2. Load this script and click save: &#8203; import json # Load the JSON data from the file with specified encoding with open('watch-history.json', 'r', encoding='utf-8') as file: data = json.load(file) urls = [] # Extract the URLs from the JSON data for item in data: if 'titleUrl' in item: urls.append(item['titleUrl']) if 'subtitles' in item: for subtitle in item['subtitles']: if 'url' in subtitle: urls.append(subtitle['url']) # Save the URLs to a text file with open('urls.txt', 'w') as file: for url in urls: file.write(url + '\n') Now click Ctrl+F5 to run the script. - You will get urls.txt file in the YoutubeHistory folder. **MS Excel (Organizing the history from old to new and removing duplicates):** First: You will need to remove the duplicates: 1. Copy the links from urls.txt and paste in a new excel work book. 2. CTRL+A to select all. - Click data: Remove duplicates and hit ok. Second: You will need to order the links (Old to New): 1. On column B: Number the links starting from 1. 2. CTRL+A to select all. 3. Click data: Sort. 4. Choose Sort by column B & Order by largest to smallest. Third: 1. Now create txt file and name it Flipped.txt in the YoutubeHistory folder. 2. Copy the links from the excel file and paste them in Flipped.txt **Transferring the history:** 1. Make sure you have selected the correct YouTube channel that you want to transfer to. 2. Open an empty tab in Chrome tab and keep it open. 3. Create python script named: automate\_youtube\_history.py , save it in the YoutubeHistory folder. 4. Load this script and click save: &#8203; import webbrowser import time import pyautogui # Read the URLs from a text file with open('Flipped.txt', 'r') as file: urls = file.readlines() urls = [url.strip() for url in urls] # Open each URL in a web browser for url in urls: webbrowser.open(url) time.sleep(10) # Close the current tab (you might need to adjust the coordinates) pyautogui.hotkey('ctrl', 'w') # This shortcut closes the current tab Now click Ctrl+F5 to run the script. **The process:** I recommend that you monitor the process every hour or 30 minutes because after some time, you may get logged out from all your accounts (this happened to me after 2 hours). If this occurs: 1. Stop the Python script from running. 2. Go to your watch history, and check the last video it stopped on. 3. Remove the links that were transferred successfully and keep the others. 4. Re-run the script.	11.0	t3_18upgvh	reddit		
100	BALanced Execution through Natural Activation : a human-computer interaction methodology for code running	Unknown	2023-12-31 10:20:47	https://www.reddit.com/r/Python/comments/18v4yqg/balanced_execution_through_natural_activation_a/	BALENA is a voice interaction framework utilizing state-of-the-art natural language processing and audio processing models to create a system that can interpret voice commands and associate them with predefined actions. The framework leverages the power of transformers and signal processing to understand user intent via spoken language and correlates them with a series of predefined actionable responses. [Framework workflow](https://preview.redd.it/juxyviw4wl9c1.png?width=6130&format=png&auto=webp&s=ce2a4cd2ba32dc062a704a1544a48233319ef432) ## Features * **Real-time audio streaming and recording**: Record audio from the microphone in real time for processing. * **Speech recognition with Wav2Vec 2.0**: Use a pre-trained Wav2Vec 2.0 model to convert speech to text. * **Text similarity and action triggering**: Encode the transcribed text to a vector space and find the closest action using sentence similarity techniques. * **High-pass filtering**: Process the audio signal with a high-pass filter to enhance signal quality. * **Auto-correction**: Utilize the Jaccard distance to correct words in the transcribed text auto-magically. * **Framework flexibility**: Support for different device execution contexts, allowing for usage on both CPU and CUDA devices. Link to the repo : [https://github.com/louisbrulenaudet/balena](https://github.com/louisbrulenaudet/balena)	0.0	t3_18v4yqg	reddit		
101	Sunday Daily Thread: What's everyone working on this week?	Unknown	2023-12-31 00:00:09	https://www.reddit.com/r/Python/comments/18utrn3/sunday_daily_thread_whats_everyone_working_on/	# Weekly Thread: What's Everyone Working On This Week? 🛠️ Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to! ## How it Works: 1. **Show & Tell**: Share your current projects, completed works, or future ideas. 2. **Discuss**: Get feedback, find collaborators, or just chat about your project. 3. **Inspire**: Your project might inspire someone else, just as you might get inspired here. ## Guidelines: * Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome. * Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here. ## Example Shares: 1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate! 2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better. 3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier! Let's build and grow together! Share your journey and learn from others. Happy coding! 🌟	6.0	t3_18utrn3	reddit		
102	RecoverPy 2.1.5: Python file recovery tool	Unknown	2023-12-30 17:25:15	https://www.reddit.com/r/Python/comments/18uknqm/recoverpy_215_python_file_recovery_tool/	&#x200B; https://i.redd.it/t1foxzpbvg9c1.gif **Github**: [https://github.com/PabloLec/RecoverPy](https://github.com/PabloLec/RecoverPy) Hey everyone! I'm here to share something I've been working on for nearly three years now, RecoverPy, and its new 2.1.5 version. It's a nifty tool that can really be a lifesaver when you've accidentally deleted or overwritten files. It works its magic by conducting a text-based search to find the lost data. It sports a TUI built with Textual. I found it to be quite enjoyable to use and it seems many others agree, given its rise as one of the most (or the most?) popular TUI libraries in Python, despite still being in beta. Since its creation, RecoverPy has gone through quite a transformation. It's integrated lots of feedback from its user community, improved many aspects to enhance the user experience, and even underwent almost a full rewrite to switch up the TUI library in its second version. Essentially, it uses the strength of grep and dd to sift through partition blocks, giving you a user-friendly way to sift through the results. Interestingly, it found a niche not only among individuals looking to recover files but has also piqued interest in the hacking scene, which was a bit of a pleasant surprise for me. It seems the tool lends itself well to that sphere too. I manage to chip away at it from time to time, given that my free moments are becoming a bit of a rarity these days. It still has room to grow, and if anyone here feels like contributing, I'm more than open to collaborations. Your PRs would certainly be welcome! Feel free to give it a glance, and if you find it interesting or useful, a star on the repository would be greatly appreciated.	2.0	t3_18uknqm	reddit		
103	A small collection of lesser-known statistical functions - obscure_stats	Unknown	2023-12-30 09:17:56	https://www.reddit.com/r/Python/comments/18ubr4s/a_small_collection_of_lesserknown_statistical/	Hello r/Python I’m excited to share with you my new python package called `obscure_stats`. It is a collection of lesser-known statistical functions that are not available in the standard libraries like `scipy`, `statsmodels`, or `numpy`. The package is still in development, but I hope you will find it useful and interesting. You can install it with `pip install obscure_stats` or check out the source code on [GitHub](https://github.com/glevv/obscure_stats). I would appreciate any feedback, suggestions, or bug reports.	4.0	t3_18ubr4s	reddit		
104	My first public package: wigner-symbols	Unknown	2023-12-31 02:39:08	https://www.reddit.com/r/Python/comments/18ux6et/my_first_public_package_wignersymbols/	Hi everyone! I would like to share my first public repository with you all: [wigner-symbols](https://github.com/sheodun/wigner-symbols). This package just calculates Wigner [3j](https://en.wikipedia.org/wiki/3-j_symbol) and [6j](https://en.wikipedia.org/wiki/6-j_symbol) symbols, which are commonly used in quantum mechanics for calculating coefficients of angular momentum coupling. I come from a research background and often relied on a [very good site](https://www-stone.ch.cam.ac.uk/wigner.shtml) to check these symbol values, but I would rather use a python package; so I decided to make my own. It is a small repo and there isn't much here at the moment but it performs the job. I would really appreciate your feedback. Thank you! Edit: I have not been able to publish the package on PyPi yet as registration is temporarily suspended but I plan to once we are able to again	1.0	t3_18ux6et	reddit		
105	The Python Mega Course is still free on Udemy	Unknown	2023-12-29 13:34:26	https://www.reddit.com/r/Python/comments/18tn8y0/the_python_mega_course_is_still_free_on_udemy/	"As some of you may know, ""**The Python Mega Course: Build 10 Real World Applications**"" is one of the top Python courses on Udemy. Last year, I made that version of the course available for free to the Reddit community, and I am doing the same today. In 2023, the course attracted 20,000+ students and collected 900+ reviews, achieving an exceptionally high average rating of 4.8/5 on Udemy. This makes the course exceptionally highly rated on Udemy. **How can you get the course for free today?** Three simple steps: 1. Login to Udemy. 2. Go to the course page: [https://udemy.com/course/former-python-mega-course-build-10-real-world-applications/](https://udemy.com/course/former-python-mega-course-build-10-real-world-applications/) 3. Enter the password **mega\_course** to get the course for free. Thanks and have a relaxing end of the year!"	109.0	t3_18tn8y0	reddit		
106	Grep over IPython output!	Unknown	2023-12-30 13:17:40	https://www.reddit.com/r/Python/comments/18ufgl3/grep_over_ipython_output/	Hi there! i just finish a little project allowing you to use `grep` over IPython output like so: ```ipython In [1]: {i:i for i in range(3)} Out[1]: {0: 0, 1: 1, 2: 2, } In [2]: %greps 1 Out[2]: ' 1: 1,\n' ``` [https://github.com/royreznik/greps](https://github.com/royreznik/greps)	1.0	t3_18ufgl3	reddit		
107	A Free AI Scribe Project I am Working on! Please Provide Feedback!	Unknown	2023-12-30 16:26:16	https://www.reddit.com/r/Python/comments/18ujbet/a_free_ai_scribe_project_i_am_working_on_please/	Thought I would share a project that I have been working on. AI medical scribe products have popped up everywhere but have been very expensive to deploy. I wrote a program that can connect with a local server running a version of ChatGPT and Speech-To-Text that can take a conversation via microphone and create a SOAP note. You can turn off the AI scribe and use it in a normal chat-based manner. The LLM variables are locked in on the executable option since I wrote this for an end-user physician. Looking for any feedback (I am very much an amateur) from the community! What proved to be a bit tricky was developing a client that could use the device's microphone. [https://github.com/1984Doc/AI-Scribe](https://github.com/1984Doc/AI-Scribe)	0.0	t3_18ujbet	reddit		
108	Less is More? An Empirical Study on Configuration Issues in Python PyPI Ecosystem	Unknown	2023-12-30 09:19:48	https://www.reddit.com/r/Python/comments/18ubs0y/less_is_more_an_empirical_study_on_configuration/	The utilization of third-party libraries can potentially lead to conflicts in dependencies, prompting researchers to develop dependency conflict detectors. Specifically, the researchers propose PyCon, a source-level detector, for detecting potential configuration issues. [https://arxiv.org/abs/2310.12598](https://arxiv.org/abs/2310.12598) &#x200B;	2.0	t3_18ubs0y	reddit		
109	UdemyPy - The Free Udemy courses bot	Unknown	2023-12-30 15:33:16	https://www.reddit.com/r/Python/comments/18ui5nc/udemypy_the_free_udemy_courses_bot/	UdemyPy is an open-source Python project with the mission of making education accessible to everybody. It brings free Udemy courses directly to you on [WhatsApp](https://www.whatsapp.com/channel/0029VaHwvWZ7NoZsk8UOUl0z) and [Telegram](https://t.me/freecourses000). # How it Works UdemyPy scours the web for Udemy courses offering a 100% discount, ensuring you have access to a diverse range of subjects in any language. When looking for free courses shared by UdemyPy, remember to check the offer time left. Once it’s expired, the course will no longer be free. Whenever you find a course you like, click on the link and enroll in it. Despite the fact that courses are free only for a limited amount of time, once you are enrolled *they will be yours forever!* # Why UdemyPy? * Free of Charge: No payment methods needed; just create a Udemy account. * Unrestricted Learning: Explore courses in any category or language. * Supportive: UdemyPy supports content creators in reaching a wider audience. # Learn More Explore the project on [GitHub](https://github.com/dylannalex/udemypy). Feel free to show your support with a 🌟 if you find the project intriguing!	0.0	t3_18ui5nc	reddit		
110	Coding year in review 2023!	Unknown	2023-12-30 14:56:19	https://www.reddit.com/r/Python/comments/18uhdfv/coding_year_in_review_2023/	Love to hear your thoughts on last year with coding and coming year. Here's to our first script of 2024! https://www.youtube.com/watch?v=YcmKs2M1xAo	1.0	t3_18uhdfv	reddit		
111	Curser, and other AI code editors	Unknown	2023-12-30 13:24:15	https://www.reddit.com/r/Python/comments/18ufktx/curser_and_other_ai_code_editors/	Do you use these types of tool editors to help write code more effectively/efficiently? What are you using?	3.0	t3_18ufktx	reddit		
112	How to prevent python software from being reverse engineered or pirated?	Unknown	2023-12-29 03:56:54	https://www.reddit.com/r/Python/comments/18tdmiv/how_to_prevent_python_software_from_being_reverse/	I have a program on the internet that users pay to download and use. I'm thinking about adding a free trial, but I'm very concerned that users can simply download the trial and bypass the restrictions. The program is fully offline and somewhat simple. It's not like you need an entire team to crack it. In fact, there is literally a pyinstaller unpacker out there that can revert the EXE straight back to its python source code. I use pyinstaller. Anything I can do? One thing to look out for is unpackers, and the other thing is how to make it difficult for Ghidra for example to reverse the program. Edit: to clarify, I can't just offer this as an online service/program because it requires interaction with the user's system.	89.0	t3_18tdmiv	reddit		
113	CRAP - Clear Redundant Added Packages	Unknown	2023-12-29 16:20:45	https://www.reddit.com/r/Python/comments/18tqu9m/crap_clear_redundant_added_packages/	[https://github.com/ValdonVitija/crap](https://github.com/ValdonVitija/crap) Automatically clear redundant packages from virtual environments in python 🐍📦🗑️.	7.0	t3_18tqu9m	reddit		
114	Jake: A Free Alternative to Linktree Using GitHub Pages	Unknown	2023-12-29 10:47:28	https://www.reddit.com/r/Python/comments/18tkf7e/jake_a_free_alternative_to_linktree_using_github/	"Hello, I wanted to share a new Python project I've been working on called Jake. It's an alternative to popular link aggregator services like Linktree and OneLink. Jake leverages the power of GitHub Pages to provide you with a hassle-free way to create your one-link website. The best part? It won't cost you a dime! With Jake, you can easily showcase all your important links and content in one central hub, neatly organized and easily accessible. Your website will have a sleek URL in the format of ""username.github.io,"" giving it a professional touch. Jake is completely written in Python and uses the \`tinyhtml\` library to generate static HTML websites. Simply fill in the \`data.toml\` file with your information, and Jake will automatically build and deploy your website to GitHub Pages using a GitHub action. To give you a taste of what Jake can do, I've prepared a demo project for you to explore. Just visit [https://thevahidal.github.io/jake](https://thevahidal.github.io/jake) and see the potential for yourself. If you're interested in contributing or want to dive deeper into the project, you can find the Jake repository on GitHub at [https://github.com/thevahidal/jake](https://github.com/thevahidal/jake). I welcome all contributions, feedback, and bug reports. Your input will help shape the future of Jake and make it even better. Thank you for taking the time to read about Jake. I can't wait to see what we can achieve together. Best regards, Al"	9.0	t3_18tkf7e	reddit		
115	Tastymap, create/customize matplotlib color palettes for your palate	Unknown	2023-12-29 19:51:02	https://www.reddit.com/r/Python/comments/18tvpdz/tastymap_createcustomize_matplotlib_color/	"The number of colormaps matplotlib felt limiting to me so I created a web app and Python package to customize existing colormaps or start from scratch! from tastymap import cook_tmap tmap = cook_tmap( [""red"", ""green"", ""blue""], num_colors=256, reverse=True ) Install by: \`pip install tastymap\` or try it online here: [TastyKitchen - a Hugging Face Space by ahuang11](https://huggingface.co/spaces/ahuang11/tastykitchen) [TastyKitchen](https://i.redd.it/hf6fm1ukga9c1.gif) Docs here: [TastyMap (ahuang11.github.io)](https://ahuang11.github.io/tastymap/) Code here: [ahuang11/tastymap: colormaps cooked for your palate (github.com)](https://github.com/ahuang11/tastymap) There's also a way to have AI suggest a colormap based on a description: from tastymap import ai tmap = ai.suggest_tmap(""Pikachu"") tmap [Pikachu](https://preview.redd.it/3clppe0pga9c1.png?width=512&format=png&auto=webp&s=82b5570b05cd3b1f07683a7b837860d4442ce9ff)"	0.0	t3_18tvpdz	reddit		
116	No formal schooling	Unknown	2023-12-29 14:42:58	https://www.reddit.com/r/Python/comments/18ton3n/no_formal_schooling/	I’m been doing a lot of at home python training in my free time. I do have an associates degree but it’s in an entirely unrelated field. I’m just wondering what the job market would like for me with no degree in the python field. I’ve heard that some places only care if you actually know the material, regardless of formal education.	20.0	t3_18ton3n	reddit		
117	UniDep: Unified Conda and Pip dependency management via pyproject.toml	Unknown	2023-12-29 20:50:55	https://www.reddit.com/r/Python/comments/18tx3pm/unidep_unified_conda_and_pip_dependency/	"[UniDep](https://github.com/basnijholt/unidep) streamlines Python project dependency management by unifying Conda and Pip packages in a single system. Handling dependencies in Python projects can be challenging, especially when juggling Python and non-Python packages.This often leads to confusion and inefficiency, as developers juggle between multiple dependency files. - **📝 Unified Dependency File**: Use either `requirements.yaml` or `pyproject.toml` to manage both Conda and Pip dependencies in one place. - **⚙️ Build System Integration**: Integrates with Setuptools and Hatchling for automatic dependency handling during `pip install ./your-package`. - **💻 One-Command Installation**: `unidep install` handles Conda, Pip, and local dependencies effortlessly. - **🏢 Monorepo-Friendly**: Render (multiple) `requirements.yaml` or `pyproject.toml` files into one Conda `environment.yaml` file and maintain fully consistent global *and* per sub package `conda-lock` files. - **🌍 Platform-Specific Support**: Specify dependencies for different operating systems or architectures. - **🔧 `pip-compile` Integration**: Generate fully pinned `requirements.txt` files from `requirements.yaml` or `pyproject.toml` files using `pip-compile`. - **🔒 Integration with `conda-lock`**: Generate fully pinned `conda-lock.yml` files from (multiple) `requirements.yaml` or `pyproject.toml` file(s), leveraging `conda-lock`. ### Example #### Example `requirements.yaml` Example of a `requirements.yaml` file: ```yaml name: example_environment channels: - conda-forge dependencies: - numpy # same name on conda and pip - conda: python-graphviz # When names differ between Conda and Pip pip: graphviz - pip: slurm-usage >=1.1.0,<2 # pip-only - conda: mumps # conda-only # Use platform selectors - conda: cuda-toolkit =11.8 # [linux64] local_dependencies: - ../other-project-using-unidep # include other projects that use unidep - ../common-requirements.yaml # include other requirements.yaml files - ../project-not-managed-by-unidep # 🚨 Skips its dependencies! platforms: # (Optional) specify platforms that are supported (used in conda-lock) - linux-64 - osx-arm64 ``` > `unidep` can process this during `pip install` and create a Conda installable `environment.yaml` or `conda-lock.yml` file, and more! > For a more in-depth example containing multiple installable projects, see the [`example`](https://github.com/basnijholt/unidep/tree/main/example) directory. #### Example `pyproject.toml` ***Alternatively***, one can fully configure the dependencies in the `pyproject.toml` file in the `[tool.unidep]` section: ```toml [tool.unidep] channels = [""conda-forge""] dependencies = [ ""numpy"", # same name on conda and pip { conda = ""python-graphviz"", pip = ""graphviz"" }, # When names differ between Conda and Pip { pip = ""slurm-usage >=1.1.0,<2"" }, # pip-only { conda = ""mumps"" }, # conda-only { conda = ""cuda-toolkit =11.8:linux64"" } # Use platform selectors by appending `:linux64` ] local_dependencies = [ ""../other-project-using-unidep"", # include other projects that use unidep ""../common-requirements.yaml"" # include other requirements.yaml files ""../project-not-managed-by-unidep"" # 🚨 Skips its dependencies! ] platforms = [ # (Optional) specify platforms that are supported (used in conda-lock) ""linux-64"", ""osx-arm64"" ] ``` This data structure is *identical* to the `requirements.yaml` format, with the exception of the `name` field and the [platform selectors](#platform-selectors). In the `requirements.yaml` file, one can use e.g., `# [linux64]`, which in the `pyproject.toml` file is `:linux64` at the end of the package name. Check out https://github.com/basnijholt/unidep"	1.0	t3_18tx3pm	reddit		
118	Voicebox: Python TTS lib with built-in audio effects	Unknown	2023-12-29 19:27:39	https://www.reddit.com/r/Python/comments/18tv650/voicebox_python_tts_lib_with_builtin_audio_effects/	"Hello there, I'm sharing a project I've been working on for some future robotics projects, and would appreciate some feedback. It's called [Voicebox](https://voicebox.readthedocs.io) ([GitHub](https://github.com/austin-bowen/voicebox)), and it's a Python library that essentially provides wrappers for a bunch of different text-to-speech programs/APIs, and includes lots of built-in audio effects like vocoder, ring mod, glitch, etc. It also includes [example voices](https://voicebox.readthedocs.io/en/stable/voicebox.examples.html) like Star Wars battle droid, GlaDOS, and 343 Guilty Spark. Audio samples [here](https://voicebox.readthedocs.io/en/stable/samples.html). The ""problem"" I was trying to solve was that a lot of TTS programs sound *too* realistic now, and I want an easy way to make audio from TTS sound more fun/robotic. There are also utilities like [`reliable_tts`](https://voicebox.readthedocs.io/en/stable/voicebox.html#voicebox.utils.reliable_tts) and [`ParallelVoicebox`](https://voicebox.readthedocs.io/en/stable/voicebox.voiceboxes.html#voicebox.voiceboxes.parallel.ParallelVoicebox) that make it easy to build responsive and robust TTS systems, which is important for robot projects. LMK what you think! &#x200B; Example: Use gTTS with a vocoder effect to speak in a robotic voice from voicebox import SimpleVoicebox from voicebox.tts import gTTS from voicebox.effects import Vocoder, Normalize voicebox = SimpleVoicebox( tts=gTTS(), effects=[Vocoder.build(), Normalize()], ) voicebox.say('Hello, world! How are you today?')"	0.0	t3_18tv650	reddit		
119	A Python monorepo template	Unknown	2023-12-29 16:55:20	https://www.reddit.com/r/Python/comments/18trmnq/a_python_monorepo_template/	Hey all! 👋 Just wanted to share a Python monorepo template I've been working on. It's designed to streamline managing multiple packages in one place. I've incorporated tools like Poetry, Black, mypy, and Ruff for setup and linting, plus my personal touch with [Breadcrumbs](https://github.com/niqodea/breadcrumbs) for cleaner path management. Happy to hear your feedback or ideas! Check it out here: https://github.com/niqodea/python-monorepo	1.0	t3_18trmnq	reddit		
120	A Python implementation of Conway's Game of Life (Cellular Automaton)	Unknown	2023-12-29 15:56:03	https://www.reddit.com/r/Python/comments/18tq9ns/a_python_implementation_of_conways_game_of_life/	I am a student of both mathematics and computer science, so I coded up a terminal-based implementation of John Conway's Game of Life. Check it out here: [https://github.com/atiumcache/game\_of\_life](https://github.com/atiumcache/game_of_life) It is packaged as an executable for UNIX, so you can quickly get it playing. Or, just view the demo on the README.	1.0	t3_18tq9ns	reddit		
121	Saturday Daily Thread: Resource Request and Sharing! Daily Thread	Unknown	2023-12-30 00:00:19	https://www.reddit.com/r/Python/comments/18u1fep/saturday_daily_thread_resource_request_and/	"# Weekly Thread: Resource Request and Sharing 📚 Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread! ## How it Works: 1. **Request**: Can't find a resource on a particular topic? Ask here! 2. **Share**: Found something useful? Share it with the community. 3. **Review**: Give or get opinions on Python resources you've used. ## Guidelines: * Please include the type of resource (e.g., book, video, article) and the topic. * Always be respectful when reviewing someone else's shared resource. ## Example Shares: 1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms. 2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures. 3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators. ## Example Requests: 1. **Looking for**: Video tutorials on web scraping with Python. 2. **Need**: Book recommendations for Python machine learning. Share the knowledge, enrich the community. Happy learning! 🌟"	1.0	t3_18u1fep	reddit		
122	Pure Recipe is a CLI app to save or view online recipes in well-formatted markdown. No more ads!	Unknown	2023-12-28 22:51:15	https://www.reddit.com/r/Python/comments/18t726b/pure_recipe_is_a_cli_app_to_save_or_view_online/	I am a long-time cook and aspiring developer, so I made a command-line recipe viewer to bypass the ads and blogs that plague recipe websites. It can also save the recipes to markdown. You can even pass in a whole list of URLs to save a bunch of recipes at once. Similar to Paprika, except it is free/open-source and you can easily save and share the recipes in markdown format. Check it out on GitHub, I would appreciate any feedback/testers: [https://github.com/atiumcache/pure-recipe](https://github.com/atiumcache/pure-recipe)	9.0	t3_18t726b	reddit		
123	Oreiller: An image library for easy Pillow manipulations.	 Python&OpenSource	2023-12-29 08:44:43	https://www.reddit.com/r/Python/comments/18til8l/oreiller_an_image_library_for_easy_pillow/	Really, [oreiller](https://www.google.com/search?q=oreiller) is the french word for a pillow. I always heard about the PIL fork, Pillow but never used it. When I finally used it, I found it to be tedious sometimes. Like including emojis in text and the general programming. I finally got around to create a small library WIP called oreiller \[[pypi](https://pypi.org/project/oreiller/) | [github](https://github.com/Abdur-RahmaanJ/oreiller)\]. &#x200B; Code demo &#x200B; https://preview.redd.it/r8ixcd8f579c1.png?width=682&format=png&auto=webp&s=3f137f150c3c1482bd38f5d1d8005fd56057e368	1.0	t3_18til8l	reddit		
124	I created a program to align thousands of selfies for daily picture videos!	Unknown	2023-12-29 02:08:34	https://www.reddit.com/r/Python/comments/18tbeet/i_created_a_program_to_align_thousands_of_selfies/	I started taking pictures 'everyday' in 2019 after seeing [Hugo's famous video](https://www.youtube.com/watch?v=65nfbW-27ps), but after aligning \~40 pictures I knew the process had to be automated. Since I barely knew python at the time, and I still find myself learning more and more everyday, it's taken a lot of on and off work, but now I have a script that can do what would've taken years of consistent effort in a few minutes. Even though another solution *kinda* exists, I'm super proud of it because it's mine (I say kinda because I couldn't get it to work for me). Here's the github repo with a lot of details on how it works: [https://github.com/Noah6544/Daily-Picture-Aligner](https://github.com/Noah6544/Daily-Picture-Aligner) Here's my video explanation: [https://www.youtube.com/watch?v=\_ow6GLv7VSA&](https://www.youtube.com/watch?v=_ow6GLv7VSA&) Please let me know ***any*** feedback you have!	1.0	t3_18tbeet	reddit		
125	A Better Way to Wrangle Figures Out of Jupyter Notebooks	Unknown	2023-12-29 07:24:08	https://www.reddit.com/r/Python/comments/18thcub/a_better_way_to_wrangle_figures_out_of_jupyter/	"*Stop wasting time saving plots manually — automate it with an extra line of code!* Hopping in to share a bit of Python that's been in my everyday workflow for the last 2 years. Finally decided it would be worth the lift to put out there for others to use, too. I always get bogged down naming things --- and **saving visualizations out of notebooks after finishing up analysis work** is a particular sore spot. So, I wrote a one-off tool to use plotting arguments to automatically name plot outputs. It ended up getting reused over and over, and then eventually became *teeplot.* *teeplot* wraps plotting calls with logic that **automatically manages matplotlib file output**, picking **meaningful file names** based on the plotting function and semantic plotting variables. # Example This example shows a call to *seaborn*'s **lmplot** dispatched through **teeplot.tee** to save out the visualization as '*teeplots/col=time+hue=sex+viz=lmplot+x=total-bill+y=tip+ext={.pdf,.png}'.* Here's what a *teeplot*'ed notebook cell and output look like, # adapted from seaborn.pydata.org/generated/seaborn.FacetGrid.html import seaborn as sns from teeplot import teeplot as tp tp.tee(sns.lmplot, # plotter, then forwarded args/kwargs sns.load_dataset(""tips""), col=""time"", hue=""sex"", x=""total_bill"", y=""tip"") https://preview.redd.it/sj6f6u69q69c1.png?width=5880&format=png&auto=webp&s=4c684e13bd05336f710545298fb3ff436ffa02f1 >teeplots/col=time+hue=sex+viz=lmplot+x=total-bill+y=tip+ext=.pdfteeplots/col=time+hue=sex+viz=lmplot+x=total-bill+y=tip+ext=.png The idea here is to make the process of saving and cataloging plots more *efficient, systematic, and meaningful*, taking the hassle out of manual file management. # Further Information *teeplot* can be installed as python3 -m pip install teeplot The library has additional advanced features, as well, including an interface to globally configure visualization output file types (i.e., "".pdf"", "".png""), etc. You can read more in the project's [*usage guide*](https://github.com/mmore500/teeplot/blob/master/README.rst#usage) and [*API listing*](https://github.com/mmore500/teeplot/blob/master/README.rst#api). *disclaimer*: am library author"	0.0	t3_18thcub	reddit		
126	Efficient Range Joins in Pandas	Unknown	2023-12-29 12:07:11	https://www.reddit.com/r/Python/comments/18tlpg0/efficient_range_joins_in_pandas/	[pyjanitor](https://pyjanitor-devs.github.io/pyjanitor/) has a [conditional_join](https://pyjanitor-devs.github.io/pyjanitor/api/functions/#janitor.functions.conditional_join.conditional_join) function that offers good performance on range joins in Pandas, avoiding the cross/cartesian join. I also wrote a [blog post](https://samukweku.github.io/data-wrangling-blog/notebooks/Fast-and-Efficient-Inequality-Joins-in-Pandas.html), as well as a [pyohio presentation](https://youtu.be/AjdBLOAhgDI?si=jWOP7QlzPpTcr7II) regarding inequality joins in pandas. Feel free to raise an issue on the [pyjanitor github issue page](https://github.com/pyjanitor-devs/pyjanitor/issues) if you encounter any difficulties.	1.0	t3_18tlpg0	reddit		
127	Stockstir is a Python project that lets you get any company stock price instantly from any script at no cost.	Unknown	2023-12-28 16:21:09	https://www.reddit.com/r/Python/comments/18sxqsc/stockstir_is_a_python_project_that_lets_you_get/	"Hello! This is Stockstir, a project I did a while ago. I just wanted to share it in case any of you have update suggestions, and also because it might be useful to all of you wanting to get stock prices from your scripts instantly. This project allows anyone to instantly get a company stock price from any of your python scripts. Not only that, but it includes other tools and features to help you gather necessary stock data, such as saving the data to a file, or even a multi-data gathering function with adjustable parameters that include antiBan, random user agent,the delay per request, and more. You can get it here: [Stockstir Link](https://github.com/PatzEdi/Stockstir) As soon as it is downloaded, you can place this line of code in your script: ``` import Stockstir price = Stockstir.Tools.getSinglePrice(""ticker/stockSymbol"") print(price) ``` Make sure to replace what is in between the quotes with the actual Ticker symbol you want to gather the price for. Edit: Based on the comments that were posted on this thread, I am currently working on a new update for Stockstir. Thank you for the great advice! Edit 2: V2 has been released! Check out the details here: [V2 Post Link](https://www.reddit.com/r/Python/s/NshHDcdeuO)"	6.0	t3_18sxqsc	reddit		
128	pytest mock	Unknown	2023-12-28 16:23:09	https://www.reddit.com/r/Python/comments/18sxsig/pytest_mock/	As per today what is the most bulletproof real life python unit testing/mocking framework? I found after some research that is pytest, but for the mocks which i need to massively use, the standard (= most used library) is unittest.mock with patch or the wrapper pytest-mock? &#x200B;	16.0	t3_18sxsig	reddit		
129	Populate template automatically from resumes	Unknown	2023-12-29 09:35:35	https://www.reddit.com/r/Python/comments/18tjccx/populate_template_automatically_from_resumes/	Hi everyone! I’m playing around with this and my goal is set up a service where I can upload any resume/cv then have it broken down into the core parts I’m interested in such as job, employers, job titles, key skills, dates of employment etc that will then populate a standardised template I’ve setup. Current thoughts are to use the ChatGPT API to create a MVP/ proof of concept via python. Is the easiest ways to convert the cvs and the template to JSON’s, and pull that data across using tags or should I be considering another approach? I’ve been using ChatGPT to analyse CV’s I upload into it and it s been doing pretty good so far in terms of analysing the resumes. If I get this going I would expect to train a model or something like that to increase efficiency. Obviously the template would need to be dynamic as there’s no set amount of jobs anyone has on their CV/ resume. The code I’ve got is rough as so far but I’m keen on how others would approach this situation? TIA	1.0	t3_18tjccx	reddit		
130	Nur the AI empowered self actualizing documentation chat bot	Unknown	2023-12-29 20:58:03	https://www.reddit.com/r/Python/comments/18tx9fj/nur_the_ai_empowered_self_actualizing/	An AI powered system that helps you find relevant documentation, identifies gaps in its knowledge, collects feedback and develops your knowledge base based on questions, answers, feedback and unanswered questions. Open source. Open for contributions. Supports confluence and slack and developing further. Nur The self actualizing documentation framework that heals its knowledge gaps as naturally as a ray of light Custom GPT to discuss the code base Chat with the custom gpt about the solution: https://chat.openai.com/g/g-zKBLXtfrD-shams-nur Feature list Done: add a confluence space (url credentials and update interval) Pulls the confluence space and stores it in a sqlite database Vectorizes the confluence space pages and stores the embeds in a chroma db collection Uses the vectorized embeds to find the most similar pages to a question Creates an assistant with the relevant pages and allows it to engage to provide the answer Listens on specific slack channels for questions relevant to its domain Implement fast response using Gpt-4 Turbo without assistant Implemented persist queue for page content retrieval and vectorization Todo: Move slack processed ids to sqlite database setup last update date and schedule to update confluence space with log in db store embeds in database create new vector database nightly and on trigger from sql database add questions, answers and reactions (- enable confluence edit or new page recommendation) add credibility rating to database trivia question collector consider removing assistants all together https://github.com/MDGrey33/Nur	0.0	t3_18tx9fj	reddit		
131	Analytics with Python	Unknown	2023-12-29 01:18:30	https://www.reddit.com/r/Python/comments/18tacyc/analytics_with_python/	New Python data analysis tutorial website at [https://dataprep.us](https://dataprep.us) (or [https://pareek.org/ba](https://pareek.org/ba)). Includes notebooks and videos on data munging, regression, shallow ML, deep learning, time series and NLP. Just a simple read-the-docs style website with no logins, sign-ups, ads or anything. Would love feedback and suggestions. Thanks in advance.	0.0	t3_18tacyc	reddit		
132	Python lib written in rust for fast bounding box manipulation	Unknown	2023-12-28 19:45:55	https://www.reddit.com/r/Python/comments/18t2nwe/python_lib_written_in_rust_for_fast_bounding_box/	See the repo here: https://github.com/Smirkey/powerboxes Some functions available are NMS (classical or with rtree) distance metrics (IoU, GIoU) and utils (box format conversion, area computation) ! Feedback would be greatly appreciated, hope it can be useful in your computer vision projects :)	1.0	t3_18t2nwe	reddit		
133	An implementation of the Python turtle library in C++ using SDL2	Unknown	2023-12-28 18:56:25	https://www.reddit.com/r/Python/comments/18t1i5k/an_implementation_of_the_python_turtle_library_in/	[https://github.com/dafiliks/tortoise](https://github.com/dafiliks/tortoise) Check it out, read the README and give feedback, thanks!	0.0	t3_18t1i5k	reddit		
134	embuild - a small tool for embedded C/CMake project library management	Unknown	2023-12-28 12:47:46	https://www.reddit.com/r/Python/comments/18st51s/embuild_a_small_tool_for_embedded_ccmake_project/	I wrote [embuild](https://pypi.org/project/embuild/) \- a small tool. Also I hooked up a website [listing available libraries](https://embuild.dev/). For now these are mine only [from my curated library repository](https://github.com/g2labs-grzegorz-grzeda/embuild-repository). Here is the my [embuild GitHub repo link](https://github.com/g2labs-grzegorz-grzeda/embuild), though I encourage you to install it through `pip`. I was looking for a small and robust tool to handle my embedded C projects. I use CMake for project building. I know there are others ready, like `conan` or `vcpkg` but they were way to overblown. So I decided to write my own. &#x200B; Give it a shot and tell me what you think.	0.0	t3_18st51s	reddit		
135	Friday Daily Thread: r/Python Meta and Free-Talk Fridays	Unknown	2023-12-29 00:01:10	https://www.reddit.com/r/Python/comments/18t8nwl/friday_daily_thread_rpython_meta_and_freetalk/	# Weekly Thread: Meta Discussions and Free Talk Friday 🎙️ Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related! ## How it Works: 1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community. 2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community. 3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting. ## Guidelines: * All topics should be related to Python or the /r/python community. * Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy). ## Example Topics: 1. **New Python Release**: What do you think about the new features in Python 3.11? 2. **Community Events**: Any Python meetups or webinars coming up? 3. **Learning Resources**: Found a great Python tutorial? Share it here! 4. **Job Market**: How has Python impacted your career? 5. **Hot Takes**: Got a controversial Python opinion? Let's hear it! 6. **Community Ideas**: Something you'd like to see us do? tell us. Let's keep the conversation going. Happy discussing! 🌟	0.0	t3_18t8nwl	reddit		
136	Duotrigordle Practice	Unknown	2023-12-28 17:35:48	https://www.reddit.com/r/Python/comments/18szjwd/duotrigordle_practice/	The popular game Wordle has an alternative version, called Duotrigordle. In this version of the game, instead of trying to solve one word, you are trying to solve 32 words at the same time. A couple weeks ago I set out on a journey to set the world record for the fastest time to complete all 32 words. The world record, 19.62 is incredibly hard to beat, and I realized that I wouldn't be able to do it without practicing certain skills. This is why I created Duotrigordle Practice, a tool to practice specific skills related to this game. Hopefully now I will be able to break the world record. However, this practice tool could be fun for some people, and I figured I might as well share it out to the public. It is still a work in progress, but it's mostly there. I hope you enjoy, and if you have suggestions, bugs, or anything else, feel free to dm me on discord at minestone4306 or post it on github. Here is the link to the github which has all of the source code and download instructions: [https://github.com/dcjvliet/Duotrigordle](https://github.com/dcjvliet/Duotrigordle)	0.0	t3_18szjwd	reddit		
137	RuGiVi - Adult media landscape browser	Unknown	2023-12-27 17:38:11	https://www.reddit.com/r/Python/comments/18s68rl/rugivi_adult_media_landscape_browser/	I wrote a python app using pygame to fly over an image collection (in my case, an adult collection) and view thousands of images at once. Zoom in and out from one image to small thumbnails with your mousewheel in seconds. Here is the code: [https://github.com/pronopython/rugivi](https://github.com/pronopython/rugivi) &#x200B; https://preview.redd.it/mgw70srpiv8c1.jpg?width=1200&format=pjpg&auto=webp&s=03e1324c4396a621d04a8673cc23a91dc36dd66c All images are grouped as you have them on your disk and arranged in a huge landscape. RuGiVi can work with hundred thousand of images at once. It runs under Linux and Windows. \- Works with hundreds of thousands of images at the same time \- Tested with around 700.000 images (see the world map shown here), that's a RuGiVi Pixel size of 4.600.000 x 4.400.000 pixels or 20.240.000 Megapixels or 10.120.000 Full HD Screens to be scrolled through \- Dynamic view rendering - screen is updated partially when drawing takes more time \- Thumbnails are cached in a database I'm really looking forward on feedback (it's still an alpha release), ideas... :-) I have more open source apps written in python to organize and enjoy a collection, have a look at them: [https://github.com/pronopython](https://github.com/pronopython)	13.0	t3_18s68rl	reddit		
138	I made a Django webapp to create memorial pages quickly and easily	Unknown	2023-12-28 00:04:16	https://www.reddit.com/r/Python/comments/18sffil/i_made_a_django_webapp_to_create_memorial_pages/	"Hi all! After several months of having no ideas to launch or work on, I'm finally launching a small SaaS to create memorial pages for our beloved ones who have passed away. To be honest, I got this idea in the worst scenario. Here's the story... Recently, one of my family members passed away, and as a software engineer, I felt compelled to use my Python / Django skills to create something meaningful in his honor. I discovered nice platforms for creating memorial pages, like Cake, Forever Missed, Much Loved, and so forth. However, given my mental state at the time, I felt there were too many steps and overwhelming options to get this done quickly. So, I turned to **carrd.com** and created a very basic page with a link to send emails to my wife and me, where you could share condolences, support messages, book recommendations, and so forth. After that, I thought, ""Why not create a platform to build these kinds of pages in just one step and start receiving support from friends and family without feeling pressured to answer the messages?"" And after two weeks, I created [easytribute.com](http://easytribute.com/) Source code [https://github.com/mariorojas/easytribute](https://github.com/mariorojas/easytribute) Feel free to take a look, and thank you all for your support and feedback."	4.0	t3_18sffil	reddit		
139	Update on My Python Tool for OpenAI API - New Features and Improvements!	Unknown	2023-12-28 18:35:57	https://www.reddit.com/r/Python/comments/18t10k6/update_on_my_python_tool_for_openai_api_new/	Hello! A little while back, I shared [a Python tool I was working on to manage the OpenAI API](https://www.reddit.com/r/Python/comments/18f8i0y/gpt_helped_me_build_a_python_tool_to_work_with/) (← link to original post), and I'm super excited to update you all on some new features and improvements! As someone who's relatively new to Python, diving into this project has been an incredible learning experience. I've been relying on GPT's guidance to help me overcome hurdles and flesh out my ideas, and it's amazing how much progress we've made together. Click here to check it out: 👉 [OpenAI Python Tools on GitHub](https://github.com/richarddas/OpenAI-Python-Tools) Here’s what’s new in the tool: * **Enhanced Error Handling**: I've added robust error handling, so the tool is now more stable and user-friendly, especially when dealing with errors or incorrect inputs. * **Local Caching for Threads**: To streamline thread management, the tool now caches thread IDs locally, making it easier to keep track of your active threads. * **UI Clarity Improvements**: I've tweaked the user interface to be less confusing, especially when navigating between menus and making selections. These updates aim to make the tool even more intuitive and efficient for managing assistants, threads, and files within the OpenAI environment. As a beginner in Python, but with a background in other programming languages, this project has been a great challenge. Working with GPT not only helped me build a tool that I needed, but it also accelerated my learning in Python. It's empowering to realize that with the right tools and resources, we can create solutions and explore our ideas, no matter our starting skill level. I'd love for you all to try out the updated tool and share any feedback or suggestions. Your insights are invaluable and will help make this tool even better for everyone working with the OpenAI API. Thanks for all the support and encouragement so far!	1.0	t3_18t10k6	reddit		
140	Django python backend for a dating social app 🐍	Unknown	2023-12-27 21:21:22	https://www.reddit.com/r/Python/comments/18sbk1v/django_python_backend_for_a_dating_social_app/	Good project to play around and explore Django REST features &#x200B; Repo -> [https://github.com/damianstone/toogether-backend](https://github.com/damianstone/toogether-backend) Frontend repo -> [https://github.com/damianstone/toogether-mobile](https://github.com/damianstone/toogether-mobile) &#x200B; **Some Django REST features used** \- Channels and websockets \- Geolocation \- Pagination \- Auth token \- ModelViewSets &#x200B; [Figma screen of the app functionalities](https://preview.redd.it/s1yf2ykxmw8c1.png?width=6801&format=png&auto=webp&s=c80e7671cc5430772830b6466cc3dd2f3276c290) **App features** \- login / register using auth token \- user profile \- matching algorithm \- swipe group and single profiles \- create group profiles using an invitation code \- group chat and 1-1 chats \- report and block \- recovery password &#x200B;	10.0	t3_18sbk1v	reddit		
141	ML Program using face recognition which analyze your face structure and measure how close it is to golden ratio	Unknown	2023-12-28 15:45:01	https://www.reddit.com/r/Python/comments/18swvoo/ml_program_using_face_recognition_which_analyze/	I know it's pretty simple project but if you can add some feature or implementation I am open to contributions. [https://github.com/Crevils/faceGoldenRatio](https://github.com/Crevils/faceGoldenRatio) (Give a star)	0.0	t3_18swvoo	reddit		
142	Blackline + Python	Unknown	2023-12-28 00:50:57	https://www.reddit.com/r/Python/comments/18sginp/blackline_python/	Are there any accountants that have used Python in conjunction with Blackline or even replaced some functionality such as Blackline matching and automated journal entry processes? If so what and how?	4.0	t3_18sginp	reddit		
143	baozi- a dataclass alternative with a greater emphasis on the 'class' aspect.	Unknown	2023-12-27 23:57:34	https://www.reddit.com/r/Python/comments/18sf9jy/baozi_a_dataclass_alternative_with_a_greater/	"github repo: [baozi-github](https://github.com/raceychan/baozi) Hi guys, I am here to introduce my new project 'baozi' to you. baozi aims to be a strictly superset of dataclass, so that user can have a very flat learning curve. besides what datalcass offers, baozi adds extra features like: * Inheritance * Immutability & Immutability check * Keyword-only arguments and random order attributes * Support user-defined __pre_init__ method that gets executed before class instantiation you can use baozi like this: ```python from baozi import Struct, FrozenStruct, field from datetime import datetime class Event(FrozenStruct): name: str create_at: datetime = field(default_factory=datetime.now) >> e = Event(name=""event"") >> assert isinstance(e.created_at, datetime) >> e.created_at = datetime.now() dataclasses.FrozenInstanceError: cannot assign to field 'created_at' ``` or ``` from baozi import Struct from dataclasses import asdict class B(Struct): name: str age: int @classmethod def __pre_init__(cls, **data): data[""age""] = int(data[""age""]) return data assert asdict(B(name=""name"", age=""15"")) == {""name"": ""name"", ""age"": 15} ``` The very first motivation for this project was that during developement I was getting really tired of duplicated @dataclass(...) decorators all over my codebase, so I decided to implement a more class-based dataclass alternative. since I am also a big fan of DDD, I added some extra features for improvements on immutability, hasing and memory efficiency. baozi is still in its early deveolopment stage, but it now has 100% test coverage, I hope you would be nice enough to give it a try, any feedback is highly appreciated. There is also a rationale for the existence of this project in the github README, I hope it will help explain why not go stright to pydantic or similar projects."	2.0	t3_18sf9jy	reddit		
144	Raycasting game in Python and Pygame Part 3	Unknown	2023-12-27 16:52:20	https://www.reddit.com/r/Python/comments/18s55am/raycasting_game_in_python_and_pygame_part_3/	I made a raycasting game using Python and Pygame Code: [https://github.com/DataWizual/Raycasting\_Part\_3](https://github.com/DataWizual/Raycasting_Part_3) Here's the video explaining how I did it: [https://youtu.be/znIAg\_6\_Od4](https://youtu.be/znIAg_6_Od4)	0.0	t3_18s55am	reddit		
145	Looking for some packages similar to Laravel's Jetstream and Cashier for subscriptions	Unknown	2023-12-27 13:10:35	https://www.reddit.com/r/Python/comments/18s0d46/looking_for_some_packages_similar_to_laravels/	For a new project at my job we're debating our new project's framework. We're in between Django and Laravel. Since I read Django is much faster and more secure (plus I'd like to do a Python project) we'd like to give that a shot. That said: it is a subscription based project that allows users to call API's, embed chat widgets etc. Laravel has some great plugins/packages for that and that's creating doubt. Is anybody aware of any such similar Python modules that can handle subscription management (subscribe, pause, trials, cancel, refund etc.) using Stripe (and others). Our current projects are in Slim 4 (PHP) and FastAPI (Python) mostly, so we're new to both Laravel and Django. Any suggestions are welcome, thank you. &#x200B;	2.0	t3_18s0d46	reddit		
146	Thursday Daily Thread: Python Careers, Courses, and Furthering Education!	Unknown	2023-12-28 00:00:09	https://www.reddit.com/r/Python/comments/18sfbsg/thursday_daily_thread_python_careers_courses_and/	# Weekly Thread: Professional Use, Jobs, and Education 🏢 Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**. --- ## How it Works: 1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles. 2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources. 3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally. --- ## Guidelines: - This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar. - Keep discussions relevant to Python in the professional and educational context. --- ## Example Topics: 1. **Career Paths**: What kinds of roles are out there for Python developers? 2. **Certifications**: Are Python certifications worth it? 3. **Course Recommendations**: Any good advanced Python courses to recommend? 4. **Workplace Tools**: What Python libraries are indispensable in your professional work? 5. **Interview Tips**: What types of Python questions are commonly asked in interviews? --- Let's help each other grow in our careers and education. Happy discussing! 🌟	0.0	t3_18sfbsg	reddit		
147	I created a web application that solves hidato puzzles from images!	Unknown	2023-12-27 23:32:46	https://www.reddit.com/r/Python/comments/18seo9w/i_created_a_web_application_that_solves_hidato/	Hidato is a logic puzzle containing a hexagonal grid of cells. The goal is to fill the grid with numbers such that consecutive numbers are in cells adjacent to each other. The solver uses image processing and deep learning to extract the grid from the image, then it uses CSP-based techniques to solve the puzzle. web application link: [https://assafvol-hidatosolverwebapp-app-1dptmp.streamlit.app/](https://assafvol-hidatosolverwebapp-app-1dptmp.streamlit.app/) Github repo - [https://github.com/assafvol/HidatoSolverWebApp](https://github.com/assafvol/HidatoSolverWebApp)	1.0	t3_18seo9w	reddit		
148	FinderZ V 2.1.2 Released	Unknown	2023-12-27 19:33:28	https://www.reddit.com/r/Python/comments/18s90lz/finderz_v_212_released/	Hello! FinderZ V2.1.2 has been released. FinderZ is a file management library in python that can do many things (in order to save time by not having to do the functions yourself). It has many features including Synchronization of folders, backing up of multiple folders, a full GatherInfo class as well as a fileOperands class. The latest release 2.1.2 includes new GatherInfo Functions as well as fileOperands functions, such as XOR encryption/decryption of files/directories, and a new data gathering function that gets all the file extensions in a directory and their specific amount in order, and returns them in a dictionary. Check out the project here: [FinderZ](https://github.com/PatzEdi/FinderZ) The documentation will be updated in the next release (2.1.5) as it is outdated as of now. I hope you find FinderZ useful! In the link provided above you will be able to find the installation instructions as well as a changelog which has started from version 2.1.2 onward. If you have any comments or concerns on what I should improve, please let me know.	3.0	t3_18s90lz	reddit		
149	Refactor using SOLID principles amounted to good speedup	Unknown	2023-12-27 03:19:17	https://www.reddit.com/r/Python/comments/18rqeev/refactor_using_solid_principles_amounted_to_good/	I've been reading about SOLID principles and used this knowledge to refactor 2 out of the 4 functions provided in PyPi's unexpected-isaves, and this amounted to a \~1.3x speedup, even though making things run faster was not my first intention. I just wanted to make the project better for the new stargazers arriving. This shows the importance of good and simple code. [Eric-Mendes/unexpected-isaves: A Python library that paints an image on a spreadsheet, builds its pixel art in Minecraft, makes its ascii art, or makes a rubik's cube art out of it. (github.com)](https://github.com/Eric-Mendes/unexpected-isaves)	2.0	t3_18rqeev	reddit		
150	Increase details of videos (from 🌱 to 🪴)	Unknown	2023-12-26 12:28:44	https://www.reddit.com/r/Python/comments/18r7487/increase_details_of_videos_from_to/	&#x200B; [Drive through rain](https://i.redd.it/nkkm6x0skm8c1.gif) I have been working on an interesting project for a while. The aim of the project is to implement some of the known ways of augmenting image details and enhance their contrast. I would absolutely appreciate it if you checkout my code repository and share your opinion. This video is enhanced using the following code base 🐍: [Two-dimensional histogram equalization and contrast enhancement](https://github.com/Mamdasn/im2dhisteq) Full video link: [https://youtu.be/7LrzX2ZpLAQ](https://youtu.be/7LrzX2ZpLAQ) Other image/video quality/contrast enhancers that I have implemented: * [Histogram-Based Locality-Preserving Contrast Enhancement](https://github.com/Mamdasn/imhblpce) * [Fast Image/Video Contrast Enhancement Based on Weighted Thresholded Histogram Equalization](https://github.com/Mamdasn/imWeightedThresholdedheq) All these modules strive to make details in images/videos more prominent and remove haziness in them as much as possible. &#x200B;	3.0	t3_18r7487	reddit		
151	Wednesday Daily Thread: Beginner questions	Unknown	2023-12-27 00:00:08	https://www.reddit.com/r/Python/comments/18rm8k7/wednesday_daily_thread_beginner_questions/	# Weekly Thread: Beginner Questions 🐍 Welcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you. ## How it Works: 1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here! 2. **Community Support**: Get answers and advice from the community. 3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources. ## Guidelines: * This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link). ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **What is the difference between a list and a tuple?** 2. **How do I read a CSV file in Python?** 3. **What are Python decorators and how do I use them?** 4. **How do I install a Python package using pip?** 5. **What is a virtual environment and why should I use one?** Let's help each other learn Python! 🌟	2.0	t3_18rm8k7	reddit		
152	Automaticly type a specific word when the chat is spamming it on kick.com. multiple accounts and threats at the same time.	Unknown	2023-12-27 20:24:12	https://www.reddit.com/r/Python/comments/18sa7fa/automaticly_type_a_specific_word_when_the_chat_is/	is the idea that I just typed out a good idea to make in python? I think I could also make it in JS as it is on a browser but I feel like pixel detection could be a good idea too. what is your ideas on it? (you get points when you type a specific word in the chat and you get money for those points)	3.0	t3_18sa7fa	reddit		
153	Data Structures and Algorithms	Unknown	2023-12-26 14:44:28	https://www.reddit.com/r/Python/comments/18r9kw7/data_structures_and_algorithms/	Hello everyone! For some time on this community, there was a complete google drive style playlist regarding Data Structures and Algorithms in Python. I followed it for some months but I did not finish the entire classes. I guess it was the one attached to this thread on this community [https://www.reddit.com/r/Python/comments/lyux3w/the\_complete\_data\_structures\_and\_algorithms/](https://www.reddit.com/r/Python/comments/lyux3w/the_complete_data_structures_and_algorithms/) Is there anyone that has the correct link to the referred playlist? Thanks in advance!	3.0	t3_18r9kw7	reddit		
154	py-cachify - cache-based locks and handy caching decorators	Unknown	2023-12-26 16:43:01	https://www.reddit.com/r/Python/comments/18rc6e6/pycachify_cachebased_locks_and_handy_caching/	Hey everybody! Sharing [**py-cachify**](https://github.com/EzyGang/py-cachify) which I just wrote and published that provides cache-based locks and decorators that come in handy around the locks and caching. Inspiration to start it came from [douglasfarinelli's python-cachelock](https://github.com/douglasfarinelli/python-cachelock) library since it's no longer maintained but the tool has proven to be very useful in my past projects. Check it out!	2.0	t3_18rc6e6	reddit		
155	Financial-Analyzer CLI App: an argument for use	Unknown	2023-12-26 04:19:13	https://www.reddit.com/r/Python/comments/18qzi6d/financialanalyzer_cli_app_an_argument_for_use/	"Hello r/Python, With Mint closing as an option for many to track personal finances and some renewed interest on my end for finance app....... I'm writing this post on this Christmas in regards to a [Github project](https://github.com/andersbandt/Financial-Analyzer/blob/main/README.md) based around financial analysis. The app in function is written in Python and is meant to analyze one's personal finances, with a main window page looking like so &#x200B; https://preview.redd.it/8cw1xyn0ek8c1.png?width=836&format=png&auto=webp&s=4fc99bdebe4b2e6cefe2910dbb3e22303e29648e The application analysis your financial spending based on data from a directory of monthly statements (typically in .csv format) from various credit cards / banks one has. It is quite easy for one to pull this data from any account like Apple Card, Venmo, Wells Fargo, U.S. Bank, etc. So each month 15-20 mins of effort is required from user to get data, but it's not that hard. My analysis on spending is performed against a preset ""tree of categories"" which allows one to get quite granular with spending data. &#x200B; [a printout of my personal category tree](https://preview.redd.it/e7zo4qrydk8c1.png?width=794&format=png&auto=webp&s=bfdca5b52bb4c3600a37f81eef16e1438bc24284) This project was brought up in [this Reddit post](https://www.reddit.com/r/Python/comments/zrv4hx/would_anyone_be_interested_in_collaborating_on_a/) when the main focus was on a GUI based version of the app (originally used Tkinter library as GUI framework). However, it is **my belief** that a CLI based version of this application is best for an open-source direction. Coding for a GUI with a full-fledged API like Flask or Django and a proper front-end like React is **not worth the time**. CLI applications (like the Linux bash shell) are perfectly functional, and honestly better than most clunky GUI applications for their linearity) My personal progress on this project has increased exponentially since switching to a CLI based application. So with Mint closing their doors feel free to try and get this app running on your machine. Likely you will encounter program bugs. But they should be easily fixable. I also setup a Discord about a year ago for discussion. Check it out [here at this Discord link](https://discord.gg/WEPzzJhs)"	6.0	t3_18qzi6d	reddit		
156	Seeking Suggestions for Enhancing my PyPI Package eagelview - Image Dataset Visualization	Unknown	2023-12-26 14:12:24	https://www.reddit.com/r/Python/comments/18r8y6d/seeking_suggestions_for_enhancing_my_pypi_package/	Hey everyone, I've been developing a PyPI package called eagelview aimed at visualizing image datasets by printing images from folder(s) and adding labels from .csv(s) files, facilitating image dataset visualization. I'm eager to expand its functionality and make it more versatile. Any ideas, suggestions, or features you think would be valuable to include in eagelview would be greatly appreciated! Looking forward to hearing your thoughts. Thanks in advance! \[Check out eagleview on GitHub\](https://github.com/hexronuspi/eagleview)	2.0	t3_18r8y6d	reddit		
157	Unofficial reverse-engineered ChatGPT API in Python	Unknown	2023-12-26 13:58:49	https://www.reddit.com/r/Python/comments/18r8oj0/unofficial_reverseengineered_chatgpt_api_in_python/	I wanted to create a discord bot that I could use to chat with ChatGPT through discord (for fun and to learn how discord bots worked). but the issue was that I couldn't afford to buy the ChatGPT Plus plan to get access to the API. So, I tried to find a way around this problem and found [reverse-engineered ChatGPT API by Antonio Cheong](https://github.com/acheong08/ChatGPT). But as you can see, Antonio Cheong stopped maintaining the API, so it doesn't work anymore (at least not for me). So, I decided to try and make my own for fun. I would really appreciate it if you check it out and tell me what you think (and advise me on how I can make it better if possible). thanks!!!! repo link: [https://github.com/Zai-Kun/reverse-engineered-chatgpt](https://github.com/Zai-Kun/reverse-engineered-chatgpt)	2.0	t3_18r8oj0	reddit		
158	cookiecutter-python-cli-app -- a cookiecutter template for creating a new Python command-line application with Click	Unknown	2023-12-26 14:38:05	https://www.reddit.com/r/Python/comments/18r9g70/cookiecutterpythoncliapp_a_cookiecutter_template/	While there exist many great [cookiecutter](https://github.com/cookiecutter/cookiecutter) templates for Python packages, web applications and data science & machine learning, for example, I was surprised to find virtually none for command-line applications. [The one I did find](https://github.com/simonw/click-app) is pretty basic, and does not have the feature set I was looking for. As such, I took it upon myself to create and publish a great cookiecutter template for CLI's, called **[cookiecutter-python-cli-app](https://github.com/sgraaf/cookiecutter-python-cli-app)**. The template supports Python 3.8, 3.9, 3.10, 3.11 and 3.12 and uses the venerate [Click](https://click.palletsprojects.com/) package to create beautiful and powerful command-line interfaces. It has many other features, like: - Linting with autofix (i.e. removing unused imports, formatting and Python syntax upgrades) with [ruff](https://beta.ruff.rs/docs/) - Code formatting with [ruff](https://beta.ruff.rs/docs/) and [Prettier](https://prettier.io/) - Static type-checking with [mypy](http://www.mypy-lang.org/) - Checks and fixes before every commit with [pre-commit](https://pre-commit.com/) - Testing with [pytest](https://docs.pytest.org/en/stable/index.html) - Project automation with [Nox](https://nox.thea.codes/en/stable/) - Continuous Integration with [GitHub Actions](https://github.com/features/actions) and [pre-commit.ci](https://pre-commit.ci/) - Automated version updates for GitHub Actions with [Dependabot](https://docs.github.com/en/code-security/dependabot/working-with-dependabot/keeping-your-actions-up-to-date-with-dependabot) - Documentation with [Sphinx](https://www.sphinx-doc.org/en/master/), [MyST](https://myst-parser.readthedocs.io/en/latest/), and [Read the Docs](https://readthedocs.org/) using the [Furo](https://pradyunsg.me/furo/) theme - Automated release builds and uploads to [PyPI](https://pypi.org/) Thank you for taking the time to read this! Please give it a try and let me know your thoughts. :)	0.0	t3_18r9g70	reddit		
159	A few questions and concerns about the dataclass PEP	Unknown	2023-12-26 12:13:00	https://www.reddit.com/r/Python/comments/18r6v5v/a_few_questions_and_concerns_about_the_dataclass/	"/u/Mugalari graciously linked us to [the PEP for dataclasses](https://peps.python.org/pep-0557/#rationale) in a thread about [a library intended to fix an issue with standard dataclasses](https://www.reddit.com/r/Python/comments/18q8w6v/dataclassy_fixing_dataclass_inheritance_hell/). This led to a few questions/thoughts/concerns for me: [We read](https://peps.python.org/pep-0557/#abstract): > A class decorator is provided which inspects a class definition for variables with type annotations as defined in PEP 526, “Syntax for Variable Annotations”. In this document, such variables are called fields. Ok, so why not call the decorator `FieldFactory`? Next, [we read](https://peps.python.org/pep-0557/#rationale) > There have been numerous attempts to define classes which exist primarily to store values which are accessible by attribute lookup. I think this is incorrectly worded first of all. I would've said ""There have been numerous attempts to define classes which provide more thorough support for defining and manipulating the attributes of a class"". The reason I would say it that way is based on [the example in the abstract](https://peps.python.org/pep-0557/#abstract) where we have a class and a large number of methods are automatically generated to guarantee complete and correct generation of auxilliary methods often needed for `field` usage. Next, and most importantly what class does **NOT** exist to store values accessible by attribute lookup? (Simula-based) Object-oriented programming is about unifying values and the methods that operate on them. Next, [we read](https://peps.python.org/pep-0557/#rationale) > There have been numerous attempts to define classes which exist primarily to store values which are accessible by attribute lookup. Why did the author leave out [Enthought Traits](https://docs.enthought.com/traits/) and [Traitlets](https://traitlets.readthedocs.io/en/stable/)? Next [we read](https://peps.python.org/pep-0557/#rationale) > Where is it not appropriate to use Data Classes? and here they give 2 scenarios where it is not appropriate (API compatibility with tuples or dicts and Type validation beyond that provided by PEPs 484 and 526 is required, or value validation or conversion is required) but here is where I have a serious problem. Remember in [the Rationale](https://peps.python.org/pep-0557/#rationale) where this PEP said ""there have been numerous attempts to define classes which exist primarily to store values which are accessible by attribute lookup""? OK, so they are implying that this PEP is tailored to help build classes which exist primarily to store values which are accessible by attribute lookup and therefore this PEP is not appropriate for other types of classes... but that is my central point: if there really were such a large number of classes outside of the ones the PEP mentions in the rationale then why were they not also mentioned when answering the question `Where is it not appropriate to use Data Classes?`."	2.0	t3_18r6v5v	reddit		
160	Building a decentralized key-value store on top of IRC (>= Python 3.6)	Unknown	2023-12-25 10:18:31	https://www.reddit.com/r/Python/comments/18qg1rq/building_a_decentralized_keyvalue_store_on_top_of/	Recently, I've been working on a design for building a decentralized, permissioned key-value store across a threshold of IRC servers using channel names to store keys and topics to store values. The system can be used for a variety of purposes but my intended use is for DNS. My code is written to target Python >= 3.6 using async networking. The write up is on my blog [https://roberts.pm/irc\_kvs/](https://roberts.pm/irc_kvs/)	5.0	t3_18qg1rq	reddit		
161	Tuesday Daily Thread: Advanced questions	Unknown	2023-12-26 00:00:08	https://www.reddit.com/r/Python/comments/18qujkd/tuesday_daily_thread_advanced_questions/	# Weekly Wednesday Thread: Advanced Questions 🐍 Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices. ## How it Works: 1. **Ask Away**: Post your advanced Python questions here. 2. **Expert Insights**: Get answers from experienced developers. 3. **Resource Pool**: Share or discover tutorials, articles, and tips. ## Guidelines: * This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday. * Questions that are not advanced may be removed and redirected to the appropriate thread. ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **How can you implement a custom memory allocator in Python?** 2. **What are the best practices for optimizing Cython code for heavy numerical computations?** 3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?** 4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?** 5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?** 6. **What are some advanced use-cases for Python's decorators?** 7. **How can you achieve real-time data streaming in Python with WebSockets?** 8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?** 9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?** 10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)** Let's deepen our Python knowledge together. Happy coding! 🌟	1.0	t3_18qujkd	reddit		
162	PNLS: An offensive tool that captures and displays SSIDs from device's Preferred Network List in the nearby vicinity.	Unknown	2023-12-25 12:52:00	https://www.reddit.com/r/Python/comments/18qi3u0/pnls_an_offensive_tool_that_captures_and_displays/	Hi everyone, I was tinkering with this idea for a while and it's finally presentable. PNLS is an open-source tool that captures and displays SSIDs from device's Preferred Network List. This is achieved by sniffing out Probe Requests in the nearby vicinity which are then parsed for SSID and other information, and finally propagated to the web UI. The tool is implemented on the Raspberry Pi. More details about the project, its architecture and the technologies it uses is available on the GitHub ([https://github.com/AleksaMCode/Preferred-Network-List-Sniffer](https://github.com/AleksaMCode/Preferred-Network-List-Sniffer)). Because the backend part is written using Python I would appreciate feedback, but more importantly I would love some suggestions on how the code and this tool could be improved.	4.0	t3_18qi3u0	reddit		
163	Introducing Pypeanuts: Monetize Your APIs with Ease!	Unknown	2023-12-25 20:57:37	https://www.reddit.com/r/Python/comments/18qqy33/introducing_pypeanuts_monetize_your_apis_with_ease/	Hello Python enthusiasts and developers! I'm excited to share a project I've been working on: Pypeanuts. It's a Python package designed to help you effortlessly monetize your APIs. While it's still a work in progress, I believe it has great potential for developers looking to generate revenue from their APIs. The code is openly available on GitHub, and I encourage you to check it out and contribute: [Pypeanuts on GitHub](https://github.com/yachty66/pypeanuts) Additionally, I've created a landing page that explains the concept in more detail. Visit [Pypeanuts Landing Page](https://www.pypeanuts.cash/) to learn more about how it works and the benefits it offers. I'm eager to hear your feedback, suggestions, and thoughts on this project. Let's discuss how we can make API monetization simpler and more accessible for everyone!	2.0	t3_18qqy33	reddit		
164	8 Levels of Using Structure Pattern Matching in Python	Unknown	2023-12-24 22:40:45	https://www.reddit.com/r/Python/comments/18q5mp1/8_levels_of_using_structure_pattern_matching_in/	There is one feature that Python developers waiting for so long: structural pattern matching. It finally became possible since Python 3.10. [This article](https://medium.com/techtofreedom/8-levels-of-using-structural-pattern-matching-in-python-d76282d5630f?sk=bc75658e9c10fc24789bd4479c358f86) will show you all tricks of it in 8 levels of difficulty.	4.0	t3_18q5mp1	reddit		
165	Best TTS API for Japanese in Python?	Unknown	2023-12-25 09:36:21	https://www.reddit.com/r/Python/comments/18qfj00/best_tts_api_for_japanese_in_python/	What's the best text-to-speech API for Japanese? I was thoroughly impressed by some of the new AI voice generation techniques but it looks like most of the work it's happening in English. The only real good Japanese AI voice I could find is Speechify's but they don't have an API you can use.	3.0	t3_18qfj00	reddit		
166	Dataclassy - fixing dataclass inheritance hell	Unknown	2023-12-25 01:49:01	https://www.reddit.com/r/Python/comments/18q8w6v/dataclassy_fixing_dataclass_inheritance_hell/	While [researching how to get out of dataclass inheritance hell](https://stackoverflow.com/questions/51575931/class-inheritance-in-python-3-7-dataclasses) I came across [dataclassy](https://github.com/biqqles/dataclassy). It's a (mostly) drop in replacement for the standard library \`dataclasses\` with a number of improvements. Whilst I haven't extensively used it so far it seems to have solved my problems and there's a good chance I'll default to using it instead of \`dataclasses\`. I thought I'd share since it's not a super well known library but seem nice 👌	4.0	t3_18q8w6v	reddit		
167	entertaining / informative youtube channels for keeping up with the nerds	Unknown	2023-12-25 04:12:04	https://www.reddit.com/r/Python/comments/18qb250/entertaining_informative_youtube_channels_for/	I'm after someone entertaining like primeagen but with a python focus/bias. I haven't come across anyone with a great personality (that arjan guy is weird/boring, etc). Any good sources you know of?	3.0	t3_18qb250	reddit		
168	Monday Daily Thread: Project ideas!	Unknown	2023-12-25 00:00:10	https://www.reddit.com/r/Python/comments/18q72ja/monday_daily_thread_project_ideas/	"# Weekly Thread: Project Ideas 💡 Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you. ## How it Works: 1. **Suggest a Project**: Comment your project idea—be it beginner-friendly or advanced. 2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code. 3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration. ## Guidelines: * Clearly state the difficulty level. * Provide a brief description and, if possible, outline the tech stack. * Feel free to link to tutorials or resources that might help. # Example Submissions: ## Project Idea: Chatbot **Difficulty**: Intermediate **Tech Stack**: Python, NLP, Flask/FastAPI/Litestar **Description**: Create a chatbot that can answer FAQs for a website. **Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM) # Project Idea: Weather Dashboard **Difficulty**: Beginner **Tech Stack**: HTML, CSS, JavaScript, API **Description**: Build a dashboard that displays real-time weather information using a weather API. **Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8) ## Project Idea: File Organizer **Difficulty**: Beginner **Tech Stack**: Python, File I/O **Description**: Create a script that organizes files in a directory into sub-folders based on file type. **Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/) Let's help each other grow. Happy coding! 🌟"	2.0	t3_18q72ja	reddit		
169	Driver's Attention Monitoring System:	Unknown	2023-12-24 00:46:12	https://www.reddit.com/r/Python/comments/18pjhk8/drivers_attention_monitoring_system/	Since accidents have been one of the factors that cause the most deaths in world the main objective of this project is to develop a system that monitors the driver and that through artificial intelligence models can predict when this is showing signs of tiredness, and can also quickly notify and ask for something feedback, thus avoiding accidents due to distraction and possible deaths. With this system it is possible to help reduce this problem, and make driving safer. https://github.com/cousintiz/Driver-s-Attention-Monitoring-System	5.0	t3_18pjhk8	reddit		
170	Debugging dockerized Python apps in VSCode	Unknown	2023-12-23 13:19:36	https://www.reddit.com/r/Python/comments/18p5j92/debugging_dockerized_python_apps_in_vscode/	Finally, set aside the time to configure VScode debugger to peek into web apps running inside docker containers. I use the debugger with pretty much everything but containers. Not sure why I didn’t bother to do it earlier. Huge productivity boost. TIL: https://rednafi.com/python/debug_dockerized_apps_in_vscode/	9.0	t3_18p5j92	reddit		
171	DSAlgo repository on GitHub	Unknown	2023-12-24 14:27:57	https://www.reddit.com/r/Python/comments/18pw8em/dsalgo_repository_on_github/	Hey everyone, I just wanted to share this amazing data structures and algorithms repository that I found on Github: [**https://github.com/SamirPaulb/DSAlgo**](https://github.com/SamirPaulb/DSAlgo). It's seriously one of the best resources I've come across for learning DSA.	1.0	t3_18pw8em	reddit		
172	Sunday Daily Thread: What's everyone working on this week?	Unknown	2023-12-24 00:00:10	https://www.reddit.com/r/Python/comments/18pikkd/sunday_daily_thread_whats_everyone_working_on/	# Weekly Thread: What's Everyone Working On This Week? 🛠️ Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to! ## How it Works: 1. **Show & Tell**: Share your current projects, completed works, or future ideas. 2. **Discuss**: Get feedback, find collaborators, or just chat about your project. 3. **Inspire**: Your project might inspire someone else, just as you might get inspired here. ## Guidelines: * Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome. * Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here. ## Example Shares: 1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate! 2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better. 3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier! Let's build and grow together! Share your journey and learn from others. Happy coding! 🌟	12.0	t3_18pikkd	reddit		
173	A simple game made with the graphics.py library	Unknown	2023-12-23 16:18:24	https://www.reddit.com/r/Python/comments/18p91rg/a_simple_game_made_with_the_graphicspy_library/	[https://github.com/sirus-the-beaver/tree-collector](https://github.com/sirus-the-beaver/tree-collector) &#x200B; &#x200B; [Starting menu](https://preview.redd.it/hz6c7nexk28c1.png?width=912&format=png&auto=webp&s=0b35eafa0d114d9ae021dfa887718a51eb2f116c) [Mid gameplay](https://preview.redd.it/7j63soexk28c1.png?width=912&format=png&auto=webp&s=a3011271d34ee2adc48d73fc976c431832e2ed4e) [Pause menu](https://preview.redd.it/6fte0qexk28c1.png?width=912&format=png&auto=webp&s=c9efc2944835538b281590d6b952aec55d7c5d02)	2.0	t3_18p91rg	reddit		
174	Why do so many online gambling sites sponsor PyDev?	Unknown	2023-12-22 21:34:29	https://www.reddit.com/r/Python/comments/18opjgt/why_do_so_many_online_gambling_sites_sponsor_pydev/	"&#x200B; https://preview.redd.it/bezgyjvmzw7c1.png?width=1332&format=png&auto=webp&s=03c2291f559fc6ef66561c1588983888a3f2be71 So, I was looking at the [PyDev homepage](https://www.pydev.org/) (""Eclipse but for Python"") and noticed that most of their sponsors are from online gambling sites. I may be looking into things here, but this seems to be VERY shady, as I don't exactly see this kind of company as the ""generous"" type, especially for a not-so-well-known (and used) python IDE"	16.0	t3_18opjgt	reddit		
175	Gymhero - FastAPI project example	Unknown	2023-12-23 14:26:50	https://www.reddit.com/r/Python/comments/18p6rox/gymhero_fastapi_project_example/	"Hello guys, A couple of weeks ago, I got the itch to build something with FastAPI. As I am a Data Engineer I didn't have a ton of experience with API development - In the past, I only developed the ""reading"" part of API to expose some database tables, KPIs, etc. But I've always wanted to give it a try to build a full CRUD app. So I thought that it would be a fun project to learn the basics of building a backend app with full CRUD functionality. I was originally planning on using Flask, but when I saw FastAPI and all its nifty features, like typing hints, Pydantic, and Depends, I knew I had to give it a go. Turns out, it was a great decision. FastAPI is a really powerful framework, and it's a joy to work with, I highly recommend using it. It's a great choice and it has great documentation and the developer experience is awesome. Here is GitHub with the project: [https://github.com/JakubPluta/gymhero](https://github.com/JakubPluta/gymhero) My project is pretty simple and it's still in development - probably there are some mistakes and some ""better ways"" to do something, but still, I am happy that I managed to write it from scratch. I just only regret I didn't start with async, so it will be harder to migrate it, but I have it in plans :) To give a short description of my project there are a couple of words:*Gymhero is a simple application to manage your gym training workouts. You have the flexibility to create your own exercises, you can develop custom training units and these units can be easily integrated into personalized training plans. You can manage your training units by adding or removing exercises as needed. By default application contains database od more than 1000 exercises*. Core technologies * FastAPI - web framework for building APIs with Python 3.8+ based on standard Python type hints. * SQLAlchemy - Object Relational Mapper * Pydantic - Data validation library for Python and FastAPI models * Uvicorn - ASGI web server implementation for Python * Alembic - lightweight database migration tool for usage with the SQLAlchemy Database Toolkit for Python. * Docker - tool to package and run an application in a loosely isolated environment * Docker Compose - tool for defining and running multi-container Docker applications * Postgres - open source object-relational database * For testing: * pytest * pytest-cov * pytest-mock * For development * precommit-hook * pylint * black * ruff * poetry * venv Some implemented functionalities: * JWT Authentication * Password Hashing * Login & Register Endpoints * ORM Objects representing SQL tables and relationships * Pydantic schemas * CRUD module for reading, updating, and deleting objects in/from the database * Pagination * Dependencies - superuser, active user, database * Initialization scripts * Separate database and env for testing You can find more in Readme [https://github.com/JakubPluta/gymhero/blob/main/README.md](https://github.com/JakubPluta/gymhero/blob/main/README.md) To run the project locally in docker container simply clone the repository, navigate to cloned directory, and run the: `make dev` or `make install` command, or if you don't have make installed just use docker commands docker compose build docker compose up -d docker exec -it app alembic upgrade head docker exec -it app python -m scripts.initdb --env=dev For more details just go through the README file.I would love to get some opinions from you, especially from experienced FastAPI users :). Please let me know what should I improve, what I did wrong, and what could be done in a better way. &#x200B;"	1.0	t3_18p6rox	reddit		
176	Azure DevOps connection to Toggl	Unknown	2023-12-24 00:27:27	https://www.reddit.com/r/Python/comments/18pj4h4/azure_devops_connection_to_toggl/	Anyone have success connecting azure DevOps with Toggl? I currently use a notebook to sync my outlook with my toggl but would really like to cut out a step and connect directly to dev ops. I use another notebook to pull some info down from dev ops to generate reports. I know its possible but before I go down that rabit hole, thought I would check here. A quick google turned up nothing useful. We can’t install from visual studio marketplace except approved plugins so the typical route wont work. Just want to take my laziness to the next level while not officially sanctioned	0.0	t3_18pj4h4	reddit		
177	Saturday Daily Thread: Resource Request and Sharing! Daily Thread	Unknown	2023-12-23 00:00:19	https://www.reddit.com/r/Python/comments/18osm7b/saturday_daily_thread_resource_request_and/	"# Weekly Thread: Resource Request and Sharing 📚 Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread! ## How it Works: 1. **Request**: Can't find a resource on a particular topic? Ask here! 2. **Share**: Found something useful? Share it with the community. 3. **Review**: Give or get opinions on Python resources you've used. ## Guidelines: * Please include the type of resource (e.g., book, video, article) and the topic. * Always be respectful when reviewing someone else's shared resource. ## Example Shares: 1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms. 2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures. 3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators. ## Example Requests: 1. **Looking for**: Video tutorials on web scraping with Python. 2. **Need**: Book recommendations for Python machine learning. Share the knowledge, enrich the community. Happy learning! 🌟"	2.0	t3_18osm7b	reddit		
178	Snake game in Python and Pygame	Unknown	2023-12-22 15:57:48	https://www.reddit.com/r/Python/comments/18oi4a6/snake_game_in_python_and_pygame/	I made a Snake game using Python and Pygame Code: [https://github.com/DataWizual/Snake-game-in-python-and-Pygame](https://github.com/DataWizual/Snake-game-in-python-and-Pygame) Here's the video explaining how I did it: [https://youtu.be/f5jWChprIGU](https://youtu.be/f5jWChprIGU)	1.0	t3_18oi4a6	reddit		
179	[wip] Automating with a Python-based BPM	Unknown	2023-12-22 16:03:44	https://www.reddit.com/r/Python/comments/18oi9gu/wip_automating_with_a_pythonbased_bpm/	Hi everyone! We're building Abstra [Workflows](https://www.abstra.io/workflows), a tool to help Python devs build process automation in a faster, yet equally powerful way. The idea is to code it all in Python (this means versionable and no lock-in) while using out-of-box features (such as access control and audit logs) that reduce tech overhead and busywork that usually comes with high-code. I'd love to understand if anyone here in the community would benefit from a tool like this. I'm on the lookout on how to make the tool as best as possible for Python devs needing to automate. Here's the [Github link](https://github.com/abstra-app/abstra-lib) also. We'll chat in the comments, thank you :)	1.0	t3_18oi9gu	reddit		
180	VT100 coloring logging utility	Unknown	2023-12-22 14:20:48	https://www.reddit.com/r/Python/comments/18og01h/vt100_coloring_logging_utility/	PyPI: https://pypi.org/project/vt100logging/ GitHub: https://github.com/g2labs-grzegorz-grzeda/vt100logging This is my first Python package. It adds basic VT100 escape codes coloring to the STDOUT.	0.0	t3_18og01h	reddit		
181	What is a low overhead ETL pipeline?	Unknown	2023-12-21 21:53:31	https://www.reddit.com/r/Python/comments/18nyeki/what_is_a_low_overhead_etl_pipeline/	I need to do some pipelines for crawling,cleaning, indexing from a flask app, expecting them to be long running and want to run outside of flask. The project is a POC/prototype for a pitch to determine if it’s worth moving forward. So looking for low overhead, minimal setup. Celery & Airflow are just too big for something like this, Luigi seems to fit the bill but looks like it’s in rough shape Spotify seems to have moved away from Luigi, but is two commands to get it up and running. Anybody have suggestions for a quick and simple etl framework?	19.0	t3_18nyeki	reddit		
182	The Decimator, or how to plot a lot of points in Python	Unknown	2023-12-21 15:48:42	https://www.reddit.com/r/Python/comments/18nq0s8/the_decimator_or_how_to_plot_a_lot_of_points_in/	"The decimator is a function that removes the points but keeps the ""information"" of a chart. The post features examples on Times series and also for clustering. [https://www.taipy.io/posts/big-data-charting-strategies-in-python](https://www.taipy.io/posts/big-data-charting-strategies-in-python)"	3.0	t3_18nq0s8	reddit		
183	How to implement DDD Entities in Python	Unknown	2023-12-21 12:59:38	https://www.reddit.com/r/Python/comments/18nmhc2/how_to_implement_ddd_entities_in_python/	👨‍💻 Recently, I delved into the world of DDD Entities in Python. 🚀 Shared my experience and some basics in my latest blog post. Check it out if you're curious: [https://blog.szymonmiks.pl/p/basic-building-blocks-ddd-entities/](https://blog.szymonmiks.pl/p/basic-building-blocks-ddd-entities/)	4.0	t3_18nmhc2	reddit		
184	Friday Daily Thread: r/Python Meta and Free-Talk Fridays	Unknown	2023-12-22 00:01:09	https://www.reddit.com/r/Python/comments/18o19gc/friday_daily_thread_rpython_meta_and_freetalk/	# Weekly Thread: Meta Discussions and Free Talk Friday 🎙️ Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related! ## How it Works: 1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community. 2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community. 3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting. ## Guidelines: * All topics should be related to Python or the /r/python community. * Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy). ## Example Topics: 1. **New Python Release**: What do you think about the new features in Python 3.11? 2. **Community Events**: Any Python meetups or webinars coming up? 3. **Learning Resources**: Found a great Python tutorial? Share it here! 4. **Job Market**: How has Python impacted your career? 5. **Hot Takes**: Got a controversial Python opinion? Let's hear it! 6. **Community Ideas**: Something you'd like to see us do? tell us. Let's keep the conversation going. Happy discussing! 🌟	1.0	t3_18o19gc	reddit		
185	Exploring 3D Terrain Visualization with Python: A DEM and PyVista Tutorial	Unknown	2023-12-21 15:28:11	https://www.reddit.com/r/Python/comments/18npkd0/exploring_3d_terrain_visualization_with_python_a/	&#x200B; [Exploring 3D Terrain Visualization with Python: A DEM and PyVista Tutorial](https://preview.redd.it/uwfu1e682o7c1.jpg?width=1024&format=pjpg&auto=webp&s=640029aa56265addfe86f152c9778f34c7df03e0) [Exploring 3D Terrain Visualization with Python: A DEM and PyVista Tutorial](https://spatial-dev.guru/2023/12/17/exploring-3d-terrain-visualization-with-python-a-dem-and-pyvista-tutorial/)	0.0	t3_18npkd0	reddit		
186	existing package for directory sharding?	Unknown	2023-12-21 14:58:25	https://www.reddit.com/r/Python/comments/18nox0v/existing_package_for_directory_sharding/	Is there an existing package that shards filenames to create subdirectory names? e.g. shard('doggy') -> 'a7/doggy' yes I know it's fairly easy to code. *pip install <some package name>* is easier iff *some package name* exists ;) Edit: So this happened: [https://pypi.org/project/directoryshard/](https://pypi.org/project/directoryshard/)	7.0	t3_18nox0v	reddit		
187	Open Source Django Admin Template - Sneat	Unknown	2023-12-21 11:04:22	https://www.reddit.com/r/Python/comments/18nkjae/open_source_django_admin_template_sneat/	Hi All, Sharing here an open-source resource: Sneat Open Source & Free Bootstrap 5 Admin Template. Incredibly versatile, the Sneat – [Sneat – Free Bootstrap Django Admin Template](https://themeselection.com/item/sneat-free-bootstrap-django-admin-template/) also allows you to build any type of web application. For instance, you can create: * SaaS platforms * Project management apps * Ecommerce backends * CRM systems * Analytics apps * Banking apps * Education apps * Fitness apps & many more. **Features:** * Based on **Django 5** * **Bootstrap 5** * **Vertical** layout * Unique Dashboard * 1 Chart library * Authentication Pages * Fully Responsive Layout * Organized Folder Structure * Clean & Commented Code * Well Documented I hope you all find this resource useful.	1.0	t3_18nkjae	reddit		
188	Looking for contributers for writing a plugin for calibre	Unknown	2023-12-21 22:12:45	https://www.reddit.com/r/Python/comments/18nyu9m/looking_for_contributers_for_writing_a_plugin_for/	Hi all, so I currently found out that there is barely any way to fetch metadata when it comes to books written in Bulgarian through calibre. I have therefore written a web scraper that will fetch metadata of a book from a couple of websites, and it seems to work as intended. The thing is — I'm a complete noob when it comes to plugins and was hoping to find someone who might be interested in helping out on the project - to turn these web scrapers into a calibre plugin. The functionality is already there, I just need someone to create the interface in calibre and to map the data to the correct fields. [https://github.com/kbkozlev/BGBookMeta](https://github.com/kbkozlev/BGBookMeta)	2.0	t3_18nyu9m	reddit		
189	The hand-picked selection of the best Python libraries and tools of 2023	Unknown	2023-12-20 20:33:05	https://www.reddit.com/r/Python/comments/18n4guw/the_handpicked_selection_of_the_best_python/	Hello Python Community! We're thrilled to present our 9th edition of the **Top Python Libraries and tools**, where we've scoured the Python ecosystem for the most innovative and impactful developments of the year. This year, it’s been the boom of Generative AI and Large Language Models (LLMs) which have influenced our picks. Our team has meticulously reviewed and categorized over 100 libraries, ensuring we highlight both the mainstream and the hidden gems. **Explore the entire list with in-depth descriptions here**: [https://tryolabs.com/blog/top-python-libraries-2023](https://tryolabs.com/blog/top-python-libraries-2023) Here’s a glimpse of our top 10 picks: 1. [**LiteLLM**](https://github.com/BerriAI/litellm) — Call any LLM using OpenAI format, and more. 2. [**PyApp**](https://github.com/ofek/pyapp) — Deploy self-contained Python applications anywhere. 3. [**Taipy**](https://github.com/Avaiga/taipy) — Build UIs for data apps, even in production. 4. [**MLX**](https://github.com/ml-explore/mlx) — Machine learning on Apple silicon with NumPy-like API. 5. [**Unstructured**](https://github.com/Unstructured-IO/unstructured) — The ultimate toolkit for text preprocessing. 6. [**ZenML**](https://github.com/zenml-io/zenml) and [**AutoMLOps**](https://github.com/GoogleCloudPlatform/automlops) — Portable, production-ready MLOps pipelines. 7. [**WhisperX**](https://github.com/m-bain/whisperX) — Speech recognition with word-level timestamps & diarization. 8. [**AutoGen**](https://github.com/microsoft/autogen) — LLM conversational collaborative suite. 9. [**Guardrails**](https://github.com/guardrails-ai/guardrails) — Babysit LLMs so they behave as intended. 10. [**Temporian**](https://github.com/google/temporian) — The “Pandas” built for preprocessing temporal data. Our selection criteria prioritize innovation, robust maintenance, and the potential to spark interest across a variety of programming fields. Alongside our top picks, we've put significant effort into the long tail, showcasing a wide range of tools and libraries that are valuable to the Python community. A huge thank you to the individuals and teams behind these libraries. Your contributions are the driving force behind the Python community's growth and innovation. 🚀🚀🚀 **What do you think of our 2023 lineup? Did we miss any library that deserves recognition?** Your feedback is vital to help us refine our selection each year.	14.0	t3_18n4guw	reddit		
190	Snappy (Candid Photos)	Unknown	2023-12-21 06:32:21	https://www.reddit.com/r/Python/comments/18nghyl/snappy_candid_photos/	Do you ever spend hours coding and wish you could capture your agony? Now you can! Snappy is a little program for the macOS menu bar that uses cv2 to take pictures on a customizable timer with the option for random filters. This is my first time combining rumps and pyqt6. Let me know what you think! [https://www.mediafire.com/file/dii30gc8oxwbzul/Snappy.zip/file](https://www.mediafire.com/file/dii30gc8oxwbzul/Snappy.zip/file) [https://github.com/CoderEgloo/Snappy](https://github.com/CoderEgloo/Snappy) &#x200B; [options](https://preview.redd.it/x1qpvxiddl7c1.png?width=215&format=png&auto=webp&s=0cf3c309f7ceb1d9ec0c8b0bcf84ebeb65086042) [settings page](https://preview.redd.it/t383fi1kdl7c1.png?width=810&format=png&auto=webp&s=53892bed52e7b1b13b8258dffcd96c12e99ac75e) &#x200B; &#x200B; &#x200B;	0.0	t3_18nghyl	reddit		
191	Have you wasted hours tweaking a plot for a presentation or academic paper, like searching StackOverflow on how to change the font size of the labels?	Unknown	2023-12-21 17:45:43	https://www.reddit.com/r/Python/comments/18nsorf/have_you_wasted_hours_tweaking_a_plot_for_a/	[LLM automatically updating plot](https://i.redd.it/cr2wcxpoqo7c1.gif) In this blog post, we will build an AI chatbot with Panel and Mixtral 8x7b that will help you generate code and execute code to tweak an Matplotlib plot. It has two functionalities: 1. You can chat with the AI assistant to do small tweaks of a Matplotlib plot or ask it to “make this figure ready for a poster presentation”. This is especially helpful when we need help with styling but don’t know where to start. This AI chatbot will not only generate ideas, but also runnable code to improve your plot directly. 2. You can also check the code of a figure, edit the code directly, and get the updated version of the plot. This is helpful when you would like to start with your own plot. You can copy and paste the code of your own plot here as a starting point for AI to improve. * Try out the app [here](https://huggingface.co/spaces/ahuang11/tweak-mpl-chat) (we will keep this app live for a week) * Check the code [here](https://huggingface.co/spaces/ahuang11/tweak-mpl-chat/blob/main/app.py)	1.0	t3_18nsorf	reddit		
192	Any mypyc users have any organization tips?	Unknown	2023-12-21 13:17:27	https://www.reddit.com/r/Python/comments/18nmti4/any_mypyc_users_have_any_organization_tips/	I've been using to download and process a bunch of data. Noticed that some of the unit tests I made ran up to 3x faster when compiled using \`mypyc\`. Some of the scripts depend on packages that don't take to well to being c-compiled, so I'm still having to interface my c-compiled scripts with vanilla python. Best organization I've come up with so far has been (showing only the stuff under version control): \`\`\`bash scripts/ |--> [file1.py](https://file1.py) |--> [file2.py](https://file2.py) |-> compiled\_scripts/ |--> mypy.ini |-> stubs/ |--> file1.pyi |-> module1/ \`\`\` And the procedure has been to navigate to \`compiled\_scripts\`, run \`mypyc ../file1.py\` and then in \`file2.py\` put a \`try/except\` to look for the package in the subdirectory: \`\`\`python try: import compiled\_scripts.file1 except: import file1 \`\`\` This seems to keep things fairly clean, but I'm wondering how other people organize things.	1.0	t3_18nmti4	reddit		
193	Ive been a python hobbyist for a couple years - am I ready to start applying? -Looking for feedback on my most recent project - A library wrapping AIOSQLite to abstract away writing SQL (for smaller projects)	Unknown	2023-12-20 17:35:40	https://www.reddit.com/r/Python/comments/18n07wj/ive_been_a_python_hobbyist_for_a_couple_years_am/	"As the title implies, I'm looking for feedback on my code and potential hire-ability. [https://github.com/sockheadrps/AIODesa](https://github.com/sockheadrps/AIODesa) This project wraps AIOSQLite using built-ins and data classes to provide an abstraction layer for dealing with SQLite databases. I definitely prefer back end web development, and know just enough HTML CSS and JS to be dangerous, but Im wondering if this project is ""professional"" enough to put on my CV, and if it accurately conveys my level of understanding. Background on myself: Im 30 years old, been programming as a hobby for like 5 years or so, always been interested in computer science, but went the route of trade school and have been a commercial/industrial electrician for 10 years. I have no formal education or training other than a HS diploma and my trade certificate. Do you think it would be unlikely for me to be hired at this stage in my life and at this stage in my code quality?"	8.0	t3_18n07wj	reddit		
194	Project: Render Cellular Automaton simulations in the terminal	Unknown	2023-12-20 22:38:46	https://www.reddit.com/r/Python/comments/18n7cbb/project_render_cellular_automaton_simulations_in/	Hey all, I wanted to share this project I've been working on for the last few days. I've written a cellular automaton program that renders cells directly to the terminal using \`rich\`, and I think the results look pretty cool. Do note the example in the README is not how the cells *actually* render -- this is some weird graphical artifacts with certain character's background/foreground colors overlapping each other. Feedback is appreciated! [https://github.com/noprobelm/terminal-cellular-automaton](https://github.com/noprobelm/terminal-cellular-automaton)	1.0	t3_18n7cbb	reddit		
195	Thursday Daily Thread: Python Careers, Courses, and Furthering Education!	Unknown	2023-12-21 00:00:08	https://www.reddit.com/r/Python/comments/18n9501/thursday_daily_thread_python_careers_courses_and/	# Weekly Thread: Professional Use, Jobs, and Education 🏢 Welcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**. --- ## How it Works: 1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles. 2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources. 3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally. --- ## Guidelines: - This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar. - Keep discussions relevant to Python in the professional and educational context. --- ## Example Topics: 1. **Career Paths**: What kinds of roles are out there for Python developers? 2. **Certifications**: Are Python certifications worth it? 3. **Course Recommendations**: Any good advanced Python courses to recommend? 4. **Workplace Tools**: What Python libraries are indispensable in your professional work? 5. **Interview Tips**: What types of Python questions are commonly asked in interviews? --- Let's help each other grow in our careers and education. Happy discussing! 🌟	0.0	t3_18n9501	reddit		
196	HoloViews Cheat Sheet for Bokeh Backend	Unknown	2023-12-20 17:25:14	https://www.reddit.com/r/Python/comments/18mzyof/holoviews_cheat_sheet_for_bokeh_backend/	"HoloViews simplifies high-level data visualization in Python, excelling in interactive and declarative visualizations, especially when paired with pandas and xarray. [hvplot](https://hvplot.holoviz.org/), which is built on top of HoloViews, makes it even easier with pandas-like plotting syntax, e.g. \`ds.hvplot(""x"", ""y"")\`. https://preview.redd.it/8iilcl2ohh7c1.png?width=1911&format=png&auto=webp&s=a229f8ed9ee8219a670e462c4207853641c41a23"	0.0	t3_18mzyof	reddit		
197	Alarm-Clock-Tkinter-GUI-project-IOS-Design	Unknown	2023-12-20 17:57:41	https://www.reddit.com/r/Python/comments/18n0r5q/alarmclocktkinterguiprojectiosdesign/	Alarm Clock with GUI is a Python project that utilizes tkinter and other libraries to create an intuitive alarm clock with a graphical user interface resembling IOS Alarm Application [https://github.com/YatoVoid/Alarm-Clock-Tkinter-GUI-project-IOS-Design.git](https://github.com/YatoVoid/Alarm-Clock-Tkinter-GUI-project-IOS-Design.git) &#x200B; https://preview.redd.it/i0pajyzqfi4c1.png?width=508&format=png&auto=webp&s=da4a8337a8b176339dac3a3fc96ea30f73f939f5 https://preview.redd.it/7q2e3qisfi4c1.png?width=504&format=png&auto=webp&s=060bf29092bd7407e30589ce0001676c133049d9 https://preview.redd.it/pnu2r6yufi4c1.png?width=503&format=png&auto=webp&s=7bf91532d85c29299ba5380d8ab227b78d115d99	0.0	t3_18n0r5q	reddit		
198	Declarative GUI for Python	Unknown	2023-12-19 21:56:26	https://www.reddit.com/r/Python/comments/18mdpig/declarative_gui_for_python/	Today, we at Slint ([https://slint.dev](https://slint.dev)) kicked off support for Python with an initial PR - [https://github.com/slint-ui/slint/pull/4155](https://github.com/slint-ui/slint/pull/4155). We invite your suggestions, feedback, and contributions to achieve the initial milestone - [https://github.com/slint-ui/slint/milestone/18](https://github.com/slint-ui/slint/milestone/18). Slint is an open-source graphical user interface toolkit to design, develop, and deploy native user interfaces on desktop and embedded systems. One of our goals is to support multiple programming languages. This project to provide native Python APIs has been made possible by the NLNet Foundation - [https://nlnet.nl/project/PythonicSlint/](https://nlnet.nl/project/PythonicSlint/).	8.0	t3_18mdpig	reddit		
199	Python-oracledb 2.0 for Oracle Database introduces asyncio support	Unknown	2023-12-20 03:02:55	https://www.reddit.com/r/Python/comments/18mk7ud/pythonoracledb_20_for_oracle_database_introduces/	Python-oracledb 2.0 for Oracle Database introduces asyncio support Python-oracledb is the Python driver for Oracle Database. The main changes in 2.0 are: * Support for asynchronous concurrent coding * Support for ‘Success With Info’ warnings * Support for configuring the SDU in Thin mode * The future \`oracledb.\_\_future\_\_.old\_json\_col\_as\_ob\`j has been removed * New Connection object attributes * New SQL Domain and Annotation attributes * Some obsolete, long deprecated parameters like \`encoding\` and \`nencoding\` have been desupported * Support for the obsolete Python 3.6 release has been dropped (you can use Python 3.7, 3.8, 3.9, 3.10, 3.11 and 3.12 !) &#x200B; Check the [release announcement](https://cjones-oracle.medium.com/python-oracledb-2-0-has-asyncio-support-2b913e40f9ca) &#x200B;	2.0	t3_18mk7ud	reddit		
200	TSAlign: A simple and fast python library to align two 1D time-series data using FFT based convolution.	Unknown	2023-12-20 06:11:23	https://www.reddit.com/r/Python/comments/18mnpoy/tsalign_a_simple_and_fast_python_library_to_align/	[TSAlign](https://github.com/nexus1203/TSAlign/tree/main) is a Python library for fast and straightforward alignment of 1D time series data, using FFT-based convolution. Ideal for signal processing and time series analysis, it offers functions for calculating distances like Euclidean, mean-adjusted, and z-normalized. [Github Link](https://github.com/nexus1203/TSAlign) Choose a distance metric ('sdist', 'mdist', 'zdist') and align your series. The package includes an example aligning sine and cosine waves, with visualization capabilities for comparing original, aligned, and difference series. **Here's a quick example:** import numpy as np import tsalign as tsa # Example time series data t = np.linspace(0, 3, 1000) Q = np.sin(2 * np.pi * 5 * t)[:500] S = np.cos(2 * np.pi * 5 * t) + 0.1 * np.random.randn(len(t)) # Align using z-normalized distance aligned_series, difference = tsa.align_timeseries(Q, S, distance='zdist') **Visualization:** https://preview.redd.it/nmabau7z5e7c1.png?width=1000&format=png&auto=webp&s=967d4fb8935d07807fb8a7dc01715d21d0dc5e20 **Benchmark** |Array Size|Mean Time (s)|Standard Deviation (s)| |:-|:-|:-| |1.0e+01|0.000265|0.000068| |1.0e+02|0.000272|0.000072| |1.0e+03|0.000330|0.000121| |1.0e+04|0.000841|0.000303| |1.0e+05|0.010003|0.001382| |1.0e+06|0.108963|0.014162| |1.0e+07|1.150634|0.203717| &#x200B;	1.0	t3_18mnpoy	reddit		
201	I recorded a crash course on Polars library of Python (Great library for working with big data) and uploaded it on Youtube	 	2023-12-19 03:44:14	https://www.reddit.com/r/Python/comments/18lsb7i/i_recorded_a_crash_course_on_polars_library_of/	Hello everyone, I created a crash course of Polars library of Python and talked about data types in Polars, reading and writing operations, file handling, and powerful data manipulation techniques. I am leaving the link, have a great day!! [https://www.youtube.com/watch?v=aiHSMYvoqYE&list=PLTsu3dft3CWiow7L7WrCd27ohlra\_5PGH&index=6&t=689s](https://www.youtube.com/watch?v=aiHSMYvoqYE&list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&index=6&t=689s)	10.0	t3_18lsb7i	reddit		
202	MiniLang - C succesor	Unknown	2023-12-20 00:12:28	https://www.reddit.com/r/Python/comments/18mgqrb/minilang_c_succesor/	Link: [https://github.com/NICUP14/MiniLang](https://github.com/NICUP14/MiniLang) # Mini Lang A type-safe C successor that compiles directly to x86\_64 assembly. ## Features * Minimal * Compiled * Typed * Functional\* * Inter-op with C functions Minimal - As close as possible to actual assembly code while maintaining as many high-level features as possible.	2.0	t3_18mgqrb	reddit		
203	Wednesday Daily Thread: Beginner questions	Unknown	2023-12-20 00:00:09	https://www.reddit.com/r/Python/comments/18mgh2m/wednesday_daily_thread_beginner_questions/	# Weekly Thread: Beginner Questions 🐍 Welcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you. ## How it Works: 1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here! 2. **Community Support**: Get answers and advice from the community. 3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources. ## Guidelines: * This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link). ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **What is the difference between a list and a tuple?** 2. **How do I read a CSV file in Python?** 3. **What are Python decorators and how do I use them?** 4. **How do I install a Python package using pip?** 5. **What is a virtual environment and why should I use one?** Let's help each other learn Python! 🌟	2.0	t3_18mgh2m	reddit		
204	Convenient SQL databases terminal client	Unknown	2023-12-19 09:13:20	https://www.reddit.com/r/Python/comments/18lxq5l/convenient_sql_databases_terminal_client/	"I spend most of my time in the terminal while developing, and I'm used to using terminal-based database clients. For example, all application logs are stored in ClickHouse, but there is no convenient client with a user-friendly data representation and SQL query storage, like DBeaver or DataGrip, but for the terminal. Since I'm a programmer, I took on 2 projects - kaa editor and visidata, both written in Python, and created ""pineapple apple pen"" - a terminal-based simplified (and in some cases superior, thanks to the capabilities of visidata) alternative to DBeaver. GitHub: [https://github.com/Sets88/dbcls](https://github.com/Sets88/dbcls) Please star 🌟 repo if you liked what i created"	8.0	t3_18lxq5l	reddit		
205	Questions regarding OpenAPI Generator CLI and Swagger Codegen with Python and Flask	Unknown	2023-12-19 16:17:39	https://www.reddit.com/r/Python/comments/18m5oia/questions_regarding_openapi_generator_cli_and/	So, I have been trying to look into OpenAPI Generator CLI but I got the feeling from the documentation and after trying to set up just a very basic example server that it: 1. does not work put of the box 2. the documentation is nearly non-existent or not specific to any generator (neither python-flask nor any other generator) 3. the code generated also indicates that the mentioned python-flask generator is not up to date when (python version 3.6+, does not run with an environment set up with py-3.6 either) Did anyone try to use this yet or has an alternative to generating a working server stub? Or is there someone who would like to share his customizaton of the openapi generator?	2.0	t3_18m5oia	reddit		
206	Questions about a TensorFlow Plate recognition project i plan on doing.	Unknown	2023-12-20 09:04:15	https://www.reddit.com/r/Python/comments/18mqb4t/questions_about_a_tensorflow_plate_recognition/	"Hello, so i have a python project i plan on doing for school and thought about training a TensorFlow model for License Plates recognition (also recognize the character), then retrieving the characters, and automatically put them in a french ""plate checker"" website via a little script, which'll give me the model/brand of the car, and use the brand/model to give info on the car via an API using the said brand/model. So now that i've explained that, does anyone know if following a 2 year old tutorial is fine for this ? I really want to dive in but am afraid i'll run into errors due to a deprecated way of installing/configuring TensorFlow. [This is the tutorial i thought about following](https://www.youtube.com/watch?v=0-4p_QgrdbE&list=LL&index=10&t=2105s&ab_channel=NicholasRenotte), seems pretty complete and he goes over a lot of details. Also want to know if i'll be able to put all of this in a app.exe with a little window that pops up that asks us to choose an image and then analyze it to do everything i want it to do. Thanks for your time and the help."	1.0	t3_18mqb4t	reddit		
207	python-decouple vs confiGOAT || Why you need to use confiGOAT to manage configurations and environment variables of your python projects	Unknown	2023-12-20 09:01:36	https://www.reddit.com/r/Python/comments/18mq9nm/pythondecouple_vs_configoat_why_you_need_to_use/	Some weeks ago, one of my colleagues and I were given a task to “fix” the management of the configuration and environment variables used in some of our mission-critical projects. While reviewing the existing implementation of the configuration management module using the python-decouple package, we identified multiple issues, 1. With python-decouple, we were restricted to using only .ini or .env files to define the configurations or settings variables. 2. Everything in python-decouple is a string. What if we wanted to use a tuple or dict without casting from <class str>? 3. We could not load configurations that required complex calculations. 4. What if we wanted all different configurations loaded from multiple sources to be available from a single interface? 5. What if we wanted to create and then access variables following a nested hierarchy? 6. What if we wanted to reference variables from anywhere in a bidirectional way? 7. We had to manually create separate configuration files and copy the entire folder architecture of Python scripts for different environments. 8. What if we wanted to access the environment variables using dynamic modules and attributes? As we started listing down the scope and functionalities of this new module, we realized that others might also benefit from having a highly extensive module where they could, 1. Define configuration parameters using both YAML and Python scripts. 2. Manage all environment variables or configuration parameters from a single setup. Define configurations once, and use them everywhere. 3. Cast values before using them. 4. Use a powerful reference mechanism to reuse variables from any level at any level in any direction. 5. Use multiple resource types in the YAML to support the vast majority of use cases. 6. Support both simple use cases and complex, multi-layered nested configurations. 7. Use dynamic modules to access the parameters through the import interface in Python. 8. Use a single exposed API to interact with the layered configurations. We are delighted to release the first version of confiGOAT, a powerful, flexible, and developer-friendly management tool for all your environment variables and configurations. We have created a detailed guide on how to set up and use this package in your projects. (https://github.com/aag13/configoat) Please take a look and let us know if you would like any enhancements or report any issues. Oh, and don’t forget to ⭐ the GitHub repository (https://github.com/aag13/configoat) and spread the news! 🥳 https://pypi.org/project/configoat/ ✨✨✨	3.0	t3_18mq9nm	reddit		
208	How could i improve This Monitoring system?	Unknown	2023-12-19 14:33:29	https://www.reddit.com/r/Python/comments/18m39nq/how_could_i_improve_this_monitoring_system/	Driver's Attention Monitoring System: Since accidents have been one of the factors that cause the most deaths in world the main objective of this project is to develop a system that monitors the driver and that through artificial intelligence models can predict when this is showing signs of tiredness, and can also quickly notify and ask for something feedback, thus avoiding accidents due to distraction and possible deaths. With this system it is possible to help reduce this problem, and make driving safer. https://github.com/cousintiz/Driver-s-Attention-Monitoring-System	0.0	t3_18m39nq	reddit		
209	Looking to buy the script of the unit cell of a TPMS structure	Unknown	2023-12-19 21:30:04	https://www.reddit.com/r/Python/comments/18md345/looking_to_buy_the_script_of_the_unit_cell_of_a/	Hi there, Anyone ever used the PyScaffolder module for creating gyroid or Schwartz structures for 3D shoe sole lattice purposes? If you have a portfolio of unit cell of such structure, then I’d like to buy one. Unless you can build it on demand for me. Thanks.	0.0	t3_18md345	reddit		
210	[blog] Convert data streams to Parquet Files in Python	Unknown	2023-12-19 20:42:58	https://www.reddit.com/r/Python/comments/18mbz1c/blog_convert_data_streams_to_parquet_files_in/	Using Bytewax (Stream processing purely in Python) take simulated streaming web event data and put it in partitioned Parquet files in 5 second intervals: \* Define a custom data source connector to our fake web events simulator \* Deserialize the data and reformat it \* Batch the records into a list and convert to an Apache Arrow Table \* Write the events to partitioned Parquet Files [https://bytewax.io/blog/data-pipelines-streams-to-parquet](https://bytewax.io/blog/data-pipelines-streams-to-parquet)	1.0	t3_18mbz1c	reddit		
211	Create Beautiful Rocks with Dynamic Lighting using PyRock2D | Made with Python and Pygame-CE	Unknown	2023-12-19 01:12:32	https://www.reddit.com/r/Python/comments/18lp80z/create_beautiful_rocks_with_dynamic_lighting/	Introducing PyRock2D - A 2D rock generator that uses real-time dynamic lighting to give a pseudo-3D effect. Export to PNG or JSON formats for use in your projects or your personal collection : ) I also made a trailer video for this app [here](https://youtu.be/Qn6LuhRiYT0) Source code is found [here](https://github.com/tank-king/PyRock2D) https://preview.redd.it/k193r7ujj57c1.png?width=1875&format=png&auto=webp&s=f27838e4b298f001b9a4c79309bf61ebc7610a6d &#x200B; https://preview.redd.it/lecfnncmj57c1.png?width=828&format=png&auto=webp&s=0f7f38528590df2e6096c9156864a9b92f3a74eb https://preview.redd.it/0ryujyypj57c1.png?width=828&format=png&auto=webp&s=f17139fe9b4268e2e22e581198a2bfaa2c2e2bae	5.0	t3_18lp80z	reddit		
212	Panel ChatInterface lets you create chat interfaces with just Python	Unknown	2023-12-19 00:04:42	https://www.reddit.com/r/Python/comments/18lnrx5/panel_chatinterface_lets_you_create_chat/	"No Javascript knowledge required. Here's a minimal example that you can use to get started! import panel as pn def callback(contents: str, user: str, instance: pn.chat.ChatInterface): message = f""Echoing {user}: {contents}"" return message chat_interface = pn.chat.ChatInterface(callback=callback) chat_interface.servable() See [https://holoviz-topics.github.io/panel-chat-examples/](https://holoviz-topics.github.io/panel-chat-examples/) for recipes, including interfacing with OpenAI, Mistral, Llama, Langchain, and LlamaIndex! https://i.redd.it/u3gfst0j757c1.gif"	0.0	t3_18lnrx5	reddit		
213	Matplotlib's subplot_mosaic()	Unknown	2023-12-19 00:12:44	https://www.reddit.com/r/Python/comments/18lny57/matplotlibs_subplot_mosaic/	I'm thrilled to share that I've been working on some fascinating content around Matplotlib's powerful features, like subplot\_mosaic(). This function is a game-changer when it comes to creating intricate subplot layouts and organizing multiple subgraphs seamlessly within a single diagram. Link: [https://colab.research.google.com/drive/1XK9K9dP\_CC3WfzimIabBZV8-8mx1aWH8?usp=sharing](https://colab.research.google.com/drive/1XK9K9dP_CC3WfzimIabBZV8-8mx1aWH8?usp=sharing)	1.0	t3_18lny57	reddit		
214	Tuesday Daily Thread: Advanced questions	Unknown	2023-12-19 00:00:07	https://www.reddit.com/r/Python/comments/18lnnzo/tuesday_daily_thread_advanced_questions/	# Weekly Wednesday Thread: Advanced Questions 🐍 Dive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices. ## How it Works: 1. **Ask Away**: Post your advanced Python questions here. 2. **Expert Insights**: Get answers from experienced developers. 3. **Resource Pool**: Share or discover tutorials, articles, and tips. ## Guidelines: * This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday. * Questions that are not advanced may be removed and redirected to the appropriate thread. ## Recommended Resources: * If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance. ## Example Questions: 1. **How can you implement a custom memory allocator in Python?** 2. **What are the best practices for optimizing Cython code for heavy numerical computations?** 3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?** 4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?** 5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?** 6. **What are some advanced use-cases for Python's decorators?** 7. **How can you achieve real-time data streaming in Python with WebSockets?** 8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?** 9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?** 10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)** Let's deepen our Python knowledge together. Happy coding! 🌟	2.0	t3_18lnnzo	reddit		
215	Tool which helps you to keep passwords inside your shell scripts(or python code) safely	Unknown	2023-12-18 07:56:30	https://www.reddit.com/r/Python/comments/18l3g42/tool_which_helps_you_to_keep_passwords_inside/	I hate entering passwords, and I'm not very fond of the concept of passwords itself, but such is life; one has to adapt to circumstances. That's why I wrote this utility that allows storing passwords in an encrypted form inside scripts, using an SSH key located in your SSH agent for encryption/decryption. ‼️Never keep your secrets in public places(like git repos accessible to multiple people) GitHub: https://github.com/Sets88/ssh-crypt Please star 🌟 repo if you liked what i created	13.0	t3_18l3g42	reddit		
216	XetCache Library: Improving the Jupyter Notebook Rerun Experience	Unknown	2023-12-18 22:34:52	https://www.reddit.com/r/Python/comments/18llosd/xetcache_library_improving_the_jupyter_notebook/	For Python-speaking data users, Jupyter notebooks are the go-to tool for data exploration. We created a plugin to easily cache the results of functions in Jupyter notebook cells. The intermediate results are stored in a pickle file in the same folder. This helps solve a few common pains we've experienced: \- **accidentally overwriting variables**: You can re-run a given cell and re-populate any variable (e.g. if you reassigned \`df\` to some other value)\_ \- **sharing notebooks for others to rerun / reproduce**: Many collaborators don't have access to all the same clients / tokens, or all the datasets. Using xetcache, notebook authors can cache any cells / functions that they know are painful for others to reproduce / recreate. \- **speed up rerunning**: even in single player mode, being able to rerun through your entire notebooks in seconds instead of minutes or hours is really really fun The syntax is super minimal and looks like: **%%xetmemo input=df,clean\_data output=model** Here's a link to the project on GitHub: [https://github.com/xetdata/xetcache](https://github.com/xetdata/xetcache) And you can install it via pip: **pip install xetcache** Let us know what you think and what feedback you have! Happy data scienc-ing &#x200B;	0.0	t3_18llosd	reddit		
217	Creating a Voice Virtual Assistant in Python (OpenAI, ElevenLabs, Deepgram)	Unknown	2023-12-18 13:35:34	https://www.reddit.com/r/Python/comments/18l8u1m/creating_a_voice_virtual_assistant_in_python/	Hey guys! I spent the weekend creating a Voice Virtual Assistant (a bit like Jarvis in Iron Man) in Python using OpenAI's GPT, ElevenLabs' TTS, Deepgram's transcription and Taipy's front-end. I figured I would share it here: GitHub repository: [https://github.com/AlexandreSajus/JARVIS](https://github.com/AlexandreSajus/JARVIS) Video demo: [https://youtu.be/aIg4-eL9ATc?si=R6aqJfe7T1fQMqMA](https://youtu.be/aIg4-eL9ATc?si=R6aqJfe7T1fQMqMA)	0.0	t3_18l8u1m	reddit		
218	Interactive TUI app for Python regex exercises	📚 learnbyexample	2023-12-18 10:23:24	https://www.reddit.com/r/Python/comments/18l5irq/interactive_tui_app_for_python_regex_exercises/	Hello! I wrote a TUI app (using `textual`) that has beginner to advanced level exercises for Python regular expressions. There are more than 100 exercises covering both the builtin `re` and third-party `regex` module. Installation: `pip install regexexercises` See https://github.com/learnbyexample/TUI-apps/tree/main/PyRegexExercises for source code, installation details, app guide, screenshot, etc. I'd highly appreciate your feedback.	0.0	t3_18l5irq	reddit		
219	Monday Daily Thread: Project ideas!	Unknown	2023-12-18 00:00:09	https://www.reddit.com/r/Python/comments/18kv3oh/monday_daily_thread_project_ideas/	"# Weekly Thread: Project Ideas 💡 Welcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you. ## How it Works: 1. **Suggest a Project**: Comment your project idea—be it beginner-friendly or advanced. 2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code. 3. **Explore**: Looking for ideas? Check out Al Sweigart's [""The Big Book of Small Python Projects""](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration. ## Guidelines: * Clearly state the difficulty level. * Provide a brief description and, if possible, outline the tech stack. * Feel free to link to tutorials or resources that might help. # Example Submissions: ## Project Idea: Chatbot **Difficulty**: Intermediate **Tech Stack**: Python, NLP, Flask/FastAPI/Litestar **Description**: Create a chatbot that can answer FAQs for a website. **Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM) # Project Idea: Weather Dashboard **Difficulty**: Beginner **Tech Stack**: HTML, CSS, JavaScript, API **Description**: Build a dashboard that displays real-time weather information using a weather API. **Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8) ## Project Idea: File Organizer **Difficulty**: Beginner **Tech Stack**: Python, File I/O **Description**: Create a script that organizes files in a directory into sub-folders based on file type. **Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/) Let's help each other grow. Happy coding! 🌟"	1.0	t3_18kv3oh	reddit		
220	FluidFrames.RIFE 2.11 - video AI fluidifier app	Unknown	2023-12-17 08:47:48	https://www.reddit.com/r/Python/comments/18kd2zx/fluidframesrife_211_video_ai_fluidifier_app/	&#x200B; https://preview.redd.it/25x6q0aigt6c1.png?width=1459&format=png&auto=webp&s=c290e2960c6376020ce884d1cfb487dee1015b7e * Github. [https://github.com/Djdefrag/FluidFrames.RIFE](https://github.com/Djdefrag/FluidFrames.RIFE) **FluidFrames.RIFE** is a Windows app powered by **RIFE AI** to fluidify videos and to create slowmotion videos. **Changelog version 2.4 -> 2.11** **NEW** * Updated **RIFE AI** model to version **4.13** * better **interpolation quality** * Added a new **RIFE\_Lite AI model** * **high interpolation quality** * **25 % faster** than full RIFE model * **25 % less VRAM** usage * suitable for **low-end GPUs** and high definition videos * Added new option to **save generated video frames** (default is enabled) &#x200B; **GUI / UI** * Completely **re-designed GUI**, now cleaner and more elegant * Added new **info-message** for **info buttons** and in case of **error** * The app will now report the **remaining time to complete video fluidify** * The app will now report the **fluidify progress in %** * Added widget to **select AI model** to use * Updated **info texts**, giving more information * Input Resolution % default value changed to **60%** &#x200B; **BUGFIXES / IMPROVEMENTS** * When the application is closed **during fluidify process**, now the process is **stopped correctly** * Drastically reduced **CPU utilization by 90%** without impacting fluidify speed * Completely revised how the app is built, using **Nuitka** (reducing **antivirus false positive**) * For **AMD gpu** users, it is recommended to update to **driver > 23.11.1** * **performance improvements for DirectML**\-based applications * Improvements for **video processing** * for .mp4 output is possibile to select the **codec (x264 or x265)** * improved video bitrate from 4M (default value for ffmpeg) **to 16M** * in future will be the possibility to select the **desired bitrate** * Better support for file path names **with special characters** * Fixed upscaled video **incorrect colorspace** * Redesigned how the app reports **fluidify progress** * General bugfixes and performance improvements * Updated dependencies	0.0	t3_18kd2zx	reddit		
221	messing around with ui's	Unknown	2023-12-17 01:11:51	https://www.reddit.com/r/Python/comments/18k5mvx/messing_around_with_uis/	i just modified a old shitty encrypted notes app to make a fancy ui as a bit of a test to see how to make better ui's and it turned out pretty good. [heres](https://github.com/popcornman209/sf-notes) github link the code is absolutely horrendous its a mix of super old code and new code (joking ofc but it was just a test so dont be suprised when your eyes start bleeding out) (when it comes to the encryption it was my own very bad algorithm that i made for fun, DONT use it, i was just bored and i know of many ways you crack the code to it decently easily) https://preview.redd.it/3xwm10yk9r6c1.jpg?width=960&format=pjpg&auto=webp&s=d02117f6198e4727b0d9da5ac4315f4e4599a617	1.0	t3_18k5mvx	reddit		
222	🚀 PYGGESTER	Unknown	2023-12-16 23:12:22	https://www.reddit.com/r/Python/comments/18k38yk/pyggester/	Pyggester is a dynamic/static analyzer used to suggest improvements to suboptimal data structure usages in Python. 🔗GitHub: [https://github.com/ValdonVitija/pyggester](https://github.com/ValdonVitija/pyggester) 📦 pip installable (pip install pyggester) ✅ Super easy to use 🖥️ Intuitive CLI interface 📚 Fully documented: 📘 User guide 📖 Code documentation (abstract, docstrings) 📝 Extremely detailed contribution guide 🧩 Modular project structure 🔝 More than 30+ potential data structure suggestions 🌟 Your Support Matters! Your star on GitHub would be greatly appreciated. Thanks in advance!	3.0	t3_18k38yk	reddit		
223	Sunday Daily Thread: What's everyone working on this week?	Unknown	2023-12-17 00:00:09	https://www.reddit.com/r/Python/comments/18k47x7/sunday_daily_thread_whats_everyone_working_on/	# Weekly Thread: What's Everyone Working On This Week? 🛠️ Hello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to! ## How it Works: 1. **Show & Tell**: Share your current projects, completed works, or future ideas. 2. **Discuss**: Get feedback, find collaborators, or just chat about your project. 3. **Inspire**: Your project might inspire someone else, just as you might get inspired here. ## Guidelines: * Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome. * Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here. ## Example Shares: 1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate! 2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better. 3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier! Let's build and grow together! Share your journey and learn from others. Happy coding! 🌟	10.0	t3_18k47x7	reddit		
224	Documenting my experience building a Python CLI tool to deploy my builds to AWS EC2 instance	Unknown	2023-12-17 05:37:02	https://www.reddit.com/r/Python/comments/18ka9gx/documenting_my_experience_building_a_python_cli/	Hey Folks, Hope everyone is doing good. I recently started blogging on Medium and I would appreciate your feedback on my given blog which would help me further improve. Just to set the context straight , this is blog is a practical guide documenting my experience on building a Python based CLI command which deploys the provided build to a Amazon EC2 instance on click of one simple command. Blog link : https://medium.com/@anubhavsanyal/from-code-to-cloud-automating-ec2-deployments-with-python-cli-e262396559a9	1.0	t3_18ka9gx	reddit		
225	Banish state-mutating methods from data classes	Unknown	2023-12-17 13:31:11	https://www.reddit.com/r/Python/comments/18kheee/banish_statemutating_methods_from_data_classes/	I've always found mutable data classes or record types in programming languages quite weird. This holds true for any language that supports mutable data classes, like Python, Kotlin, Swift, etc. Self-mutating methods are even weirder. They break the semantics of the types that these data classes or records represent. I've expanded my thoughts here. Although it mostly talks about Python, the message remains valid for any other language that allows you to add self-mutating methods to data classes. https://rednafi.com/python/dataclasses_and_methods/	14.0	t3_18kheee	reddit		
226	[Tkinter] TkClassWizard - Graphically define objects	Unknown	2023-12-17 01:08:25	https://www.reddit.com/r/Python/comments/18k5khj/tkinter_tkclasswizard_graphically_define_objects/	Hello guys, I've recently created a new library called TkClassWizard. Originally it was part of a different library, but I decided to split it for reusage. Features: * Graphical definition of any class that has been type annotated. * Validation of defined values * Ability to register / overwrite additional annotations to classes that cannot be modified * Save the defined data into fake objects and then into real Python objects (or vice-versa) [https://github.com/davidhozic/TkClassWizard](https://github.com/davidhozic/TkClassWizard)	0.0	t3_18k5khj	reddit		
227	Do you guys use any accessory libraries to manage or expedite your web scraping?	Unknown	2023-12-16 00:59:20	https://www.reddit.com/r/Python/comments/18jfasl/do_you_guys_use_any_accessory_libraries_to_manage/	I'm mainly referring to additional libraries that aren't the big popular primary HTML or JS parsers (b4s, selenium, scrapy). I'm no stranger to writing some truly heinous Regex parsing scripts with some sinful nested loops iterating over hundreds of web-pages on sites where there was clearly no templated format being adhered to, essentially non-existent HTML tree structure patterns to design around. I have an upcoming project where I may end up needing to write scripts such as this for a very small company where shelling out the hundreds/low thousands per month for proper API access is not likely to take priority over the other pricy budgeted items. How do you guys go about dealing with either poorly structured webpages or, at the other end, highly dynamic high foot traffic websites where the front end is probably getting script breaking updates at least monthly? Anyway to make this stuff more resilient/easier to repair or is it still the same PITA to deal with as it has been for the last 15+ years	14.0	t3_18jfasl	reddit		
228	Feud: Build simple CLIs based on Pydantic for typing and Click for argument parsing.	Unknown	2023-12-15 16:31:09	https://www.reddit.com/r/Python/comments/18j41fv/feud_build_simple_clis_based_on_pydantic_for/	"- **GitHub repository**: https://github.com/eonu/feud/ - **API reference**: https://docs.feud.wiki/ --- Hello! I've spent the last three months or so working on a new package, [**Feud**](https://github.com/eonu/feud/), for building CLIs in Python, and thought I'd share it here for anyone interested. While existing solutions such as [Click](https://github.com/pallets/click) and [Typer](https://github.com/tiangolo/typer) often provide most of the necessary functionality for the majority of CLIs, I've found that there are still some things missing from these packages, such as validation, support of common input types and high ease-of-use. *Feud combines the best parts of the following packages to make building CLIs as smooth as possible*: - **Click**: Argument parsing library used either: - directly to implement CLIs, - or as the core of other CLI-building packages like Typer and Feud itself. - [**Pydantic**](https://github.com/pydantic/pydantic): Popular data validation library for Python. ### Basic features #### Relies on Python language features To make it as easy as possible for even beginner Python developers to quickly create sophisticated CLIs, Feud aims to rely on basic core language features as much as possible, e.g.: - using type annotations from the function signature to validate CLI inputs (via Pydantic), - using the function signature structure (e.g. default values, the `*` operator to separate arguments and options) to determine arguments, options, required options and defaults. - using docstrings to define CLI help commands and parameter descriptions. ```python # serve.py import feud from typing import Literal def serve(port: int, *, watch: bool = True, env: Literal[""dev"", ""prod""] = ""dev""): """"""Start a local HTTP server. Parameters ---------- port: Server port. watch: Watch source code for changes. env: Environment mode. """""" if __name__ == ""__main__"": feud.run(serve) ``` Usage: - `python serve.py 8080` - `python serve.py 3000 --watch --env dev` - `python serve.py 4567 --no-watch --env prod` **See the [README.md](https://github.com/eonu/feud/blob/master/README.md) and [API reference](https://docs.feud.wiki/) for more examples.** #### Easy validation and extensive type support (via Pydantic) Essentially all types supported by Pydantic are also supported by Feud, meaning that it is very straightforward to perform validation and type conversion of CLI inputs. ```python # command.py import feud from pydantic import PositiveInt, FutureDate, conlist def command(ids: conlist(PositiveInt, max_length=3), *, date: FutureDate): """"""Command that accepts up to three ID arguments (must be positive integers), and an optional date that must be in the future. """""" if __name__ == ""__main__"": feud.run(command) ``` e.g. calling `$ python command.py 2 5 8 --date 2029-12-02` would make: - the list of integers `[2, 5, 8]` accessible as the `ids` argument, - the date `datetime.date(2029, 12, 02)` accessible as the `date` argument. And of course, an appropriate error would be shown if the validation of any parameter failed. #### Simple grouping of commands To create a group of commands, you can simply define functions in a `feud.Group` subclass. ```python # post.py import feud from datetime import date class Post(feud.Group): """"""Manage blog posts."""""" def create(id: int, *, title: str, desc: str | None = None): """"""Create a blog post."""""" def delete(*ids: int): """"""Delete blog posts."""""" def list(*, between: tuple[date, date] | None = None): """"""View all blog posts, optionally filtering by date range."""""" if __name__ == ""__main__"": feud.run(Post) ``` Usage: ```bash $ python post.py --help Usage: post.py [OPTIONS] COMMAND [ARGS]... Manage blog posts. ╭─ Options ──────────────────────────────────────────────────────────╮ │ --help Show this message and exit. │ ╰────────────────────────────────────────────────────────────────────╯ ╭─ Commands ─────────────────────────────────────────────────────────╮ │ create Create a blog post. │ │ delete Delete blog posts. │ │ list View all blog posts, optionally filtering by date range. │ ╰────────────────────────────────────────────────────────────────────╯ ``` ### Comparison with similar packages - [`argparse`](https://docs.python.org/3/library/argparse.html) (and [`optparse`](https://docs.python.org/3/library/optparse.html) – deprecated): The standard library argument parsing libraries are perfectly fine to use for simple CLIs, and even complex CLIs as long as you are careful in maintaining them, and happy to deal with the somewhat verbose code required to build a CLI. Feud may not provide every feature offered by these more fundamental packages, but it is designed to have a much more user-friendly experience and better input validation. - [`click`](https://github.com/pallets/click): Click forms the basis of Feud, as all Feud-defined commands and groups are 'compiled' into Click applications. While Click itself is a huge upgrade from `argparse`, it can sometimes still be a bit verbose to use when building CLIs. - [`typer`](https://github.com/tiangolo/typer): Typer is a more complete CLI-building package that is also based on Click, but currently lacks support for more complex types such as those offered by Pydantic."	4.0	t3_18j41fv	reddit		
229	Saturday Daily Thread: Resource Request and Sharing! Daily Thread	Unknown	2023-12-16 00:00:19	https://www.reddit.com/r/Python/comments/18je37p/saturday_daily_thread_resource_request_and/	"# Weekly Thread: Resource Request and Sharing 📚 Stumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread! ## How it Works: 1. **Request**: Can't find a resource on a particular topic? Ask here! 2. **Share**: Found something useful? Share it with the community. 3. **Review**: Give or get opinions on Python resources you've used. ## Guidelines: * Please include the type of resource (e.g., book, video, article) and the topic. * Always be respectful when reviewing someone else's shared resource. ## Example Shares: 1. **Book**: [""Fluent Python""](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \- Great for understanding Pythonic idioms. 2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \- Excellent overview of Python's built-in data structures. 3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \- A deep dive into decorators. ## Example Requests: 1. **Looking for**: Video tutorials on web scraping with Python. 2. **Need**: Book recommendations for Python machine learning. Share the knowledge, enrich the community. Happy learning! 🌟"	1.0	t3_18je37p	reddit		
230	Abstract Blockchain: designed to streamline and simplify interactions with blockchain networks and smart contracts.	Unknown	2023-12-16 14:44:25	https://www.reddit.com/r/Python/comments/18jsnyc/abstract_blockchain_designed_to_streamline_and/	Abstract Blockchain Abstract Blockchain is a Python package designed to streamline and simplify interactions with blockchain networks and smart contracts. It consists of various utilities that enable users to manage RPC parameters, work with smart contract ABIs, and facilitate user-friendly interactions using graphical user interfaces (GUIs). [GITHUB-Abstract\_Blockchain](https://github.com/AbstractEndeavors/abstract_blockchain/tree/main)[PYPI-Abstract\_Blockchain](https://pypi.org/project/abstract-blockchain/) ## Available Modules * **abstract\_abis.py**: This module provides the `ABIBridge` class, an interface to Ethereum smart contract ABIs. It allows interactions with contract functions and retrieves read-only functions. Additionally, it categorizes RPC parameters for easier blockchain interaction. * **abstract\_apis.py**: Houses the `APIBridge` class for managing API URL creation and their respective calls. It contains GUI-enabled tools to build API URLs or fetch preselected call parameters. * **abstract\_rpcs.py**: This module offers the `RPCBridge` class that manages the RPC parameters for different blockchain networks. It provides a GUI for filtering and selecting RPC parameters and organizes them for easy use. * **abstract\_accounts.py**: The `ACCTBridge` class in this module allows interfacing with your personal wallet. You can build transaction information, derive public keys, and send/verify transactions. * **abstract\_contract\_console.py**: This section of the module integrates all classes for a harmonious interaction with smart contracts. * **abstract\_gui.py** : This submodule provides utilities for creating GUIs that enhance user interaction with blockchain-related features. * **main.py**: This is the entry point of the package where files are uploaded. ## Installation The package is available on [PyPI](https://pypi.org/project/abstract-blockchain/). You can install it using pip with `pip install abstract-blockchain`. [providing a Pythonic interface to their Application Binary Interfaces \(ABIs\).](https://preview.redd.it/hm5vhud55o6c1.png?width=604&format=png&auto=webp&s=654f1011dd48b0230dfbd5c175d243502fe9f683) ## Example Usage from abstract_abis import ABIBridge from abstract_apis import Choose_RPC_Parameters_GUI, RPCData # Example usage of ABIBridge abi_manager = ABIBridge(contract_address='0x3dCCeAE634f371E779c894A1cEa43a09C23af8d5', rpc=default_rpc()) read_only_functions = abi_manager.get_read_only_functions() for each in read_only_functions: inputs = abi_manager.get_required_inputs(each) if len(inputs) == 0: result = abi_manager.call_function(each) print(each, result) else: print(each, inputs) # Example usage of RPCData and GUI rpc_data = Choose_RPC_Parameters_GUI() rpc_manager = RPCData(rpc_data) w3 = rpc_manager.w3 # Your blockchain interactions using w3... ## Installation The `abstract_blockchain` package can be installed using pip: pip install abstract_blockchain ## Module - abstract_accounts.py This module, under the `abstract_blockchain` package, includes the `ACCTBridge` class, providing an interface to the user's personal wallet. It interacts with Ethereum accounts, allowing the user to perform transactions, estimate gas, retrieve transaction counts, sign and send transactions, and handle Ethereum addresses. The module primarily leverages other modules and classes from `abstract_rpcs.py` and `abstract_apis.py`, requiring the `eth_account` package to interact with Ethereum accounts. The critical methods within the `ACCTBridge` class include: * `__init__`: Initializes the `ACCTBridge` object, establishing an RPC bridge for interaction and retrieves the private key and account address. * `check_priv_key` & `get_address_from_private_key`: Manages operations related to the private key and converts it into an Ethereum address. * `build_txn` & `get_txn_info`: Allows the user to build a transaction, accounting for multiple variables. * `check_sum` & `try_check_sum`: Manages the conversion of the address to a checksum address. * `get_transaction_count`: Fetches the transaction count of the Ethereum account. * `sign_transaction` & `send_transaction`: Handles the signing and sending of transactions. * `estimate_gas`: Estimates the gas fee for Ethereum transactions. The module employs a rate limiting manager to manage the frequency of requests, preventing the exceeding of API rate limits. ## Module - abstract_abis.py Part of the `abstract_blockchain` package, the `abstract_abis.py` module is a critical component intended to streamline interactions with Ethereum smart contracts, providing a Pythonic interface to their Application Binary Interfaces (ABIs). The core of this module is the `ABIBridge` class, which offers an encompassing interface for managing Ethereum contract ABIs. Just like the `abstract_accounts.py` module, `abstract_abis.py` performs various tasks in collaboration with other modules, principally `abstract_rpcs.py` and `abstract_apis.py`. It houses several methods responsible for: * `Validating` Ethereum addresses * Creating `ABI bridges` * `Enumerating` contract functions * `Accessing` read-only functions from contract ABIs * `Invoking` contract functions * `Acquiring` and `categorizing` RPC parameters that are crucial for interaction with the blockchain * `Managing` rate limiting for API requests The `ABIBridge` class also emphasizes contracts' functions, offering tools to list all functions, obtain necessary input details, and invoke functions smoothly. It also provides mechanisms to create functions ready to be executed in future operations. A default\_rpc() function is also included, providing a default RPC configuration used when an instance of ABIBridge is created. This function underlines how to utilize the ABIBridge class for tasks like interacting with Ethereum contracts, managing user interaction, retrieving read-only functions, obtaining required input details, and invoking contract functions. # Module - abstract_api_gui.py Part of the `abstract_blockchain` package, `abstract_api_gui.py` is a module that builds a Graphical User Interface (GUI) to simplify interactions with APIs. This module utilises `PySimpleGUI` for creating the GUI, and `abstract_utilities.list_utils` for utility functions. The primary features of this module include: * Declaring hard-coded API descriptions through `apiCallDesc` * Defining options for API actions using `options` * Streamlining API parameters with `inputs` Additionally, it introduces several functions to generate API GUI and manage user interactions: 1. `get_revised_dict()`: This function modifies a dictionary based on required keys. 2. `generate_api_variables()`: This function produces API variables based on user input. 3. `generate_api_gui(api_desc)`: Generates the GUI layout with the given API description. 4. `make_invisible_unless(window,values,visible_list,example)`: Manages UI elements' visibility based on user input. 5. `choose_api_gui()`: Renders the main GUI displaying available APIs, parameters, and execution results. In the main application execution, `choose_api_gui` function gets called to display the user interface. As user actions are detected in the dropdown or interaction buttons, relevant changes are made in the GUI, providing a user-friendly environment for API interaction. # The abstract_apis.py Script The `abstract_apis.py` script is a core component of the abstract-blockchain module. This script houses the `APIBridge` class which serves as the robust engine for API URL construction and execution, and efficient GUI management for RPC parameters. ## Key Components * `APIBridge` class: This primary class initializes with optional parameters, `api_data`, `rpc`, and `address`. To ensure smooth functionality and improve efficiency, the class imports from external modules namely, `abstract_webtools` and `abstract_utilities`. ## Methods of the APIBridge class include: * `get_api_data_string`: This method prepares the appropriate API data string based on the provided `api_data_type` and `address`. * `api_keys`: An essential method that retrieves API keys from the environment settings contingent on the scanner in use. * `get_http_variants`, `get_api_variants`: These methods lend a hand in navigating different versions of the API URL based on request requirements. * `try_api_url`: As the name suggests, this method obtains the API request URL. * `get_try`, `get_request`: Key in sending a request to the API URL with a focus on 'Rate-Limiting'. * `get_response`: This method parses the JSON response from the API. * `check_sum`, `try_check_sum`: Integral in ensuring the validity of an Ethereum address and converting it to a checksum address. * `safe_json_loads`: A safety-oriented method that loads JSON data as a dictionary or a list. Remember to study the functional activities of this module and understand its relevance in the larger abstract-blockchain module. Join us in the next section where we detail another integral part of the module, the abstract-api-gui.py script. # abstract_contract_console.py The `abstract_contract_console.py` module within the `abstract-blockchain` package offers a Graphical User Interface(GUI). This GUI is ideal for users interested in engaging interactively with the Smart Contracts on the Ethereum Blockchain. At its core, it is designed to provide a user-friendly console for interacting with Ethereum Smart Contract functions. The module imports required dependencies and presents helper functions to perform data conversions and error checks. This setup lays the foundation for an interface that allows users to input a contract address on the Ethereum Blockchain. Once the address is provided, the interface makes a connection with a network node that will process the desired transactions and fetch available contract functions. All available functions are displayed in the GUI, which features input fields and buttons to facilitate interaction. The GUI shows the return value for functions having 'read' or 'pure' mutability; for transaction-triggering functions, the transaction hash is displayed. Notably, this module also permits users to manually input their account details, vital for signing transactions when calling non-read-only functions. Determining the Endpoint URL to connect to an Ethereum node is made simple with the `get_account_layout` and `determine_correct_rpc` functions. Operating within a GUI Event Loop, the interface maintains responsiveness and interactive capabilities. When a button associated with a contract function is clicked, input values are collected, the function is executed, and the output is displayed. In summary, `abstract_contract_console.py` emulates a local Ethereum interaction console, simplifying users' interactions with the Ethereum Blockchain and providing an all-in-one abstraction service. Furthermore, the module features an `abstract_contract_console_main()`. This function leverages various classes from the package for smart contract interaction and accepts an optional 'rpc\_list' argument. If no argument is provided, it defaults to the RPC list from the RPCBridge class. To launch a new window titled 'New Blockchain Console,' it retrieves the RPC layout and values, constructs a final layout consisting of the account, ABI, and RPC layouts. The new\_window\_mgr object's `while_basic()` method responsibly handles the main application loop, managing events and rendering. ## Overview The `abstract_contracts.py` script is a part of the `abstract_blockchain` module which is designed to facilitate the interaction of users with the Ethereum network. The script is built around a suite of utility functions which assist users in communicating with smart contracts on the blockchain, providing an easy and effective way to perform a variety of tasks from simple data conversions to transaction generation. ## Key Features 1. **Versatile Utility Functions:** The script offers utility functions which handle a wide range of features including estimation of average gas price for transactions, verification and handling of different input types (e.g., boolean, integers, and addresses), and user interaction management through GUIs. 2. **Data Type Conversion:** It supports conversion of different data types (e.g., addresses, integers, bytes, boolean values, and strings) to their required format for interaction with the Ethereum blockchain. 3. **User-friendly Interaction:** The script provides a comfortable user interface, allowing for inputs confirmation for a smart contract function or generation of a new transaction. 4. **Error Handling and Validation:** It manages various situations and edge cases, such as checking the validity of a potential Ethereum address and dealing with batch inputs. It provides intuitive feedback and correction options throughout the code execution. ## abstract_contract Module The `abstract_contracts.py` script within the abstract\_blockchain module is designed to enhance user interaction with blockchain contracts associated with the Ethereum network. This script extensively uses the web3 module to enable these interactions while also leveraging PySimpleGUI to deliver a simple yet effective graphical user interface. The script initiates with the importation of needed modules and subsequently defines several utility functions. These functions specialize in aiding users in contract communication and boosting their utilization of smart contracts within the Ethereum network. Several features are encompassed by these functions such as average gas price estimation for transactions, verification and management of multiple input types including boolean, integers, and addresses, user interaction facilitation via GUIs, and tasks like check-summing for Ethereum addresses. Further, they empower users to interact directly with the blockchain, such as confirming inputs for a smart contract function or even producing a new transaction. The script introduces functions to convert a diverse range of data types to a format that is suitable for the interaction with the Ethereum blockchain. Data types like addresses, integers, bytes, boolean values, and strings are all catered to. They also support list processing of these data types, allowing for batch operations. The functions are coded to handle a broad array of situations and edge cases such as validating potential Ethereum addresses and managing batch inputs. The code regularly provides intuitive feedback and correction options. Overall, this script serves as a comprehensive suite of tools for users interested in interacting with smart contract careers on the Ethereum network. ## abstract_rpcs Module The abstract\_rpcs.py script is part of the Abstract Blockchain package and it offers the RPCBridge class that is designed to manage RPC parameters for different blockchain networks. RPC parameters are necessary for remote procedure calls (RPC), a protocol that one program can use to request a service from a program located in another computer on a network without having to understand the network's details. In the context of blockchain, RPC parameters are used to interact with the blockchain network. The RPCBridge class in abstract\_rpcs.py provides several key functionalities. It allows users to filter and select RPC parameters through a graphical user interface (GUI), streamlining the process of defining these parameters. This makes it user-friendly even for those without deep knowledge of RPC parameters. The RPCBridge class also categorizes and organizes RPC parameters, so that they can easily be used in blockchain interactions. Information is thus made more accessible, and the usage of blockchain technology is simplified as a result. Overall, the abstract\_rpcs.py script plays a crucial role in the Abstract Blockchain package by providing efficient and streamlined ways to manage RPC parameters, one of the essential parts of interacting with blockchain networks. In conclusion, `abstract_blockchain` is a powerful tool that allows developers to interact with Ethereum networks and contracts. While the package is easy to install and use, we always recommend carefully reading the documentation and understanding how blockchain technologies work before getting started. Happy coding! For more info regarding license, please visit [here](https://github.com/AbstractEndeavors/abstract_blockchain/blob/main/LICENSE).	2.0	t3_18jsnyc	reddit		
231	Personal Telegram Bot with ChatGPT, Stable Diff, Kandinsky and other useful tools	Unknown	2023-12-15 15:03:37	https://www.reddit.com/r/Python/comments/18j23f9/personal_telegram_bot_with_chatgpt_stable_diff/	Hello everyone, I have created a Telegram bot with a lot of useful features that can be helpful for you too: \- Most OpenAI models (GPT4, Dalle3, TTS, Whisper) \- A large number of free models hosted in Replicate (Kandinsky, Stable Diffusion, Blip, LLama) \- Ability to download media content from various sources Please leave stars if you liked my project Github: [https://github.com/Sets88/sets88\_telegram\_bot](https://github.com/Sets88/sets88_telegram_bot)	1.0	t3_18j23f9	reddit		
232	PyCon US 2024 Registration Now Open	:litestar-logo: Litestar Maintainer & :ruff-logo: Ruff Fanboy 	2023-12-15 08:20:39	https://www.reddit.com/r/Python/comments/18ivdl7/pycon_us_2024_registration_now_open/	# PyCon US 2024 Registration Opens &#x200B; * [Register Now](https://us.pycon.org/2024/registration/register) * [PyCon Blog Announcement](https://pycon.blogspot.com/2023/12/pycon-us-2024-registration-launch.html) You have 30 days until the early bird pricing is gone! ### Early Bird Registration prices PyCon US offers discounted early bird rates for Corporate, Individual, and Student ticket types **for the first 30 days** that registration is open. All rates will switch to the regular rate prices on January 13, 2024. |Cost|Rate| |:-|:-| |650|Corporate| |350|Individual| |75|Student| |100|Online (not included in Early Bird Discount)| &#x200B; ## Details May 15 - May 23, 2024 - Pittsburgh, Pennsylvania Conference breakdown: * Tutorials: May 15 - 16, 2024 * Main Conference and Online: May 17 - 19, 2024 * Job Fair: May 19, 2024 * Sprints: May 20 - May 23, 2024 &#x200B;	1.0	t3_18ivdl7	reddit		
233	Simplifying django-rest-framework Testing with drf-api-action	Unknown	2023-12-15 15:21:32	https://www.reddit.com/r/Python/comments/18j2hjy/simplifying_djangorestframework_testing_with/	Hi all! I’m proud to share my new first open-source project drf-api-action. https://github.com/Ori-Roza/drf-api-action This project was built as a side project at work in which we had to tweak DRF for our own needs, this project was successful back then so I wanted to publish it to everyone :) The drf-api-action Python package is designed to elevate your testing experience for Django Rest Framework (DRF) REST endpoints. With the custom decorator api-action, this package empowers you to effortlessly test your REST endpoints as if they were conventional functions. Features: Simplified Testing: Testing DRF REST endpoints using the api-action decorator, treating them like regular functions. Seamless Integration: Replacing DRF's action decorator with api-action in your WebViewSet seamlessly. Clear Traceback: Instead of getting a response with error code, get the real traceback that led to the error. Pagination Support: Paginating easily through pages by a single kwarg. Please let me know what you think/ any feedback. It means a lot since it's my first open-source project :) \#feedback #feedbackwelcome #djangorestframework #python #django	0.0	t3_18j2hjy	reddit		
234	Implementing 3.12 nested strings to build device configurations without Jinja	Unknown	2023-12-14 23:49:51	https://www.reddit.com/r/Python/comments/18imcvy/implementing_312_nested_strings_to_build_device/	"So I was playing around with 3.12's newly expanded f-string capability to see how it well could work for building network device configurations. I was able to come up with something pretty cool that worked but it used an eval statement which I am not a fan of. Can anyone think of a clean way to achieve this without using eval? #!/usr/bin/python3.12 def repeat(input_data): response = """" input_data = ""f\""\""\"""" + input_data + ""\""\""\"""" for i in range(5): interface = f""1/{i}"" description = f""test user interface {i}"" response = response + eval(input_data) + ""\n"" return response.strip() config = f"""""" This is a test of {repeat(""""""\ interface {interface} description {description}"""""")} The test is ending """""" print(config) result: This is an f-string test interface 1/0 description test user interface 0 interface 1/1 description test user interface 1 interface 1/2 description test user interface 2 interface 1/3 description test user interface 3 interface 1/4 description test user interface 4 The test is ending &#x200B; Keep in mind that in the real world `config` is more like 300 lines long and not 6. This is why I am trying to keep `config` as clean and compact as possible sacrificing complexity elsewhere. What do you think about this complexity trade offs, is eval a mortal sin if I always control the input?"	4.0	t3_18imcvy	reddit		
235	Python course for Duality Views (JSON + Relational at the same time)	Unknown	2023-12-15 16:49:17	https://www.reddit.com/r/Python/comments/18j4ggg/python_course_for_duality_views_json_relational/	Hi Python devs! I had created a workshop for learning how to use Python with JSON and Oracle Duality Views. The Duality Views allows to work with JSON and Relational and the same time, combining the benefits of both! If you want to have a short overview, you can go to this linkedin post with a short video summary [Duality Views Video](https://www.linkedin.com/posts/javier-de-la-torre-medina_oracle-json-python-activity-7136277598828904448-7a5c) which points to [dev.to](https://dev.to) blogs where all the details and code are there. Willing to hear your feedback!	0.0	t3_18j4ggg	reddit		
236	A simple library to write and read disk based datasets for ML training	Unknown	2023-12-15 08:00:48	https://www.reddit.com/r/Python/comments/18iv3l1/a_simple_library_to_write_and_read_disk_based/	"If you don't have enough RAM to load the whole dataset, it is probably required to load them during training. Here is a simple library to help with that (link at the end). The main class of the library is `SplitDataLoader`. It supports len() and indexing. The ""split"" here is for splitting the dataset into tiny files. This seems to help with a number of issues. One of them is the shuffling of data during loading. Additionally, the library also has a helper routine to run a generator in another process and get the result via a queue. This will make sure that the training loop does not have to wait for data loading. Writing data looks like this: from splitdataloader import write_split_data def example_writer(...): # Get the data source data_source: Iterable[bytes] = some_source() target_dir = ""tmp/training_data"" write_split_data(target_dir, data_source, splits=128) And reading would look like this: from splitdataloader import SplitDataLoader def example_loader(...): # Get the data source data_dir = ""tmp/training_data"" loader = SplitDataLoader(data_dir) # Supports len() print(len(loader)) # Supports indexing data = loader[2] # Supports iteration for data in loader.iterate_binwise(shuffle=True): do_something(data) This is the library: [https://github.com/charstorm/split-data-loader](https://github.com/charstorm/split-data-loader)"	0.0	t3_18iv3l1	reddit		
237	Staying Excited about Python!	Unknown	2023-12-14 21:09:35	https://www.reddit.com/r/Python/comments/18iirrf/staying_excited_about_python/	Hey all, I was just wondering what kinds of resources do you use to stay updated about current trends in the Python community? Websites, podcasts, YouTube channels?!? I joined a few meetups in my local area and they’re awesome (but only once a month or so)! Looking for a more condensed/valuable r/Python. Thanks!	5.0	t3_18iirrf	reddit		
238	GPT-4 Advanced Data Analysis: A Beginner’s Guide to Charts and Maps	Unknown	2023-12-15 15:46:13	https://www.reddit.com/r/Python/comments/18j31fc/gpt4_advanced_data_analysis_a_beginners_guide_to/	🌍 Calling all data science mapping enthusiasts! The #GPT4 Advanced Data Analysis tool simplifies the data visualization process. This article shows beginners how to create on-the-fly maps and charts from just a CSV file.📊 👇 👇 **Medium Friend Link (No Paywall)**: [https://pub.towardsai.net/gpt-4-advanced-data-analysis-a-beginners-guide-to-charts-and-maps-d59763487750?source=friends\_link&sk=faceba7fdb89a4363f3dfae5043b02d6](https://pub.towardsai.net/gpt-4-advanced-data-analysis-a-beginners-guide-to-charts-and-maps-d59763487750?source=friends_link&sk=faceba7fdb89a4363f3dfae5043b02d6) [Dall-E 2 image: impressionist painting in oil colors of a map of earth](https://preview.redd.it/5tvx1tqybh6c1.png?width=1008&format=png&auto=webp&s=52791016fc70496ca025719aa58150c7ae8da907)	0.0	t3_18j31fc	reddit		
239	Registration is open for PyCon US 2024	:pythonLogo: Python Software Foundation Staff	2023-12-14 23:13:54	https://www.reddit.com/r/Python/comments/18illcu/registration_is_open_for_pycon_us_2024/	We'll be in Pittsburgh PA this year, May 16-23 2024, and early bird prices are in effect now through January 12. [Lots more information on the PyCon US site](https://us.pycon.org/2024/attend/information/).	1.0	t3_18illcu	reddit		
240	Monadic-Error Package	Unknown	2023-12-14 15:21:53	https://www.reddit.com/r/Python/comments/18iaz0x/monadicerror_package/	Hey everyone, I just recently published a new version of a python package called `monadic-error`. This library implements two error handling monads: Option and Attempt (or if you're familiar with Haskell Maybe and Either), along with some helper functions and decorators to make integration into current code easy. I'd love some feedback on improvements for the library, and on the coding style in general. The library is written using Python 3.12 type syntax. PyPI: https://pypi.org/project/monadic-error/ Source Code: https://github.com/ikollipara/monadic-error	4.0	t3_18iaz0x	reddit		
241	Check wrong private function calls pre-commit hook	Unknown	2023-12-14 17:15:55	https://www.reddit.com/r/Python/comments/18idhhz/check_wrong_private_function_calls_precommit_hook/	Python doesn't actually complain about a private function being called outside of the module it was defined, but to do that is bad practice. As a code owner of several begginer friendly open source projects I decided to create a pre-commit hook that checks that and throws an exception if one of those bad function calls is found. [Eric-Mendes/private-calls-pre-commit: pre-commit hook that checks whether a private function is being called outside of its module. (github.com)](https://github.com/Eric-Mendes/private-calls-pre-commit) Not everything is working as expected, but I'm open for contributions!	2.0	t3_18idhhz	reddit		
242	Implementing Role-Based Access Control in Django	Unknown	2023-12-14 15:46:41	https://www.reddit.com/r/Python/comments/18ibhyh/implementing_rolebased_access_control_in_django/	Hi folks, We've written a brief guide to demonstrate how to implement Role-Based Access Control (RBAC) in a Django app 🔒 In particular, we've utilized Django's built-in authentication system to enable or restrict user access to resources and actions based on the permissions assigned to their roles. Here's the post if you're interested: [https://www.permify.co/post/rbac-in-django/](https://www.permify.co/post/rbac-in-django/) Looking forward for your feedbacks!!	0.0	t3_18ibhyh	reddit		
243	De4py toolkit for python RE v1.0.4 has been released	Unknown	2023-12-14 16:45:35	https://www.reddit.com/r/Python/comments/18icssg/de4py_toolkit_for_python_re_v104_has_been_released/	[De4py v1.0.4](https://github.com/Fadi002/de4py/releases/tag/v1.0.4-stable) update has been released and includes an advanced feature that can be used for analysis of python files by monitoring it's behavior. in this update a major feature have taken place, memory analyzing (WinAPI hooking). Monitoring Files: * Monitoring File Handles Creation Monitoring Processes: * Monitoring Process handle * Monitoring if the process tried to write/read to a process * Monitoring Termination of other processes Monitoring Connections: * Monitoring Socket creation * Monitoring sending/receiving of data with the size of data sent/recieved. &#x200B; more to come soon.	0.0	t3_18icssg	reddit		
244	Friday Daily Thread: r/Python Meta and Free-Talk Fridays	Unknown	2023-12-15 00:01:13	https://www.reddit.com/r/Python/comments/18imlqn/friday_daily_thread_rpython_meta_and_freetalk/	# Weekly Thread: Meta Discussions and Free Talk Friday 🎙️ Welcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related! ## How it Works: 1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community. 2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community. 3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting. ## Guidelines: * All topics should be related to Python or the /r/python community. * Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy). ## Example Topics: 1. **New Python Release**: What do you think about the new features in Python 3.11? 2. **Community Events**: Any Python meetups or webinars coming up? 3. **Learning Resources**: Found a great Python tutorial? Share it here! 4. **Job Market**: How has Python impacted your career? 5. **Hot Takes**: Got a controversial Python opinion? Let's hear it! 6. **Community Ideas**: Something you'd like to see us do? tell us. Let's keep the conversation going. Happy discussing! 🌟	2.0	t3_18imlqn	reddit		
245	Beam: Run Python functions on the cloud in seconds	Unknown	2023-12-13 15:02:59	https://www.reddit.com/r/Python/comments/18hiqyq/beam_run_python_functions_on_the_cloud_in_seconds/	"Hi r/python! I’m Eli, and my co-founder and I built [Beam](https://beam.cloud) to quickly get your Python code running on the cloud. All you need to do is install a Python SDK, add a decorator to your code, and run a CLI command to get a cloud endpoint for your function. Here is an extremely simple example of a function that can be deployed onto a GPU, as a REST API: from beam import App, Runtime, Image # Register your function to Beam app = App( name=""quickstart"", runtime=Runtime(gpu=""A10G"", image=Image(python_packages=[""requests"", ""pandas""])), ) # Add a decorator to any function to run it remotely @app.rest_api() def hello_world(): return {""This is running on the cloud remotely!""} This function can be deployed as a REST API by running only one command: `beam deploy app.py:hello_world` When you run this command, you’ll get a web endpoint with load balancing, authentication, and autoscaling. There’s also a web dashboard to view logs, metrics, and other data you’d want to monitor for your app. We also have GPU support, so it’s super easy to run compute-heavy workloads on the cloud using Beam. **The Pricing Model** Pricing is pay-for-what-you-use. Beam is serverless, so your apps will turn off when you’re not using them. If you don’t use your API, you don’t pay anything. It’s pretty simple. Also, Beam has a 10 hour free tier! You can sign up and immediately start running workloads for free. **Things you can build with Beam** * [GPU-accelerated APIs for AI inference](https://docs.beam.cloud/examples/stable-diffusion-gpu) * [Web scrapers](https://docs.beam.cloud/examples/reddit-posts) * [ASGI apps](https://docs.beam.cloud/examples/gradio) * [Cron jobs](https://docs.beam.cloud/deployment/schedule) This is a relatively new platform, so it would be great to hear your thoughts and feedback. Thanks for checking it out! [https://docs.beam.cloud](https://docs.beam.cloud)"	21.0	t3_18hiqyq	reddit		
246	The Evolution of GPT-4: Crafting Python Plotly Dashboards With Ease	Unknown	2023-12-14 16:23:02	https://www.reddit.com/r/Python/comments/18icaki/the_evolution_of_gpt4_crafting_python_plotly/	A few months ago, I wrote a series of (moderately successful) articles on how to prompt GPT-4 for Python ***plotly*** dashboard creation. Back then, I ran into some limitations on the capabilities available - namely GPT-4 would cough, cry, and complain about creating multi-visual Plotly dashboard code. And so would I. It was frustrating. With the added functionality in the main chat window, can GPT-4 NOW handle the task of ***seamlessly creating*** complex plotly dashboard code from an uploaded CSV? The answer is yes! Here’s how it works. **MEDIUM FRIEND LINK (no paywall):** [https://pub.towardsai.net/the-evolution-of-gpt-4-crafting-python-plotly-dashboards-with-ease-7216952c476d?source=friends\_link&sk=3dd90dbc4647840ed15c141a4d8be7da](https://pub.towardsai.net/the-evolution-of-gpt-4-crafting-python-plotly-dashboards-with-ease-7216952c476d?source=friends_link&sk=3dd90dbc4647840ed15c141a4d8be7da) [Dall-E 2 image: impressionist painting of a global dashboard](https://preview.redd.it/i2jj8majda6c1.png?width=1008&format=png&auto=webp&s=8322ad767bcd1a52942cc893ab49f91363d4f730) &#x200B; &#x200B;	0.0	t3_18icaki	reddit		
247	I made a Windows Notepad Alternative with PyQt6!	Unknown	2023-12-13 15:12:25	https://www.reddit.com/r/Python/comments/18hiyes/i_made_a_windows_notepad_alternative_with_pyqt6/	ZenNotes is a minimalistic Notepad app with a sleek design inspired by [Fluent Design](https://fluent2.microsoft.design/). It offers the familiar look of the Windows Notepad while having much more powerful features like Translation, TTS, etc. GitHub: [https://github.com/rohankishore/ZenNotes](https://github.com/rohankishore/ZenNotes) Please star 🌟 the repo if you like my project. Also, visit Aura Text ([https://github.com/rohankishore/Aura-Text](https://github.com/rohankishore/Aura-Text)), my IDE project [UI](https://preview.redd.it/i9zm39ywv26c1.png?width=1444&format=png&auto=webp&s=0aa157effcacaa2f9eaaf66b621eb54e81258e23)	10.0	t3_18hiyes	reddit		
248	Cyclopts: A CLI library that fixes 13 annoying issues in Typer	Unknown	2023-12-13 18:09:46	https://www.reddit.com/r/Python/comments/18hn2t1/cyclopts_a_cli_library_that_fixes_13_annoying/	Like many users here, I've used Typer because of its popularity and how it seemingly removed a lot of boilerplate from CLI creation. However, after getting past the shiny exterior, I quickly found it unnecessary bloated function signatures, lacked a lot of features (such as supporting Literal types!), and the author is famous for not addressing issues and merging in pull-requests. So, I created my own CLI library, Cyclopts, that addresses all of these issues. Please check it out! Typer Comparison: [https://cyclopts.readthedocs.io/en/latest/vs\_typer/README.html](https://cyclopts.readthedocs.io/en/latest/vs_typer/README.html) Project Page: [https://github.com/BrianPugh/cyclopts](https://github.com/BrianPugh/cyclopts)	8.0	t3_18hn2t1	reddit		
249	Good cheat sheet for beginners	Unknown	2023-12-13 13:20:22	https://www.reddit.com/r/Python/comments/18hgn7c/good_cheat_sheet_for_beginners/	So I am writing an exam next week in python and R and we are allowed to have all kinds of cheat sheets. Chat bots are not allowed though which is kinda fucking me over because Im only somewhat good at coding in R and I would normally use ChatGPT to translate R code to python. The exam is very basic. The hardest part is knowing the commands for tidying and manipulating data and just general stuff. Is anyone aware of a good cheat sheet like a HTML file where you could use the search function for example to look up specific code? Because I have looked for something like this and failed to find anything. Any help would be greatly appreciated! Thanks	4.0	t3_18hgn7c	reddit		
250	Making Python Code Idiomatic by Automatic Refactoring Non-Idiomatic Python Code with Pythonic Idioms	Zejun Zhang	2022-07-12 15:30:46	http://arxiv.org/abs/2207.05613v1	Compared to other programming languages (e.g., Java), Python has more idioms to make Python code concise and efficient. Although pythonic idioms are well accepted in the Python community, Python programmers are often faced with many challenges in using them, for example, being unaware of certain pythonic idioms or do not know how to use them properly. Based on an analysis of 7,638 Python repositories on GitHub, we find that non-idiomatic Python code that can be implemented with pythonic idioms occurs frequently and widely. Unfortunately, there is no tool for automatically refactoring such non-idiomatic code into idiomatic code. In this paper, we design and implement an automatic refactoring tool to make Python code idiomatic. We identify nine pythonic idioms by systematically contrasting the abstract syntax grammar of Python and Java. Then we define the syntactic patterns for detecting non-idiomatic code for each pythonic idiom. Finally, we devise atomic AST-rewriting operations and refactoring steps to refactor non-idiomatic code into idiomatic code. We test and review over 4,115 refactorings applied to 1,065 Python projects from GitHub, and submit 90 pull requests for the 90 randomly sampled refactorings to 84 projects. These evaluations confirm the high-accuracy, practicality and usefulness of our refactoring tool on real-world Python code. Our refactoring tool can be accessed at 47.242.131.128:5000.			arxiv	['Zhenchang Xing', 'Xin Xia', 'Xiwei Xu', 'Liming Zhu']	1.0
251	Modern Python at the Large Synoptic Survey Telescope	Tim Jenness	2017-12-01 19:04:46	http://arxiv.org/abs/1712.00461v1	The LSST software systems make extensive use of Python, with almost all of it initially being developed solely in Python 2. Since LSST will be commissioned when Python 2 is end-of-lifed it is critical that we have all our code support Python 3 before commissioning begins. Over the past year we have made significant progress in migrating the bulk of the code from the Data Management system onto Python 3. This paper presents our migration methodology, and the current status of the port, with our eventual aim to be running completely on Python 3 by early 2018. We also discuss recent modernizations to our Python codebase.			arxiv	[]	2.0
252	Python GUI Scripting Interface for Running Atomic Physics Applications	Amani Tahat	2011-06-05 01:11:08	http://arxiv.org/abs/1106.0868v1	We create a Python GUI scripting interface working under Windows in addition to (UNIX/Linux). The GUI has been built around the Python open-source programming language. We use the Python's GUI library that so called Python Mega Widgets (PMW) and based on Tkinter Python module (http://www.freenetpages.co.uk/hp/alan.gauld/tutgui.htm). The new GUI was motivated primarily by the desire of more updated operations, more flexibility incorporating future and current improvements in producing atomic data. Furthermore it will be useful for a variety of applications of atomic physics, plasma physics and astrophysics and will help in calculating various atomic properties.			arxiv	['Mofleh Tahat']	3.0
253	Towards Memory Safe Python Enclave for Security Sensitive Computation	Huibo Wang	2020-05-12 18:19:08	http://arxiv.org/abs/2005.05996v1	Intel SGX Guard eXtensions (SGX), a hardware-supported trusted execution environment (TEE), is designed to protect security-sensitive applications. However, since enclave applications are developed with memory unsafe languages such as C/C++, traditional memory corruption is not eliminated in SGX. Rust-SGX is the first toolkit providing enclave developers with a memory-language. However, Rust is considered a Systems language and has become the right choice for concurrent applications and web browsers. Many application domains such as Big Data, Machine Learning, Robotics, Computer Vision are more commonly developed in the python programming language. Therefore, Python application developers cannot benefit from secure enclaves like Intel SGX and rust-SGX. To fill this gap, we propose Python-SGX, which is a memory-safe SGX SDK providing enclave developers a memory-safe Python development environment. The key idea is to enable memory-safe Python language in SGX by solving the following key challenges: (1) defining a memory-safe Python interpreter (2)replacing unsafe elements of Python interpreter with safe ones,(3) achieving comparable performance to non-enclave Python applications, and (4) not introducing any unsafe new code or libraries into SGX. We propose to build Python-SGX with PyPy, a Python interpreter written by RPython, which is a subset of Python, and tame unsafe parts in PyPy by formal verification, security hardening, and memory safe language. We have implemented python-SGX and tested it with a series of benchmarks programs. Our evaluation results show that Python-SGX does not cause significant overhead.			arxiv	['Mingshen Sun', 'Qian Feng', 'Pei Wang', 'Tongxin Li', 'Yu Ding']	4.0
254	Porting the LSST Data Management Pipeline Software to Python 3	Tim Jenness	2016-11-02 19:48:34	http://arxiv.org/abs/1611.00751v1	The LSST data management science pipelines software consists of more than 100,000 lines of Python 2 code. LSST operations will begin after support for Python 2 has been dropped by the Python community in 2020, and we must therefore plan to migrate the codebase to Python 3. During the transition period we must also support our community of active Python 2 users and this complicates the porting significantly. We have decided to use the Python future package as the basis for our port to enable support for Python 2 and Python 3 simultaneously, whilst developing with a mindset more suited to Python 3. In this paper we report on the current status of the port and the difficulties that have been encountered.			arxiv	[]	5.0
255	A general approach for running Python codes in OpenFOAM using an embedded pybind11 Python interpreter	Simon Rodriguez	2022-03-30 15:25:03	http://arxiv.org/abs/2203.16394v1	As the overlap between traditional computational mechanics and machine learning grows, there is an increasing demand for straight-forward approaches to interface Python-based procedures with C++-based OpenFOAM. This article introduces one such general methodology, allowing the execution of Python code directly within an OpenFOAM solver without the need for Python code translation. The proposed approach is based on the lightweight library pybind11, where OpenFOAM data is transferred to an embedded Python interpreter for manipulation, and results are returned as needed. Following a review of related approaches, the article describes the approach, with a particular focus on data transfer between Python and OpenFOAM, executing Python scripts and functions, and practical details about the implementation in OpenFOAM. Three complementary test cases are presented to highlight the functionality and demonstrate the effect of different data transfer approaches: a Python-based velocity profile boundary condition; a Python-based solver for prototyping; and a machine learning mechanical constitutive law class for solids4foam which performs field calculations.			arxiv	['Philip Cardiff']	6.0
256	Python for education: the exact cover problem	Andrzej Kapanowski	2010-10-28 08:53:26	http://arxiv.org/abs/1010.5890v1	Python implementation of Algorithm X by Knuth is presented. Algorithm X finds all solutions to the exact cover problem. The exemplary results for pentominoes, Latin squares and Sudoku are given.			arxiv	[]	7.0
257	Teddy: Automatic Recommendation of Pythonic Idiom Usage For Pull-Based Software Projects	Purit Phan-udom	2020-09-05 12:54:57	http://arxiv.org/abs/2009.03302v1	Pythonic code is idiomatic code that follows guiding principles and practices within the Python community. Offering performance and readability benefits, Pythonic code is claimed to be widely adopted by experienced Python developers, but can be a learning curve to novice programmers. To aid with Pythonic learning, we create an automated tool, called Teddy, that can help checking the Pythonic idiom usage. The tool offers a prevention mode with Just-In-Time analysis to recommend the use of Pythonic idiom during code review and a detection mode with historical analysis to run a thorough scan of idiomatic and non-idiomatic code. In this paper, we first describe our tool and an evaluation of its performance. Furthermore, we present a case study that demonstrates how to use Teddy in a real-life scenario on an Open Source project. An evaluation shows that Teddy has high precision for detecting Pythonic idiom and non-Pythonic code. Using interactive visualizations, we demonstrate how novice programmers can navigate and identify Pythonic idiom and non-Pythonic code in their projects. Our video demo with the full interactive visualizations is available at https://youtu.be/vOCQReSvBxA.			arxiv	['Naruedon Wattanakul', 'Tattiya Sakulniwat', 'Chaiyong Ragkhitwetsagul', 'Thanwadee Sunetnanta', 'Morakot Choetkiertikul', 'Raula Gaikovina Kula']	8.0
258	Machine Learning using Stata/Python	Giovanni Cerulli	2021-03-03 10:31:44	http://arxiv.org/abs/2103.03122v1	We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting popular Machine Learning (ML) methods both in regression and classification settings. Using the recent Stata/Python integration platform (sfi) of Stata 16, these commands provide hyper-parameters' optimal tuning via K-fold cross-validation using greed search. More specifically, they make use of the Python Scikit-learn API to carry out both cross-validation and outcome/label prediction.			arxiv	[]	9.0
259	Using Python for Model Inference in Deep Learning	Zachary DeVito	2021-04-01 04:48:52	http://arxiv.org/abs/2104.00254v1	Python has become the de-facto language for training deep neural networks, coupling a large suite of scientific computing libraries with efficient libraries for tensor computation such as PyTorch or TensorFlow. However, when models are used for inference they are typically extracted from Python as TensorFlow graphs or TorchScript programs in order to meet performance and packaging constraints. The extraction process can be time consuming, impeding fast prototyping. We show how it is possible to meet these performance and packaging constraints while performing inference in Python. In particular, we present a way of using multiple Python interpreters within a single process to achieve scalable inference and describe a new container format for models that contains both native Python code and data. This approach simplifies the model deployment story by eliminating the model extraction step, and makes it easier to integrate existing performance-enhancing Python libraries. We evaluate our design on a suite of popular PyTorch models on Github, showing how they can be packaged in our inference format, and comparing their performance to TorchScript. For larger models, our packaged Python models perform the same as TorchScript, and for smaller models where there is some Python overhead, our multi-interpreter approach ensures inference is still scalable.			arxiv	['Jason Ansel', 'Will Constable', 'Michael Suo', 'Ailing Zhang', 'Kim Hazelwood']	10.0
260	Python Type Hints are Turing Complete	Ori Roth	2022-08-31 10:11:42	http://arxiv.org/abs/2208.14755v1	Grigore showed that Java generics are Turing complete by describing a reduction from Turing machines to Java subtyping. We apply Grigore's algorithm to Python type hints and deduce that they are Turing complete. In addition, we present an alternative reduction in which the Turing machines are simulated in real time, resulting in significantly lower compilation times. Our work is accompanied by a Python implementation of both reductions that compiles Turing machines into Python subtyping machines.			arxiv	[]	11.0
261	OMB-Py: Python Micro-Benchmarks for Evaluating Performance of MPI Libraries on HPC Systems	Nawras Alnaasan	2021-10-20 16:59:14	http://arxiv.org/abs/2110.10659v2	Python has become a dominant programming language for emerging areas like Machine Learning (ML), Deep Learning (DL), and Data Science (DS). An attractive feature of Python is that it provides easy-to-use programming interface while allowing library developers to enhance performance of their applications by harnessing the computing power offered by High Performance Computing (HPC) platforms. Efficient communication is key to scaling applications on parallel systems, which is typically enabled by the Message Passing Interface (MPI) standard and compliant libraries on HPC hardware. mpi4py is a Python-based communication library that provides an MPI-like interface for Python applications allowing application developers to utilize parallel processing elements including GPUs. However, there is currently no benchmark suite to evaluate communication performance of mpi4py -- and Python MPI codes in general -- on modern HPC systems. In order to bridge this gap, we propose OMB-Py -- Python extensions to the open-source OSU Micro-Benchmark (OMB) suite -- aimed to evaluate communication performance of MPI-based parallel applications in Python. To the best of our knowledge, OMB-Py is the first communication benchmark suite for parallel Python applications. OMB-Py consists of a variety of point-to-point and collective communication benchmark tests that are implemented for a range of popular Python libraries including NumPy, CuPy, Numba, and PyCUDA. Our evaluation reveals that mpi4py introduces a small overhead when compared to native MPI libraries. We plan to publicly release OMB-Py to benefit the Python HPC community.			arxiv	['Arpan Jain', 'Aamir Shafi', 'Hari Subramoni', 'Dhabaleswar K Panda']	12.0
262	Does Coding in Pythonic Zen Peak Performance? Preliminary Experiments of Nine Pythonic Idioms at Scale	Pattara Leelaprute	2022-03-28 04:05:54	http://arxiv.org/abs/2203.14484v1	In the field of data science, and for academics in general, the Python programming language is a popular choice, mainly because of its libraries for storing, manipulating, and gaining insight from data. Evidence includes the versatile set of machine learning, data visualization, and manipulation packages used for the ever-growing size of available data. The Zen of Python is a set of guiding design principles that developers use to write acceptable and elegant Python code. Most principles revolve around simplicity. However, as the need to compute large amounts of data, performance has become a necessity for the Python programmer. The new idea in this paper is to confirm whether writing the Pythonic way peaks performance at scale. As a starting point, we conduct a set of preliminary experiments to evaluate nine Pythonic code examples by comparing the performance of both Pythonic and Non-Pythonic code snippets. Our results reveal that writing in Pythonic idioms may save memory and time. We show that incorporating list comprehension, generator expression, zip, and itertools.zip_longest idioms can save up to 7,000 MB and up to 32.25 seconds. The results open more questions on how they could be utilized in a real-world setting. The replication package includes all scripts, and the results are available at https://doi.org/10.5281/zenodo.5712349			arxiv	['Bodin Chinthanet', 'Supatsara Wattanakriengkrai', 'Raula Gaikovina Kula', 'Pongchai Jaisri', 'Takashi Ishio']	13.0
263	Pydelay - a python tool for solving delay differential equations	V. Flunkert	2009-11-09 11:00:43	http://arxiv.org/abs/0911.1633v1	pydelay is a python library which translates a system of delay differential equations into C-code and simulates the code using scipy weave.			arxiv	['E. Schoell']	14.0
264	Performance of Python runtimes on a non-numeric scientific code	Riccardo Murri	2014-04-25 10:55:48	http://arxiv.org/abs/1404.6388v2	The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational homology of the moduli space of Riemann surfaces is an example of a non-numeric scientific code: most of the processing it does is generating graphs (represented by complex Python objects) and computing their isomorphisms (a triple of Python lists; again a nested data structure). These operations are repeated many times over: for example, the spaces and are triangulated by 4'583'322 and 747'664 graphs, respectively. This is an opportunity for every Python runtime to prove its strength in optimization. The purpose of this experiment was to assess the maturity of alternative Python runtimes, in terms of: compatibility with the language as implemented in CPython 2.7, and performance speedup. This paper compares the results and experiences from running FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython 0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.			arxiv	[]	15.0
265	A Python Extension for the Massively Parallel Multiphysics Simulation Framework waLBerla	Martin Bauer	2015-11-23 15:06:47	http://arxiv.org/abs/1511.07261v1	We present a Python extension to the massively parallel HPC simulation toolkit waLBerla. waLBerla is a framework for stencil based algorithms operating on block-structured grids, with the main application field being fluid simulations in complex geometries using the lattice Boltzmann method. Careful performance engineering results in excellent node performance and good scalability to over 400,000 cores. To increase the usability and flexibility of the framework, a Python interface was developed. Python extensions are used at all stages of the simulation pipeline: They simplify and automate scenario setup, evaluation, and plotting. We show how our Python interface outperforms the existing text-file-based configuration mechanism, providing features like automatic nondimensionalization of physical quantities and handling of complex parameter dependencies. Furthermore, Python is used to process and evaluate results while the simulation is running, leading to smaller output files and the possibility to adjust parameters dependent on the current simulation state. C++ data structures are exported such that a seamless interfacing to other numerical Python libraries is possible. The expressive power of Python and the performance of C++ make development of efficient code with low time effort possible.			arxiv	['Florian Schornbaum', 'Christian Godenschwager', 'Matthias Markl', 'Daniela Anderl', 'Harald Köstler', 'Ulrich Rüde']	16.0
266	Generating Python Code From Object-Z Specifications	A. F. Al Azzawi	2018-02-17 11:41:24	http://arxiv.org/abs/1802.06224v1	Object-Z is an object-oriented specification language which extends the Z language with classes, objects, inheritance and polymorphism that can be used to represent the specification of a complex system as collections of objects. There are a number of existing works that mapped Object-Z to C++ and Java programming languages. Since Python and Object-Z share many similarities, both are object-oriented paradigm, support set theory and predicate calculus moreover, Python is a functional programming language which is naturally closer to formal specifications, we propose a mapping from Object-Z specifications to Python code that covers some Object-Z constructs and express its specifications in Python to validate these specifications. The validations are used in the mapping covered preconditions, post-conditions, and invariants that are built using lambda function and Python's decorator. This work has found Python is an excellent language for developing libraries to map Object-Z specifications to Python.			arxiv	['M. Bettaz', 'H. M. Al-Refai']	17.0
267	Building a scalable python distribution for HEP data analysis	David Lange	2018-04-24 10:07:02	http://arxiv.org/abs/1804.08939v1	There are numerous approaches to building analysis applications across the high-energy physics community. Among them are Python-based, or at least Python-driven, analysis workflows. We aim to ease the adoption of a Python-based analysis toolkit by making it easier for non-expert users to gain access to Python tools for scientific analysis. Experimental software distributions and individual user analysis have quite different requirements. Distributions tend to worry most about stability, usability and reproducibility, while the users usually strive to be fast and nimble. We discuss how we built and now maintain a python distribution for analysis while satisfying requirements both a large software distribution (in our case, that of CMSSW) and user, or laptop, level analysis. We pursued the integration of tools used by the broader data science community as well as HEP developed (e.g., histogrammar, root_numpy) Python packages. We discuss concepts we investigated for package integration and testing, as well as issues we encountered through this process. Distribution and platform support are important topics. We discuss our approach and progress towards a sustainable infrastructure for supporting this Python stack for the CMS user community and for the broader HEP user community.			arxiv	[]	18.0
268	How fast can we make interpreted Python?	Russell Power	2013-06-25 17:57:00	http://arxiv.org/abs/1306.6047v2	Python is a popular dynamic language with a large part of its appeal coming from powerful libraries and extension modules. These augment the language and make it a productive environment for a wide variety of tasks, ranging from web development (Django) to numerical analysis (NumPy). Unfortunately, Python's performance is quite poor when compared to modern implementations of languages such as Lua and JavaScript. Why does Python lag so far behind these other languages? As we show, the very same API and extension libraries that make Python a powerful language also make it very difficult to efficiently execute. Given that we want to retain access to the great extension libraries that already exist for Python, how fast can we make it? To evaluate this, we designed and implemented Falcon, a high-performance bytecode interpreter fully compatible with the standard CPython interpreter. Falcon applies a number of well known optimizations and introduces several new techniques to speed up execution of Python bytecode. In our evaluation, we found Falcon an average of 25% faster than the standard Python interpreter on most benchmarks and in some cases about 2.5X faster.			arxiv	['Alex Rubinsteyn']	19.0
269	Image Processing in Python With Montage	John Good	2019-08-26 15:50:25	http://arxiv.org/abs/1908.09753v1	The Montage image mosaic engine has found wide applicability in astronomy research, integration into processing environments, and is an examplar application for the development of advanced cyber-infrastructure. It is written in C to provide performance and portability. Linking C/C++ libraries to the Python kernel at run time as binary extensions allows them to run under Python at compiled speeds and enables users to take advantage of all the functionality in Python. We have built Python binary extensions of the 59 ANSI-C modules that make up version 5 of the Montage toolkit. This has involved a turning the code into a C library, with driver code fully separated to reproduce the calling sequence of the command-line tools; and then adding Python and C linkage code with the Cython library, which acts as a bridge between general C libraries and the Python interface. We will demonstrate how to use these Python binary extensions to perform image processing, including reprojecting and resampling images, rectifying background emission to a common level, creation of image mosaics that preserve the calibration and astrometric fidelity of the input images, creating visualizations with an adaptive stretch algorithm, processing HEALPix images, and analyzing and managing image metadata.			arxiv	['G. Bruce Berriman']	20.0
270	An Analysis of Python's Topics, Trends, and Technologies Through Mining Stack Overflow Discussions	Hamed Tahmooresi	2020-04-14 02:59:16	http://arxiv.org/abs/2004.06280v1	Python is a popular, widely used, and general-purpose programming language. In spite of its ever-growing community, researchers have not performed much analysis on Python's topics, trends, and technologies which provides insights for developers about Python community trends and main issues. In this article, we examine the main topics related to this language being discussed by developers on one of the most popular Q\&A websites, Stack Overflow, as well as temporal trends through mining 2461876 posts. To be more useful for the software engineers, we study what Python provides as the alternative to popular technologies offered by common programming languages like Java. Our results indicate that discussions about Python standard features, web programming, and scientific programming. Programming in areas such as mathematics, data science, statistics, machine learning, natural language processing (NLP), and so forth. are the most popular areas in the Python community. At the same time, areas related to scientific programming are steadily receiving more attention from the Python developers.			arxiv	['Abbas Heydarnoori', 'Alireza Aghamohammadi']	21.0
271	The Dune Python Module	Andreas Dedner	2018-07-13 19:17:48	http://arxiv.org/abs/1807.05252v1	In this paper we present the new Dune-Python module which provides Python bindings for the Dune core, which is a C++ environment for solving partial differential equations. The aim of this new module is to firstly provide the general infrastructure for exporting realizations of statically polymorphic interfaces based on just-in-time compilation and secondly to provide bindings for the central interfaces of the dune core modules. In the first release we focus on the grid interface. Our aim is to only introduce a thin layer when passing objects into Python which can be removed when the object is passed back into a C++ algorithm. Thus no efficiency is lost and little additional code maintenance cost is incurred. To make the transition for Dune users to the Python environment straightforward the Python classes provide a very similar interface to their C++ counterparts. In addition, vectorized versions of many interfaces allow for more efficient code on the Python side. The infrastructure for exporting these interfaces and the resulting bindings for a Dune grid are explained in detail in this paper for both experienced Dune users and others interested in a flexible Python environment for implementing grid based schemes for solving partial differential equations.			arxiv	['Martin Nolte']	22.0
272	Python Workflows on HPC Systems	Dominik Strassel	2020-12-01 09:51:12	http://arxiv.org/abs/2012.00365v1	The recent successes and wide spread application of compute intensive machine learning and data analytics methods have been boosting the usage of the Python programming language on HPC systems. While Python provides many advantages for the users, it has not been designed with a focus on multi-user environments or parallel programming - making it quite challenging to maintain stable and secure Python workflows on a HPC system. In this paper, we analyze the key problems induced by the usage of Python on HPC clusters and sketch appropriate workarounds for efficiently maintaining multi-user Python software environments, securing and restricting resources of Python jobs and containing Python processes, while focusing on Deep Learning applications running on GPU clusters.			arxiv	['Philipp Reusch', 'Janis Keuper']	23.0
273	Conflict-aware Inference of Python Compatible Runtime Environments with Domain Knowledge Graph	Wei Cheng	2022-01-18 14:55:00	http://arxiv.org/abs/2201.07029v1	Code sharing and reuse is a widespread use practice in software engineering. Although a vast amount of open-source Python code is accessible on many online platforms, programmers often find it difficult to restore a successful runtime environment. Previous studies validated automatic inference of Python dependencies using pre-built knowledge bases. However, these studies do not cover sufficient knowledge to accurately match the Python code and also ignore the potential conflicts between their inferred dependencies, thus resulting in a low success rate of inference. In this paper, we propose PyCRE, a new approach to automatically inferring Python compatible runtime environments with domain knowledge graph (KG). Specifically, we design a domain-specific ontology for Python third-party packages and construct KGs for over 10,000 popular packages in Python 2 and Python 3. PyCRE discovers candidate libraries by measuring the matching degree between the known libraries and the third-party resources used in target code. For the NP-complete problem of dependency solving, we propose a heuristic graph traversal algorithm to efficiently guarantee the compatibility between packages. PyCRE achieves superior performance on a real-world dataset and efficiently resolves nearly half more import errors than previous methods.			arxiv	['Xiangrong Zhu', 'Wei Hu']	24.0
274	Triangulating Python Performance Issues with Scalene	Emery D. Berger	2022-12-15 02:56:25	http://arxiv.org/abs/2212.07597v1	This paper proposes Scalene, a profiler specialized for Python. Scalene combines a suite of innovations to precisely and simultaneously profile CPU, memory, and GPU usage, all with low overhead. Scalene's CPU and memory profilers help Python programmers direct their optimization efforts by distinguishing between inefficient Python and efficient native execution time and memory usage. Scalene's memory profiler employs a novel sampling algorithm that lets it operate with low overhead yet high precision. It also incorporates a novel algorithm that automatically pinpoints memory leaks, whether within Python or across the Python-native boundary. Scalene tracks a new metric called copy volume, which highlights costly copying operations that can occur when Python silently converts between C and Python data representations, or between CPU and GPU. Since its introduction, Scalene has been widely adopted, with over 500,000 downloads to date. We present experience reports from developers who used Scalene to achieve significant performance improvements and memory savings.			arxiv	['Sam Stern', 'Juan Altmayer Pizzorno']	25.0
275	Python bindings for libcloudph++	Dorota Jarecka	2015-04-05 20:58:18	http://arxiv.org/abs/1504.01161v1	This technical note introduces the Python bindings for libcloudph++. The libcloudph++ is a C++ library of algorithms for representing atmospheric cloud microphysics in numerical models. The bindings expose the complete functionality of the library to the Python users. The bindings are implemented using the Boost.Python C++ library and use NumPy arrays. This note includes listings with Python scripts exemplifying the use of selected library components. An example solution for using the Python bindings to access libcloudph++ from Fortran is presented.			arxiv	['Sylwester Arabas', 'Davide Del Vento']	26.0
276	Yaps: Python Frontend to Stan	Guillaume Baudart	2018-12-06 01:24:29	http://arxiv.org/abs/1812.04125v1	Stan is a popular probabilistic programming language with a self-contained syntax and semantics that is close to graphical models. Unfortunately, existing embeddings of Stan in Python use multi-line strings. That approach forces users to switch between two different language styles, with no support for syntax highlighting or simple error reporting within the Stan code. This paper tackles the question of whether Stan could use Python syntax while retaining its self-contained semantics. The answer is yes, that can be accomplished by reinterpreting the Python syntax. This paper introduces Yaps, a new frontend to Stan based on reinterpreted Python. We tested Yaps on over a thousand Stan models and made it available open-source.			arxiv	['Martin Hirzel', 'Kiran Kate', 'Louis Mandel', 'Avraham Shinnar']	27.0
277	Python for education: permutations	Andrzej Kapanowski	2013-07-26 14:18:21	http://arxiv.org/abs/1307.7042v1	Python implementation of permutations is presented. Three classes are introduced: Perm for permutations, Group for permutation groups, and PermError to report any errors for both classes. The class Perm is based on Python dictionaries and utilize cycle notation. The methods of calculation for the perm order, parity, ranking and unranking are given. A random permutation generation is also shown. The class Group is very simple and it is also based on dictionaries. It is mainly the presentation of the permutation groups interface with methods for the group order, subgroups (normalizer, centralizer, center, stabilizer), orbits, and several tests. The corresponding Python code is contained in the modules perms and groups.			arxiv	[]	28.0
278	Pytrec_eval: An Extremely Fast Python Interface to trec_eval	Christophe Van Gysel	2018-05-04 03:37:03	http://arxiv.org/abs/1805.01597v2	We introduce pytrec_eval, a Python interface to the tree_eval information retrieval evaluation toolkit. pytrec_eval exposes the reference implementations of trec_eval within Python as a native extension. We show that pytrec_eval is around one order of magnitude faster than invoking trec_eval as a sub process from within Python. Compared to a native Python implementation of NDCG, pytrec_eval is twice as fast for practically-sized rankings. Finally, we demonstrate its effectiveness in an application where pytrec_eval is combined with Pyndri and the OpenAI Gym where query expansion is learned using Q-learning.			arxiv	['Maarten de Rijke']	29.0
279	Nonparametric Estimation of the Random Coefficients Model in Python	Emil Mendoza	2021-08-08 07:27:49	http://arxiv.org/abs/2108.03582v2	We present $\textbf{PyRMLE}$, a Python module that implements Regularized Maximum Likelihood Estimation for the analysis of Random Coefficient models. $\textbf{PyRMLE}$ is simple to use and readily works with data formats that are typical to Random Coefficient problems. The module makes use of Python's scientific libraries $\textbf{NumPy}$ and $\textbf{SciPy}$ for computational efficiency. The main implementation of the algorithm is executed purely in Python code which takes advantage of Python's high-level features.			arxiv	['Fabian Dunker', 'Marco Reale']	30.0
280	Running HMC Simulation with Python via QUDA	Shuhei Yamamoto	2022-12-13 15:40:29	http://arxiv.org/abs/2212.06657v1	Lyncs-API is a Python API for Lattice QCD applications. It is designed as a Python toolkit that allows the user to use and run various lattice QCD libraries while programming in Python. The goal is to provide the user an easy programming experience without scarifying performance across multiple platforms, by preparing a common framework for various softwares for lattice QCD calculations. As such, it contains interfaces to, e.g., c-lime, DDalphaAMG, tmLQCD, and QUDA. In this proceeding, we focus on a Lyncs interface to QUDA, named Lyncs-QUDA, and present a small tutorial on how to use this Python interface to perform a HMC simulation using QUDA.			arxiv	['Simone Bacchio', 'Jacob Finenrath']	31.0
281	Python client for Isabelle server	Boris Shminke	2022-12-09 12:05:28	http://arxiv.org/abs/2212.11173v1	We contribute a Python client for the Isabelle server, which gives researchers and students using Python as their primary programming language an opportunity to communicate with the Isabelle server through TCP directly from a Python script. Such an approach helps avoid the complexities of integrating the existing Python script with languages used for Isabelle development (ML and Scala). We also describe new features that appeared since the announcement of the first version of the client a year ago. Finally, we give examples of the client's applications in research and education and discuss known limitations and possible directions for future development.			arxiv	[]	32.0
282	ePython: An implementation of Python for the many-core Epiphany coprocessor	Nick Brown	2020-10-28 09:01:27	http://arxiv.org/abs/2010.14827v1	The Epiphany is a many-core, low power, low on-chip memory architecture and one can very cheaply gain access to a number of parallel cores which is beneficial for HPC education and prototyping. The very low power nature of these architectures also means that there is potential for their use in future HPC machines, however there is a high barrier to entry in programming them due to the associated complexities and immaturity of supporting tools. In this paper we present our work on ePython, a subset of Python for the Epiphany and similar many-core co-processors. Due to the limited on-chip memory per core we have developed a new Python interpreter and this, combined with additional support for parallelism, has meant that novices can take advantage of Python to very quickly write parallel codes on the Epiphany and explore concepts of HPC using a smaller scale parallel machine. The high level nature of Python opens up new possibilities on the Epiphany, we examine a computationally intensive Gauss-Seidel code from the programmability and performance perspective, discuss running Python hybrid on both the host CPU and Epiphany, and interoperability between a full Python interpreter on the CPU and ePython on the Epiphany. The result of this work is support for developing Python on the Epiphany, which can be applied to other similar architectures, that the community have already started to adopt and use to explore concepts of parallelism and HPC.			arxiv	[]	33.0
283	Characterizing Bugs in Python and R Data Analytics Programs	Shibbir Ahmed	2023-06-14 16:50:01	http://arxiv.org/abs/2306.08632v1	R and Python are among the most popular languages used in many critical data analytics tasks. However, we still do not fully understand the capabilities of these two languages w.r.t. bugs encountered in data analytics tasks. What type of bugs are common? What are the main root causes? What is the relation between bugs and root causes? How to mitigate these bugs? We present a comprehensive study of 5,068 Stack Overflow posts, 1,800 bug fix commits from GitHub repositories, and several GitHub issues of the most used libraries to understand bugs in R and Python. Our key findings include: while both R and Python have bugs due to inexperience with data analysis, Python see significantly larger data preprocessing bugs compared to R. Developers experience significantly more data flow bugs in R because intermediate results are often implicit. We also found changes and bugs in packages and libraries cause more bugs in R compared to Python while package or library misselection and conflicts cause more bugs in Python than R. While R has a slightly higher readability barrier for data analysts, the statistical power of R leads to a less number of bad performance bugs. In terms of data visualization, R packages have significantly more bugs than Python libraries. We also identified a strong correlation between comparable packages in R and Python despite their linguistic and methodological differences. Lastly, we contribute a large dataset of manually verified R and Python bugs.			arxiv	['Mohammad Wardat', 'Hamid Bagheri', 'Breno Dantas Cruz', 'Hridesh Rajan']	34.0
284	Simplifying Parallelization of Scientific Codes by a Function-Centric Approach in Python	Jon K. Nilsen	2010-02-03 12:31:14	http://arxiv.org/abs/1002.0705v1	The purpose of this paper is to show how existing scientific software can be parallelized using a separate thin layer of Python code where all parallel communication is implemented. We provide specific examples on such layers of code, and these examples may act as templates for parallelizing a wide set of serial scientific codes. The use of Python for parallelization is motivated by the fact that the language is well suited for reusing existing serial codes programmed in other languages. The extreme flexibility of Python with regard to handling functions makes it very easy to wrap up decomposed computational tasks of a serial scientific application as Python functions. Many parallelization-specific components can be implemented as generic Python functions, which may take as input those functions that perform concrete computational tasks. The overall programming effort needed by this parallelization approach is rather limited, and the resulting parallel Python scripts have a compact and clean structure. The usefulness of the parallelization approach is exemplified by three different classes of applications in natural and social sciences.			arxiv	['Xing Cai', 'Bjorn Hoyland', 'Hans Petter Langtangen']	35.0
285	DockerizeMe: Automatic Inference of Environment Dependencies for Python Code Snippets	Eric Horton	2019-05-27 11:23:29	http://arxiv.org/abs/1905.11127v1	Platforms like Stack Overflow and GitHub's gist system promote the sharing of ideas and programming techniques via the distribution of code snippets designed to illustrate particular tasks. Python, a popular and fast-growing programming language, sees heavy use on both sites, with nearly one million questions asked on Stack Overflow and 400 thousand public gists on GitHub. Unfortunately, around 75% of the Python example code shared through these sites cannot be directly executed. When run in a clean environment, over 50% of public Python gists fail due to an import error for a missing library. We present DockerizeMe, a technique for inferring the dependencies needed to execute a Python code snippet without import error. DockerizeMe starts with offline knowledge acquisition of the resources and dependencies for popular Python packages from the Python Package Index (PyPI). It then builds Docker specifications using a graph-based inference procedure. Our inference procedure resolves import errors in 892 out of nearly 3,000 gists from the Gistable dataset for which Gistable's baseline approach could not find and install all dependencies.			arxiv	['Chris Parnin']	36.0
286	OpenML-Python: an extensible Python API for OpenML	Matthias Feurer	2019-11-06 16:59:30	http://arxiv.org/abs/1911.02490v2	OpenML is an online platform for open science collaboration in machine learning, used to share datasets and results of machine learning experiments. In this paper we introduce OpenML-Python, a client API for Python, opening up the OpenML platform for a wide range of Python-based tools. It provides easy access to all datasets, tasks and experiments on OpenML from within Python. It also provides functionality to conduct machine learning experiments, upload the results to OpenML, and reproduce results which are stored on OpenML. Furthermore, it comes with a scikit-learn plugin and a plugin mechanism to easily integrate other machine learning libraries written in Python into the OpenML ecosystem. Source code and documentation is available at https://github.com/openml/openml-python/.			arxiv	['Jan N. van Rijn', 'Arlind Kadra', 'Pieter Gijsbers', 'Neeratyoy Mallik', 'Sahithya Ravi', 'Andreas Müller', 'Joaquin Vanschoren', 'Frank Hutter']	37.0
287	Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations and visualizations via ParaMonte::Python library	Amir Shahmoradi	2020-10-01 23:26:42	http://arxiv.org/abs/2010.00724v1	ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for sampling mathematical objective functions, in particular, the posterior distributions of parameters in Bayesian modeling and analysis in data science, Machine Learning, and scientific inference in general. In addition to providing access to fast high-performance serial/parallel Monte Carlo and MCMC sampling routines, the ParaMonte::Python library provides extensive post-processing and visualization tools that aim to automate and streamline the process of model calibration and uncertainty quantification in Bayesian data analysis. Furthermore, the automatically-enabled restart functionality of ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future restart of Monte Carlo simulations, should any interruptions happen. The ParaMonte::Python library is MIT-licensed and is permanently maintained on GitHub at https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.			arxiv	['Fatemeh Bagheri', 'Joshua Alexander Osborne']	38.0
288	Productivity, Portability, Performance: Data-Centric Python	Alexandros Nikolaos Ziogas	2021-07-01 15:51:18	http://arxiv.org/abs/2107.00555v2	Python has become the de facto language for scientific computing. Programming in Python is highly productive, mainly due to its rich science-oriented software ecosystem built around the NumPy module. As a result, the demand for Python support in High Performance Computing (HPC) has skyrocketed. However, the Python language itself does not necessarily offer high performance. In this work, we present a workflow that retains Python's high productivity while achieving portable performance across different architectures. The workflow's key features are HPC-oriented language extensions and a set of automatic optimizations powered by a data-centric intermediate representation. We show performance results and scaling across CPU, GPU, FPGA, and the Piz Daint supercomputer (up to 23,328 cores), with 2.47x and 3.75x speedups over previous-best solutions, first-ever Xilinx and Intel FPGA results of annotated Python, and up to 93.16% scaling efficiency on 512 nodes.			arxiv	['Timo Schneider', 'Tal Ben-Nun', 'Alexandru Calotoiu', 'Tiziano De Matteis', 'Johannes de Fine Licht', 'Luca Lavarini', 'Torsten Hoefler']	39.0
289	PyTracer: Automatically profiling numerical instabilities in Python	Yohan Chatelain	2021-12-21 20:22:34	http://arxiv.org/abs/2112.11508v2	Numerical stability is a crucial requirement of reliable scientific computing. However, despite the pervasiveness of Python in data science, analyzing large Python programs remains challenging due to the lack of scalable numerical analysis tools available for this language. To fill this gap, we developed PyTracer, a profiler to quantify numerical instability in Python applications. PyTracer transparently instruments Python code to produce numerical traces and visualize them interactively in a Plotly dashboard. We designed PyTracer to be agnostic to numerical noise model, allowing for tool evaluation through Monte-Carlo Arithmetic, random rounding, random data perturbation, or structured noise for a particular application. We illustrate PyTracer's capabilities by testing the numerical stability of key functions in both SciPy and Scikit-learn, two dominant Python libraries for mathematical modeling. Through these evaluations, we demonstrate PyTracer as a scalable, automatic, and generic framework for numerical profiling in Python.			arxiv	['Nigel Yong', 'Gregory Kiar', 'Tristan Glatard']	40.0
290	GAP-Gen: Guided Automatic Python Code Generation	Junchen Zhao	2022-01-19 06:32:47	http://arxiv.org/abs/2201.08810v2	Automatic code generation from natural language descriptions can be highly beneficial during the process of software development. In this work, we propose GAP-Gen, a Guided Automatic Python Code Generation method based on Python syntactic constraints and semantic constraints. We first introduce Python syntactic constraints in the form of Syntax-Flow, which is a simplified version of Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract Syntax Tree but maintaining crucial syntactic information of Python code. In addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable and function names consistently through out the code. In our work, rather than pretraining, we focus on modifying the finetuning process which reduces computational requirements but retains high generation performance on automatic Python code generation task. GAP-Gen fine-tunes the transformer based language models T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet, CodeSearchNet AdvTest and Code-Docstring Corpus from EdinburghNLP. Our experiments show that GAP-Gen achieves better results on automatic Python code generation task than previous works.			arxiv	['Yurun Song', 'Junlin Wang', 'Ian G. Harris']	41.0
291	Approaches to the Parallelization of Merge Sort in Python	Alexandra Yang	2022-11-26 18:26:30	http://arxiv.org/abs/2211.16479v1	The theory of divide-and-conquer parallelization has been well-studied in the past, providing a solid basis upon which to explore different approaches to the parallelization of merge sort in Python. Python's simplicity and extensive selection of libraries make it the most popular scientific programming language, so it is a fitting language in which to implement and analyze these algorithms. In this paper, we use Python packages multiprocessing and mpi4py to implement several different parallel merge sort algorithms. Experiments are conducted on an academic supercomputer, upon which benchmarks are performed using Cloudmesh. We find that hybrid multiprocessing merge sort outperforms several other algorithms, achieving a 1.5x speedup compared to the built-in Python sorted() and a 34x speedup compared to sequential merge sort. Our results provide insight into different approaches to implementing parallel merge sort in Python and contribute to the understanding of general divide-and-conquer parallelization in Python on both shared and distributed memory systems.			arxiv	[]	42.0
292	Faster or Slower? Performance Mystery of Python Idioms Unveiled with Empirical Evidence	Zejun Zhang	2023-01-30 03:28:24	http://arxiv.org/abs/2301.12633v1	The usage of Python idioms is popular among Python developers in a formative study of 101 performance-related questions of Python idioms on Stack Overflow, we find that developers often get confused about the performance impact of Python idioms and use anecdotal toy code or rely on personal project experience which is often contradictory in performance outcomes. There has been no large-scale, systematic empirical evidence to reconcile these performance debates. In the paper, we create a large synthetic dataset with 24,126 pairs of non-idiomatic and functionally-equivalent idiomatic code for the nine unique Python idioms identified in Zhang et al., and reuse a large real-project dataset of 54,879 such code pairs provided by Zhang et al. We develop a reliable performance measurement method to compare the speedup or slowdown by idiomatic code against non-idiomatic counterpart, and analyze the performance discrepancies between the synthetic and real-project code, the relationships between code features and performance changes, and the root causes of performance changes at the bytecode level. We summarize our findings as some actionable suggestions for using Python idioms.			arxiv	['Zhenchang Xing', 'Xin Xia', 'Xiwei Xu', 'Liming Zhu', 'Qinghua Lu']	43.0
293	Rapid Development of Interferometric Software Using MIRIAD and Python	Peter K. G. Williams	2012-03-01 22:07:31	http://arxiv.org/abs/1203.0330v1	"New and upgraded radio interferometers produce data at massive rates and will require significant improvements in analysis techniques to reach their promised levels of performance in a routine manner. Until these techniques are fully developed, productivity and accessibility in scientific programming environments will be key bottlenecks in the pipeline leading from data-taking to research results. We present an open-source software package, miriad-python, that allows access to the MIRIAD interferometric reduction system in the Python programming language. The modular design of MIRIAD and the high productivity and accessibility of Python provide an excellent foundation for rapid development of interferometric software. Several other projects with similar goals exist and we describe them and compare miriad-python to them in detail. Along with an overview of the package design, we present sample code and applications, including the detection of millisecond astrophysical transients, determination and application of nonstandard calibration parameters, interactive data visualization, and a reduction pipeline using a directed acyclic graph dependency model analogous to that of the traditional Unix tool ""make"". The key aspects of the miriad-python software project are documented. We find that miriad-python provides an extremely effective environment for prototyping new interferometric software, though certain existing packages provide far more infrastructure for some applications. While equivalent software written in compiled languages can be much faster than Python, there are many situations in which execution time is profitably exchanged for speed of development, code readability, accessibility to nonexpert programmers, quick interlinking with foreign software packages, and other virtues of the Python language."			arxiv	['Casey J. Law', 'Geoffrey C. Bower']	44.0
294	Toward Efficient Interactions between Python and Native Libraries	Jialiang Tan	2021-06-11 00:48:02	http://arxiv.org/abs/2107.00064v1	Python has become a popular programming language because of its excellent programmability. Many modern software packages utilize Python for high-level algorithm design and depend on native libraries written in C/C++/Fortran for efficient computation kernels. Interaction between Python code and native libraries introduces performance losses because of the abstraction lying on the boundary of Python and native libraries. On the one side, Python code, typically run with interpretation, is disjoint from its execution behavior. On the other side, native libraries do not include program semantics to understand algorithm defects. To understand the interaction inefficiencies, we extensively study a large collection of Python software packages and categorize them according to the root causes of inefficiencies. We extract two inefficiency patterns that are common in interaction inefficiencies. Based on these patterns, we develop PieProf, a lightweight profiler, to pinpoint interaction inefficiencies in Python applications. The principle of PieProf is to measure the inefficiencies in the native execution and associate inefficiencies with high-level Python code to provide a holistic view. Guided by PieProf, we optimize 17 real-world applications, yielding speedups up to 6.3$\times$ on application level.			arxiv	['Yu Chen', 'Zhenming Liu', 'Bin Ren', 'Shuaiwen Leon Song', 'Xipeng Shen', 'Xu Liu']	45.0
295	Improving Tese Case Generation for Python Native Libraries Through Constraints on Input Data Structures	Xin Zhang	2022-06-28 08:47:33	http://arxiv.org/abs/2206.13828v1	Modern Python projects execute computational functions using native libraries and give Python interfaces to boost execution speed; hence, testing these libraries becomes critical to the project's robustness. One challenge is that existing approaches use coverage to guide generation, but native libraries run as black boxes to Python code with no execution information. Another is that dynamic binary instrumentation reduces testing performance as it needs to monitor both native libraries and the Python virtual machine. To address these challenges, in this paper, we propose an automated test case generation approach that works at the Python code layer. Our insight is that many path conditions in native libraries are for processing input data structures through interacting with the VM. In our approach, we instrument the Python Interpreter to monitor the interactions between native libraries and VM, derive constraints on the structures, and then use the constraints to guide test case generation. We implement our approach in a tool named PyCing and apply it to six widely-used Python projects. The experimental results reveal that with the structure constraint guidance, PyCing can cover more execution paths than existing test cases and state-of-the-art tools. Also, with the checkers in the testing framework Pytest, PyCing can identify segmentation faults in 10 Python interfaces and memory leaks in 9. Our instrumentation strategy also has an acceptable influence on testing efficiency.			arxiv	['Xutong Ma', 'Jiwen Yan', 'Baoquan Cui', 'Jun Yan', 'Jian Zhang']	46.0
296	binary_c-python: A Python-based stellar population synthesis tool and interface to binary_c	D. D. Hendriks	2023-06-05 11:04:17	http://arxiv.org/abs/2306.02779v1	We present the software package binary_c-python which provides a convenient and easy-to-use interface to the binary_c framework, allowing the user to rapidly evolve individual systems and populations of stars. binary_c-python is available on Pip and on GitLab. binary_c-python contains many useful features to control and process the output of binary_c, like by providing binary_c-python with logging statements that are dynamically compiled and loaded into binary_c. Moreover, we have recently added standardised output of events like Roche-lobe overflow or double compact-object formation to binary_c, and automatic parsing and managing of that output in binary_c-python. binary_c-python uses multiprocessing to utilise all the cores on a particular machine, and can run populations with HPC cluster workload managers like HTCondor and Slurm, allowing the user to run simulations on large computing clusters. We provide documentation that is automatically generated based on docstrings and a suite of Jupyter notebooks. These notebooks consist of technical tutorials on how to use binary_c-python and use-case scenarios aimed at doing science. Much of binary_c-python is covered by unit tests to ensure reliability and correctness, and the test coverage is continually increased as the package is improved.			arxiv	['R. G. Izzard']	47.0
297	PyMsOfa: A Python Package for the Standards of Fundamental Astronomy (SOFA) Service	Jianghui Ji	2023-10-12 19:11:41	http://arxiv.org/abs/2310.08673v2	The Standards of Fundamental Astronomy (SOFA) is a service provided by the International Astronomical Union (IAU) that offers algorithms and software for astronomical calculations, which was released in two versions by FORTRAN 77 and ANSI C, respectively. In this work, we implement the python package PyMsOfa for SOFA service by three ways: (1) a python wrapper package based on a foreign function library for Python (ctypes), (2) a python wrapper package with the foreign function interface for Python calling C code (cffi), and (3) a python package directly written in pure python codes from SOFA subroutines. The package PyMsOfa has fully implemented 247 functions of the original SOFA routines. In addition, PyMsOfa is also extensively examined, which is exactly consistent with those test examples given by the original SOFA. This python package can be suitable to not only the astrometric detection of habitable planets of the Closeby Habitable Exoplanet Survey (CHES) mission (Ji et al. 2022), but also for the frontiers themes of black holes and dark matter related to astrometric calculations and other fields. The source codes are available via https://github.com/CHES2023/PyMsOfa.			arxiv	['Dongjie Tan', 'Chunhui Bao', 'Xiumin Huang', 'Shoucun Hu', 'Yao Dong', 'Su Wang']	48.0
298	Python for Education: Computational Methods for Nonlinear Systems	Christopher R. Myers	2007-04-24 18:55:17	http://arxiv.org/abs/0704.3182v1	We describe a novel, interdisciplinary, computational methods course that uses Python and associated numerical and visualization libraries to enable students to implement simulations for a number of different course modules. Problems in complex networks, biomechanics, pattern formation, and gene regulation are highlighted to illustrate the breadth and flexibility of Python-powered computational environments.			arxiv	['James. P. Sethna']	49.0
299	A Framework for Distributed Deep Learning Layer Design in Python	Clay McLeod	2015-10-25 21:04:12	http://arxiv.org/abs/1510.07303v1	In this paper, a framework for testing Deep Neural Network (DNN) design in Python is presented. First, big data, machine learning (ML), and Artificial Neural Networks (ANNs) are discussed to familiarize the reader with the importance of such a system. Next, the benefits and detriments of implementing such a system in Python are presented. Lastly, the specifics of the system are explained, and some experimental results are presented to prove the effectiveness of the system.			arxiv	[]	50.0
300	Want Drugs? Use Python	Michał Nowotka	2016-07-01 19:02:36	http://arxiv.org/abs/1607.00378v1	We describe how Python can be leveraged to streamline the curation, modelling and dissemination of drug discovery data as well as the development of innovative, freely available tools for the related scientific community. We look at various examples, such as chemistry toolkits, machine-learning applications and web frameworks and show how Python can glue it all together to create efficient data science pipelines.			arxiv	['George Papadatos', 'Mark Davies', 'Nathan Dedman', 'Anne Hersey']	51.0
301	Geoplotlib: a Python Toolbox for Visualizing Geographical Data	Andrea Cuttone	2016-08-05 16:39:27	http://arxiv.org/abs/1608.01933v1	We introduce geoplotlib, an open-source python toolbox for visualizing geographical data. geoplotlib supports the development of hardware-accelerated interactive visualizations in pure python, and provides implementations of dot maps, kernel density estimation, spatial graphs, Voronoi tesselation, shapefiles and many more common spatial visualizations. We describe geoplotlib design, functionalities and use cases.			arxiv	['Sune Lehmann', 'Jakob Eg Larsen']	52.0
302	Powerbox: A Python package for creating structured fields with isotropic power spectra	Steven G. Murray	2018-08-27 00:21:57	http://arxiv.org/abs/1809.05030v1	Powerbox is a pure-Python package for creating and measuring structured fields with homogeneous and isotropic power spectra.			arxiv	[]	53.0
303	Implementation of Kalman Filter with Python Language	Mohamed Laaraiedh	2012-04-02 11:40:41	http://arxiv.org/abs/1204.0375v1	In this paper, we investigate the implementation of a Python code for a Kalman Filter using the Numpy package. A Kalman Filtering is carried out in two steps: Prediction and Update. Each step is investigated and coded as a function with matrix input and output. These different functions are explained and an example of a Kalman Filter application for the localization of mobile in wireless networks is given.			arxiv	[]	54.0
304	TimeGym: Debugging for Time Series Modeling in Python	Diogo Seca	2021-05-04 10:36:29	http://arxiv.org/abs/2105.01404v1	We introduce the TimeGym Forecasting Debugging Toolkit, a Python library for testing and debugging time series forecasting pipelines. TimeGym simplifies the testing forecasting pipeline by providing generic tests for forecasting pipelines fresh out of the box. These tests are based on common modeling challenges of time series. Our library enables forecasters to apply a Test-Driven Development approach to forecast modeling, using specified oracles to generate artificial data with noise.			arxiv	[]	55.0
305	MontePython: Implementing Quantum Monte Carlo using Python	J. K. Nilsen	2006-09-22 12:42:42	http://arxiv.org/abs/physics/0609191v1	We present a cross-language C++/Python program for simulations of quantum mechanical systems with the use of Quantum Monte Carlo (QMC) methods. We describe a system for which to apply QMC, the algorithms of variational Monte Carlo and diffusion Monte Carlo and we describe how to implement theses methods in pure C++ and C++/Python. Furthermore we check the efficiency of the implementations in serial and parallel cases to show that the overhead using Python can be negligible.			arxiv	[]	56.0
306	HOOMD-blue: A Python package for high-performance molecular dynamics and hard particle Monte Carlo simulations	Joshua A. Anderson	2013-08-26 13:56:04	http://arxiv.org/abs/1308.5587v2	HOOMD-blue is a particle simulation engine designed for nano- and colloidal-scale molecular dynamics and hard particle Monte Carlo simulations. It has been actively developed since March 2007 and available open source since August 2008. HOOMD-blue is a Python package with a high performance C++/CUDA backend that we built from the ground up for GPU acceleration. The Python interface allows users to combine HOOMD-blue with with other packages in the Python ecosystem to create simulation and analysis workflows. We employ software engineering practices to develop, test, maintain, and expand the code.			arxiv	['Jens Glaser', 'Sharon C. Glotzer']	57.0
307	Plyades: A Python Library for Space Mission Design	Helge Eichhorn	2016-07-01 18:53:15	http://arxiv.org/abs/1607.00849v1	Plyades: A Python Library for Space Mission Design Designing a space mission is a computation-heavy task. Software tools that conduct the necessary numerical simulations and optimizations are therefore indispensable. The usability of existing software, written in Fortran and MATLAB, suffers because of high complexity, low levels of abstraction and out-dated programming practices. We propose Python as a viable alternative for astrodynamics tools and demonstrate the proof-of-concept library Plyades which combines powerful features with Pythonic ease of use.			arxiv	['Reiner Anderl']	58.0
308	A Practical Python API for Querying AFLOWLIB	Conred W. Rosenbrock	2017-09-28 20:38:47	http://arxiv.org/abs/1710.00813v1	"Large databases such as aflowlib.org provide valuable data sources for discovering material trends through machine learning. Although a REST API and query language are available, there is a learning curve associated with the AFLUX language that acts as a barrier for new users. Additionally, the data is stored using non-standard serialization formats. Here we present a high-level API that allows immediate access to the aflowlib data using standard python operators and language features. It provides an easy way to integrate aflowlib data with other python materials packages such as ase and quippy, and provides automatic deserialization into numpy arrays and python objects. This package is available via ""pip install aflow""."			arxiv	[]	59.0
309	salmon: A Symbolic Linear Regression Package for Python	Alex Boyd	2019-11-02 04:42:28	http://arxiv.org/abs/1911.00648v3	One of the most attractive features of R is its linear modeling capabilities. We describe a Python package, salmon, that brings the best of R's linear modeling functionality to Python in a Pythonic way -- by providing composable objects for specifying and fitting linear models. This object-oriented design also enables other features that enhance ease-of-use, such as automatic visualizations and intelligent model building.			arxiv	['Dennis L. Sun']	60.0
310	pySiDR: Python Event Reconstruction for SiD	C. T. Potter	2020-02-13 22:43:25	http://arxiv.org/abs/2002.05804v1	Event reconstruction in the ILC community has typically relied on algorithms implemented in C++, a fast compiled language. However, the Python package pyLCIO provides a full interface to tracker and calorimeter hits stored in LCIO files, opening up the possibility to implement reconstruction algorithms in a language uniquely well suited to working with large lists of hits built with list comprehensions. Python, an interpreted language which can perform complex tasks with minimal code, also allows seamless integration with powerful machine learning tools developed recently. We discuss pySiDR, a Python package for SiD event reconstruction.			arxiv	[]	61.0
311	FitsGeo -- Python package for PHITS geometry development and visualization	Ivan Gordeev	2020-08-08 09:54:21	http://arxiv.org/abs/2008.03298v1	An easy way to define and visualize geometry for PHITS input files introduced. Suggested FitsGeo Python package helps to define surfaces as Python objects and manipulate them conveniently. VPython assists to view defined geometry interactively which boosts geometry development and helps with complicated cases. Every class that sets the surface object has methods with some extra properties. As well as geometry generation for PHITS input, additional modules developed for material and cell definition. Any user with a very basic knowledge of Python can define the geometry in a convenient way and use it in further research related to particle transport.			arxiv	[]	62.0
312	HDPython: A High Level Python Based Object-Oriented HDL Framework	R. Peschke	2020-11-05 02:43:50	http://arxiv.org/abs/2011.02626v2	We present a High-Level Python-based Hardware Description Language (HDPython), It uses Python as its source language and converts it to standard VHDL. Compared to other approaches of building converters from a high-level programming language into a hardware description language, this new approach aims to maintain an object-oriented paradigm throughout the entire process. Instead of removing all the high-level features from Python to make it into an HDL, this approach goes the opposite way. It tries to show how certain features from a high-level language can be implemented in an HDL, providing the corresponding benefits of high-level programming for the user.			arxiv	['K. Nishimura', 'G. Varner']	63.0
313	cellanneal: A User-Friendly Deconvolution Software for Omics Data	Lisa Buchauer	2021-10-15 17:14:58	http://arxiv.org/abs/2110.08209v1	We introduce cellanneal, a python-based software for deconvolving bulk RNA sequencing data. cellanneal relies on the optimization of Spearman's rank correlation coefficient between experimental and computational mixture gene expression vectors using simulated annealing. cellanneal can be used as a python package or via a command line interface, but importantly also provides a simple graphical user interface which is distributed as a single executable file for user convenience. The python package is available at https://github.com/LiBuchauer/cellanneal , the graphical software can be downloaded at http://shalevlab.weizmann.ac.il/resources .			arxiv	['Shalev Itzkovitz']	64.0
314	Asgl: A Python Package for Penalized Linear and Quantile Regression	Álvaro Méndez Civieta	2021-10-31 11:43:10	http://arxiv.org/abs/2111.00472v1	Asg is a Python package that solves penalized linear regression and quantile regression models for simultaneous variable selection and prediction, for both high and low dimensional frameworks. It makes very easy to set up and solve different types of lasso-based penalizations among which the asgl (adaptive sparse group lasso, that gives name to the package) is remarked. This package is built on top of cvxpy, a Python-embedded modeling language for convex optimization problems and makes extensive use of multiprocessing, a Python module for parallel computing that significantly reduces computation times of asgl.			arxiv	['M. Carmen Aguilera-Morillo', 'Rosa E. Lillo']	65.0
315	Scalpel: The Python Static Analysis Framework	Li Li	2022-02-24 00:27:56	http://arxiv.org/abs/2202.11840v1	Despite being the most popular programming language, Python has not yet received enough attention from the community. To the best of our knowledge, there is no general static analysis framework proposed to facilitate the implementation of dedicated Python static analyzers. To fill this gap, we design and implement such a framework (named Scalpel) and make it publicly available as an open-source project. The Scalpel framework has already integrated a number of fundamental static analysis functions (e.g., call graph constructions, control-flow graph constructions, alias analysis, etc.) that are ready to be reused by developers to implement client applications focusing on statically resolving dedicated Python problems such as detecting bugs or fixing vulnerabilities.			arxiv	['Jiawei Wang', 'Haowei Quan']	66.0
316	Modernizing the ESRF beamline application software architecture with generic Python modules	Jorg Klora	2002-10-16 13:27:22	http://arxiv.org/abs/cond-mat/0210344v1	We report on the modernization of the ESRF beamline application software with Python modules. The current building blocks used around the SPEC data acquisition software together with the new elements are presented.			arxiv	[]	67.0
317	Multi-Agent Programming Contest 2011 - The Python-DTU Team	Jørgen Villadsen	2011-10-01 15:03:52	http://arxiv.org/abs/1110.0105v1	We provide a brief description of the Python-DTU system, including the overall design, the tools and the algorithms that we plan to use in the agent contest.			arxiv	['Mikko Berggren Ettienne', 'Steen Vester']	68.0
318	Proceedings of the 6th European Conference on Python in Science (EuroSciPy 2013)	Pierre de Buyl	2014-05-01 14:22:09	http://arxiv.org/abs/1405.0166v1	These are the proceedings of the 6th European Conference on Python in Science, EuroSciPy 2013, that was held in Brussels (21-25 August 2013).			arxiv	['Nelle Varoquaux']	69.0
319	Py-oopsi: the python implementation of the fast-oopsi algorithm	Benyuan Liu	2014-05-06 06:05:04	http://arxiv.org/abs/1405.6181v1	Fast-oopsi was developed by Joshua Vogelstein in 2009, which is now widely used to extract neuron spike activities from calcium fluorescence signals. Here, we propose detailed implementation of the fast-oopsi algorithm in python programming language. Some corrections are also made to the original fast-oopsi paper.			arxiv	[]	70.0
320	Proceedings of the 7th European Conference on Python in Science (EuroSciPy 2014)	Pierre de Buyl	2014-12-22 15:47:51	http://arxiv.org/abs/1412.7030v1	These are the proceedings of the 7th European Conference on Python in Science, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).			arxiv	['Nelle Varoquaux']	71.0
321	PythonFOAM: In-situ data analyses with OpenFOAM and Python	Romit Maulik	2021-03-17 01:34:41	http://arxiv.org/abs/2103.09389v2	We outline the development of a general-purpose Python-based data analysis tool for OpenFOAM. Our implementation relies on the construction of OpenFOAM applications that have bindings to data analysis libraries in Python. Double precision data in OpenFOAM is cast to a NumPy array using the NumPy C-API and Python modules may then be used for arbitrary data analysis and manipulation on flow-field information. We highlight how the proposed wrapper may be used for an in-situ online singular value decomposition (SVD) implemented in Python and accessed from the OpenFOAM solver PimpleFOAM. Here, `in-situ' refers to a programming paradigm that allows for a concurrent computation of the data analysis on the same computational resources utilized for the partial differential equation solver. In addition, to demonstrate data-parallel analyses, we deploy a distributed SVD, which collects snapshot data across the ranks of a distributed simulation to compute the global left singular vectors. Crucially, both OpenFOAM and Python share the same message passing interface (MPI) communicator for this deployment which allows Python objects and functions to exchange NumPy arrays across ranks. Subsequently, we provide scaling assessments of this distributed SVD on multiple nodes of Intel Broadwell and KNL architectures for canonical test cases such as the large eddy simulations of a backward facing step and a channel flow at friction Reynolds number of 395. Finally, we demonstrate the deployment of a deep neural network for compressing the flow-field information using an autoencoder to demonstrate an ability to use state-of-the-art machine learning tools in the Python ecosystem.			arxiv	['Dimitrios Fytanidis', 'Bethany Lusch', 'Venkatram Vishwanath', 'Saumil Patel']	72.0
322	Python Crypto Misuses in the Wild	Anna-Katharina Wickert	2021-09-02 17:32:41	http://arxiv.org/abs/2109.01109v1	Background: Previous studies have shown that up to 99.59 % of the Java apps using crypto APIs misuse the API at least once. However, these studies have been conducted on Java and C, while empirical studies for other languages are missing. For example, a controlled user study with crypto tasks in Python has shown that 68.5 % of the professional developers write a secure solution for a crypto task. Aims: To understand if this observation holds for real-world code, we conducted a study of crypto misuses in Python. Method: We developed a static analysis tool that covers common misuses of 5 different Python crypto APIs. With this analysis, we analyzed 895 popular Python projects from GitHub and 51 MicroPython projects for embedded devices. Further, we compared our results with the findings of previous studies. Results: Our analysis reveals that 52.26 % of the Python projects have at least one misuse. Further, some Python crypto libraries API design helps developers from misusing crypto functions, which were much more common in studies conducted with Java and C code. Conclusion: We conclude that we can see a positive impact of the good API design on crypto misuses for Python applications. Further, our analysis of MicroPython projects reveals the importance of hybrid analyses.			arxiv	['Lars Baumgärtner', 'Florian Breitfelder', 'Mira Mezini']	73.0
323	An array-oriented Python interface for FastJet	Aryan Roy	2022-02-08 14:57:31	http://arxiv.org/abs/2202.03911v1	Analysis on HEP data is an iterative process in which the results of one step often inform the next. In an exploratory analysis, it is common to perform one computation on a collection of events, then view the results (often with histograms) to decide what to try next. Awkward Array is a Scikit-HEP Python package that enables data analysis with array-at-a-time operations to implement cuts as slices, combinatorics as composable functions, etc. However, most C++ HEP libraries, such as FastJet, have an imperative, one-particle-at-a-time interface, which would be inefficient in Python and goes against the grain of the array-at-a-time logic of scientific Python. Therefore, we developed fastjet, a pip-installable Python package that provides FastJet C++ binaries, the classic (particle-at-a-time) Python interface, and the new array-oriented interface for use with Awkward Array. The new interface streamlines interoperability with scientific Python software beyond HEP, such as machine learning. In one case, adopting this library along with other array-oriented tools accelerated HEP analysis code by a factor of 20. It was designed to be easily integrated with libraries in the Scikit-HEP ecosystem, including Uproot (file I/O), hist (histogramming), Vector (Lorentz vectors), and Coffea (high-level glue). We discuss the design of the fastjet Python library, integrating the classic interface with the array oriented interface and with the Vector library for Lorentz vector operations. The new interface was developed as open source.			arxiv	['Jim Pivarski', 'Chad Wells Freer']	74.0
324	Deep Learning: From Basics to Building Deep Neural Networks with Python	Milad Vazan	2022-04-22 11:57:19	http://arxiv.org/abs/2205.01069v1	This book is intended for beginners who have no familiarity with deep learning. Our only expectation from readers is that they already have the basic programming skills in Python.			arxiv	[]	75.0
325	The Awkward World of Python and C++	Manasvi Goyal	2023-03-03 20:33:50	http://arxiv.org/abs/2303.02205v1	There are undeniable benefits of binding Python and C++ to take advantage of the best features of both languages. This is especially relevant to the HEP and other scientific communities that have invested heavily in the C++ frameworks and are rapidly moving their data analyses to Python. Version 2 of Awkward Array, a Scikit-HEP Python library, introduces a set of header-only C++ libraries that do not depend on any application binary interface. Users can directly include these libraries in their compilation rather than linking against platform-specific libraries. This new development makes the integration of Awkward Arrays into other projects easier and more portable as the implementation is easily separable from the rest of the Awkward Array codebase. The code is minimal, it does not include all of the code needed to use Awkward Arrays in Python, nor does it include references to Python or pybind11. The C++ users can use it to make arrays and then copy them to Python without any specialized data types - only raw buffers, strings, and integers. This C++ code also simplifies the process of just-in-time (JIT) compilation in ROOT. This implementation approach solves some of the drawbacks, like packaging projects where native dependencies can be challenging. In this paper, we demonstrate the technique to integrate C++ and Python by using a header-only approach. We also describe the implementation of a new LayoutBuilder and a GrowableBuffer. Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposing Awkward Arrays to C++ without copying them are discussed.			arxiv	['Ianna Osborne', 'Jim Pivarski']	76.0
326	SlipCover: Near Zero-Overhead Code Coverage for Python	Juan Altmayer Pizzorno	2023-05-04 14:49:44	http://arxiv.org/abs/2305.02886v4	Coverage analysis is widely used but can suffer from high overhead. This overhead is especially acute in the context of Python, which is already notoriously slow (a recent study observes a roughly 30x slowdown vs. native code). We find that the state-of-the-art coverage tool for Python, coverage$.$py, introduces a median overhead of 180% with the standard Python interpreter. Slowdowns are even more extreme when using PyPy, a JIT-compiled Python implementation, with coverage$.$py imposing a median overhead of 1,300%. This performance degradation reduces the utility of coverage analysis in most use cases, including testing and fuzzing, and precludes its use in deployment. This paper presents SlipCover, a novel, near-zero overhead coverage analyzer for Python. SlipCover works without modifications to either the Python interpreter or PyPy. It first processes a program's AST to accurately identify all branches and lines. SlipCover then dynamically rewrites Python bytecodes to add lightweight instrumentation to each identified branch and line. At run time, SlipCover periodically de-instruments already-covered lines and branches. The result is extremely low overheads -- a median of just 5% -- making SlipCover suitable for use in deployment. We show its efficiency can translate to significant increases in the speed of coverage-based clients. As a proof of concept, we integrate SlipCover into TPBT, a targeted property-based testing system, and observe a 22x speedup.			arxiv	['Emery D Berger']	77.0
327	Cosmic Microwave Background Anisotropy Measurement From Python V	K. Coble	2001-12-21 01:09:38	http://arxiv.org/abs/astro-ph/0112506v2	We analyze observations of the microwave sky made with the Python experiment in its fifth year of operation at the Amundsen-Scott South Pole Station in Antarctica. After modeling the noise and constructing a map, we extract the cosmic signal from the data. We simultaneously estimate the angular power spectrum in eight bands ranging from large (l ~ 40) to small (l ~ 260) angular scales, with power detected in the first six bands. There is a significant rise in the power spectrum from large to smaller (l ~ 200) scales, consistent with that expected from acoustic oscillations in the early Universe. We compare this Python V map to a map made from data taken in the third year of Python. Python III observations were made at a frequency of 90 GHz and covered a subset of the region of the sky covered by Python V observations, which were made at 40 GHz. Good agreement is obtained both visually (with a filtered version of the map) and via a likelihood ratio test.			arxiv	['S. Dodelson', 'M. Dragovan', 'K. Ganga', 'L. Knox', 'J. Kovac', 'B. Ratra', 'T. Souradeep']	78.0
328	Solve the Master Equation by Python-An Introduction to the Python Computing Environment	Wei Fan	2011-03-02 00:46:20	http://arxiv.org/abs/1103.0325v4	A brief introduction to the Python computing environment is given. By solving the master equation encountered in quantum transport, we give an example of how to solve the ODE problems in Python. The ODE solvers used are the ZVODE routine in Scipy and the bsimp solver in GSL. For the former, the equation can be in its complex-valued form, while for the latter, it has to be rewritten to a real-valued form. The focus is on the detailed workflow of the implementation process, rather than on the syntax of the python language, with the hope to help readers simulate their own models in Python.			arxiv	['Yan Xu', 'Bing Chen', 'Qianqian Ye']	79.0
329	Scalene: Scripting-Language Aware Profiling for Python	Emery D. Berger	2020-06-06 14:43:09	http://arxiv.org/abs/2006.03879v2	"Existing profilers for scripting languages (a.k.a. ""glue"" languages) like Python suffer from numerous problems that drastically limit their usefulness. They impose order-of-magnitude overheads, report information at too coarse a granularity, or fail in the face of threads. Worse, past profilers---essentially variants of their counterparts for C---are oblivious to the fact that optimizing code in scripting languages requires information about code spanning the divide between the scripting language and libraries written in compiled languages. This paper introduces scripting-language aware profiling, and presents Scalene, an implementation of scripting-language aware profiling for Python. Scalene employs a combination of sampling, inference, and disassembly of byte-codes to efficiently and precisely attribute execution time and memory usage to either Python, which developers can optimize, or library code, which they cannot. It includes a novel sampling memory allocator that reports line-level memory consumption and trends with low overhead, helping developers reduce footprints and identify leaks. Finally, it introduces a new metric, copy volume, to help developers root out insidious copying costs across the Python/library boundary, which can drastically degrade performance. Scalene works for single or multi-threaded Python code, is precise, reporting detailed information at the line granularity, while imposing modest overheads (26%--53%)."			arxiv	[]	80.0
330	FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC libraries	Ashwin Vishnu Mohanan	2018-07-03 09:52:57	http://arxiv.org/abs/1807.01775v1	"The Python package fluidfft provides a common Python API for performing Fast Fourier Transforms (FFT) in sequential, in parallel and on GPU with different FFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFT framework which allows Python users to easily and efficiently perform FFT and the associated tasks, such as as computing linear operators and energy spectra. We describe the architecture of the package composed of C++ and Cython FFT classes, Python ""operator"" classes and Pythran functions. The package supplies utilities to easily test itself and benchmark the different FFT solutions for a particular case and on a particular machine. We present a performance scaling analysis on three different computing clusters and a microbenchmark showing that fluidfft is an interesting solution to write efficient Python applications using FFT."			arxiv	['Cyrille Bonamy', 'Pierre Augier']	81.0
331	Speeding simulation analysis up with yt and Intel Distribution for Python	Salvatore Cielo	2019-10-17 12:28:46	http://arxiv.org/abs/1910.07855v1	As modern scientific simulations grow ever more in size and complexity, even their analysis and post-processing becomes increasingly demanding, calling for the use of HPC resources and methods. yt is a parallel, open source post-processing python package for numerical simulations in astrophysics, made popular by its cross-format compatibility, its active community of developers and its integration with several other professional Python instruments. The Intel Distribution for Python enhances yt's performance and parallel scalability, through the optimization of lower-level libraries Numpy and Scipy, which make use of the optimized Intel Math Kernel Library (Intel-MKL) and the Intel MPI library for distributed computing. The library package yt is used for several analysis tasks, including integration of derived quantities, volumetric rendering, 2D phase plots, cosmological halo analysis and production of synthetic X-ray observation. In this paper, we provide a brief tutorial for the installation of yt and the Intel Distribution for Python, and the execution of each analysis task. Compared to the Anaconda python distribution, using the provided solution one can achieve net speedups up to 4.6x on Intel Xeon Scalable processors (codename Skylake).			arxiv	['Luigi Iapichino', 'Fabio Baruffa']	82.0
332	Extending Python for Quantum-Classical Computing via Quantum Just-in-Time Compilation	Thien Nguyen	2021-05-10 21:11:21	http://arxiv.org/abs/2105.04671v1	Python is a popular programming language known for its flexibility, usability, readability, and focus on developer productivity. The quantum software community has adopted Python on a number of large-scale efforts due to these characteristics, as well as the remote nature of near-term quantum processors. The use of Python has enabled quick prototyping for quantum code that directly benefits pertinent research and development efforts in quantum scientific computing. However, this rapid prototyping ability comes at the cost of future performant integration for tightly-coupled CPU-QPU architectures with fast-feedback. Here we present a language extension to Python that enables heterogeneous quantum-classical computing via a robust C++ infrastructure for quantum just-in-time (QJIT) compilation. Our work builds off the QCOR C++ language extension and compiler infrastructure to enable a single-source, quantum hardware-agnostic approach to quantum-classical computing that retains the performance required for tightly coupled CPU-QPU compute models. We detail this Pythonic extension, its programming model and underlying software architecture, and provide a robust set of examples to demonstrate the utility of our approach.			arxiv	['Alexander J. McCaskey']	83.0
333	An Empirical Study of Automated Unit Test Generation for Python	Stephan Lukasczyk	2021-11-09 08:54:33	http://arxiv.org/abs/2111.05003v2	Various mature automated test generation tools exist for statically typed programming languages such as Java. Automatically generating unit tests for dynamically typed programming languages such as Python, however, is substantially more difficult due to the dynamic nature of these languages as well as the lack of type information. Our Pynguin framework provides automated unit test generation for Python. In this paper, we extend our previous work on Pynguin to support more aspects of the Python language, and by studying a larger variety of well-established state of the art test-generation algorithms, namely DynaMOSA, MIO, and MOSA. Furthermore, we improved our Pynguin tool to generate regression assertions, whose quality we also evaluate. Our experiments confirm that evolutionary algorithms can outperform random test generation also in the context of Python, and similar to the Java world, DynaMOSA yields the highest coverage results. However, our results also demonstrate that there are still fundamental remaining issues, such as inferring type information for code without this information, currently limiting the effectiveness of test generation for Python.			arxiv	['Florian Kroiß', 'Gordon Fraser']	84.0
334	An Exploratory Study on the Predominant Programming Paradigms in Python Code	Robert Dyer	2022-09-05 08:03:20	http://arxiv.org/abs/2209.01817v1	Python is a multi-paradigm programming language that fully supports object-oriented (OO) programming. The language allows writing code in a non-procedural imperative manner, using procedures, using classes, or in a functional style. To date, no one has studied what paradigm(s), if any, are predominant in Python code and projects. In this work, we first define a technique to classify Python files into predominant paradigm(s). We then automate our approach and evaluate it against human judgements, showing over 80% agreement. We then analyze over 100k open-source Python projects, automatically classifying each source file and investigating the paradigm distributions. The results indicate Python developers tend to heavily favor OO features. We also observed a positive correlation between OO and procedural paradigms and the size of the project. And despite few files or projects being predominantly functional, we still found many functional feature uses.			arxiv	['Jigyasa Chauhan']	85.0
335	A Data Set of Generalizable Python Code Change Patterns	Akalanka Galappaththi	2023-04-11 04:59:26	http://arxiv.org/abs/2304.04983v1	Mining repetitive code changes from version control history is a common way of discovering unknown change patterns. Such change patterns can be used in code recommender systems or automated program repair techniques. While there are such tools and datasets exist for Java, there is little work on finding and recommending such changes in Python. In this paper, we present a data set of manually vetted generalizable Python repetitive code change patterns. We create a coding guideline to identify generalizable change patterns that can be used in automated tooling. We leverage the mined change patterns from recent work that mines repetitive changes in Python projects and use our coding guideline to manually review the patterns. For each change, we also record a description of the change and why it is applied along with other characteristics such as the number of projects it occurs in. This review process allows us to identify and share 72 Python change patterns that can be used to build and advance Python developer support tools.			arxiv	['Sarah Nadi']	86.0
336	Scalable Demand-Driven Call Graph Generation for Python	Yixuan Yan	2023-05-10 07:40:05	http://arxiv.org/abs/2305.05949v1	Call graph generation is the foundation of inter-procedural static analysis. PyCG is the state-of-the-art approach for generating call graphs for Python programs. Unfortunately, PyCG does not scale to large programs when adapted to whole-program analysis where dependent libraries are also analyzed. Further, PyCG does not support demand-driven analysis where only the reachable functions from given entry functions are analyzed. Moreover, PyCG is flow-insensitive and does not fully support Python's features, hindering its accuracy. To overcome these drawbacks, we propose a scalable demand-driven approach for generating call graphs for Python programs, and implement it as a prototype tool Jarvis. Jarvis maintains an assignment graph (i.e., points-to relations between program identifiers) for each function in a program to allow reuse and improve scalability. Given a set of entry functions as the demands, Jarvis generates the call graph on-the-fly, where flow-sensitive intra-procedural analysis and inter-procedural analysis are conducted in turn. Our evaluation on a micro-benchmark of 135 small Python programs and a macro-benchmark of 6 real-world Python applications has demonstrated that Jarvis can significantly improve PyCG by at least 67% faster in time, 84% higher in precision, and at least 10% higher in recall.			arxiv	['Kaifeng Huang', 'Bihuan Chen', 'Zixin Tao', 'Xin Peng']	87.0
337	Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for Tetrad Causal Search	Joseph D. Ramsey	2023-08-13 16:29:05	http://arxiv.org/abs/2308.07346v1	We give novel Python and R interfaces for the (Java) Tetrad project for causal modeling, search, and estimation. The Tetrad project is a mainstay in the literature, having been under consistent development for over 30 years. Some of its algorithms are now classics, like PC and FCI; others are recent developments. It is increasingly the case, however, that researchers need to access the underlying Java code from Python or R. Existing methods for doing this are inadequate. We provide new, up-to-date methods using the JPype Python-Java interface and the Reticulate Python-R interface, directly solving these issues. With the addition of some simple tools and the provision of working examples for both Python and R, using JPype and Reticulate to interface Python and R with Tetrad is straightforward and intuitive.			arxiv	['Bryan Andrews']	88.0
338	High performance Python for direct numerical simulations of turbulent flows	Mikael Mortensen	2016-02-11 08:12:37	http://arxiv.org/abs/1602.03638v1	Direct Numerical Simulations (DNS) of the Navier Stokes equations is an invaluable research tool in fluid dynamics. Still, there are few publicly available research codes and, due to the heavy number crunching implied, available codes are usually written in low-level languages such as C/C++ or Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS code that nearly matches the performance of C++ for thousands of processors and billions of unknowns. We also describe a version optimized through Cython, that is found to match the speed of C++. The solvers are written from scratch in Python, both the mesh, the MPI domain decomposition, and the temporal integrators. The solvers have been verified and benchmarked on the Shaheen supercomputer at the KAUST supercomputing laboratory, and we are able to show very good scaling up to several thousand cores. A very important part of the implementation is the mesh decomposition (we implement both slab and pencil decompositions) and 3D parallel Fast Fourier Transforms (FFT). The mesh decomposition and FFT routines have been implemented in Python using serial FFT routines (either NumPy, pyFFTW or any other serial FFT module), NumPy array manipulations and with MPI communications handled by MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT in Python for a slab mesh decomposition using 4 lines of compact Python code, for which the parallel performance on Shaheen is found to be slightly better than similar routines provided through the FFTW library. For a pencil mesh decomposition 7 lines of code is required to execute a transform.			arxiv	['Hans Petter Langtangen']	89.0
339	PyCG: Practical Call Graph Generation in Python	Vitalis Salis	2021-02-28 18:49:25	http://arxiv.org/abs/2103.00587v1	"Call graphs play an important role in different contexts, such as profiling and vulnerability propagation analysis. Generating call graphs in an efficient manner can be a challenging task when it comes to high-level languages that are modular and incorporate dynamic features and higher-order functions. Despite the language's popularity, there have been very few tools aiming to generate call graphs for Python programs. Worse, these tools suffer from several effectiveness issues that limit their practicality in realistic programs. We propose a pragmatic, static approach for call graph generation in Python. We compute all assignment relations between program identifiers of functions, variables, classes, and modules through an inter-procedural analysis. Based on these assignment relations, we produce the resulting call graph by resolving all calls to potentially invoked functions. Notably, the underlying analysis is designed to be efficient and scalable, handling several Python features, such as modules, generators, function closures, and multiple inheritance. We have evaluated our prototype implementation, which we call PyCG, using two benchmarks: a micro-benchmark suite containing small Python programs and a set of macro-benchmarks with several popular real-world Python packages. Our results indicate that PyCG can efficiently handle thousands of lines of code in less than a second (0.38 seconds for 1k LoC on average). Further, it outperforms the state-of-the-art for Python in both precision and recall: PyCG achieves high rates of precision ~99.2%, and adequate recall ~69.9%. Finally, we demonstrate how PyCG can aid dependency impact analysis by showcasing a potential enhancement to GitHub's ""security advisory"" notification service using a real-world example."			arxiv	['Thodoris Sotiropoulos', 'Panos Louridas', 'Diomidis Spinellis', 'Dimitris Mitropoulos']	90.0
340	PyArmadillo: a streamlined linear algebra library for Python	Jason Rumengan	2021-04-22 15:13:33	http://arxiv.org/abs/2104.11120v4	PyArmadillo is a linear algebra library for the Python language, with the aim of closely mirroring the programming interface of the widely used Armadillo C++ library, which in turn is deliberately similar to Matlab. PyArmadillo hence facilitates algorithm prototyping with Matlab-like syntax directly in Python, and relatively straightforward conversion of PyArmadillo-based Python code into performant Armadillo-based C++ code. The converted code can be used for purposes such as speeding up Python-based programs in conjunction with pybind11, or the integration of algorithms originally prototyped in Python into larger C++ codebases. PyArmadillo provides objects for matrices and cubes, as well as over 200 associated functions for manipulating data stored in the objects. Integer, floating point and complex numbers are supported. Various matrix factorisations are provided through integration with LAPACK, or one of its high performance drop-in replacements such as Intel MKL or OpenBLAS. PyArmadillo is open-source software, distributed under the Apache 2.0 license; it can be obtained at https://pyarma.sourceforge.io or via the Python Package Index in precompiled form.			arxiv	['Terry Yue Zhuo', 'Conrad Sanderson']	91.0
341	Python for Smarter Cities: Comparison of Python libraries for static and interactive visualisations of large vector data	Gregor Herda	2022-02-26 10:23:29	http://arxiv.org/abs/2202.13105v1	Local governments, as part of 'smart city' initiatives and to promote interoperability, are increasingly incorporating open-source software into their data management, analysis, and visualisation workflows. Python, with its concise and natural syntax, presents a low barrier to entry for municipal staff without computer science backgrounds. However, with regard to geospatial visualisations in particular, the range of available Python libraries has diversified to such an extent that identifying candidate libraries for specific use cases is a challenging undertaking. This study therefore assesses prominent, actively-developed visualisation libraries in the Python ecosystem with respect to their suitability for producing visualisations of large vector datasets. A simple visualisation task common in urban development is used to produce near-identical thematic maps across static and an interactive 'tracks' of comparison. All short-listed libraries were able to generate the sample map products for both a small and larger dataset. Code complexity differed more strongly for interactive visualisations. Formal and informal documentation channels are highlighted to outline available resources for flattening learning curves. CPU runtimes for the Python-based portion of the process chain differed starkly for both tracks, pointing to avenues for further research. These results demonstrate that the Python ecosystem offers local governments powerful tools, free of vendor lock-in and licensing fees, to produce performant and consistently formatted visualisations for both internal and public distribution.			arxiv	['Robert McNabb']	92.0
342	An Empirical Study of Fault Localization in Python Programs	Mohammad Rezaalipour	2023-05-31 13:21:30	http://arxiv.org/abs/2305.19834v2	Despite its massive popularity as a programming language, especially in novel domains like data science programs, there is comparatively little research about fault localization that targets Python. Even though it is plausible that several findings about programming languages like C/C++ and Java -- the most common choices for fault localization research -- carry over to other languages, whether the dynamic nature of Python and how the language is used in practice affect the capabilities of classic fault localization approaches remain open questions to investigate. This paper is the first large-scale empirical study of fault localization on real-world Python programs and faults. Using Zou et al.'s recent large-scale empirical study of fault localization in Java as the basis of our study, we investigated the effectiveness (i.e., localization accuracy), efficiency (i.e., runtime performance), and other features (e.g., different entity granularities) of seven well-known fault-localization techniques in four families (spectrum-based, mutation-based, predicate switching, and stack-trace based) on 135 faults from 13 open-source Python projects from the BugsInPy curated collection. The results replicate for Python several results known about Java, and shed light on whether Python's peculiarities affect the capabilities of fault localization. The replication package that accompanies this paper includes detailed data about our experiments, as well as the tool FauxPy that we implemented to conduct the study.			arxiv	['Carlo A. Furia']	93.0
343	Does Python Smell Like Java? Tool Support for Design Defect Discovery in Python	Nicole Vavrová	2017-03-31 12:47:50	http://arxiv.org/abs/1703.10882v1	The context of this work is specification, detection and ultimately removal of detectable harmful patterns in source code that are associated with defects in design and implementation of software. In particular, we investigate five code smells and four antipatterns previously defined in papers and books. Our inquiry is about detecting those in source code written in Python programming language, which is substantially different from all prior research, most of which concerns Java or C-like languages. Our approach was that of software engineers: we have processed existing research literature on the topic, extracted both the abstract definitions of nine design defects and their concrete implementation specifications, implemented them all in a tool we have programmed and let it loose on a huge test set obtained from open source code from thousands of GitHub projects. When it comes to knowledge, we have found that more than twice as many methods in Python can be considered too long (statistically extremely longer than their neighbours within the same project) than in Java, but long parameter lists are seven times less likely to be found in Python code than in Java code. We have also found that Functional Decomposition, the way it was defined for Java, is not found in the Python code at all, and Spaghetti Code and God Classes are extremely rare there as well. The grounding and the confidence in these results comes from the fact that we have performed our experiments on 32'058'823 lines of Python code, which is by far the largest test set for a freely available Python parser. We have also designed the experiment in such a way that it aligned with prior research on design defect detection in Java in order to ease the comparison if we treat our own actions as a replication. Thus, the importance of the work is both in the unique open Python grammar of highest quality, tested on millions of lines of code, and in the design defect detection tool which works on something else than Java.			arxiv	['Vadim Zaytsev']	94.0
344	Python I, II, and III CMB Anisotropy Measurement Constraints on Open and Flat-Lambda CDM Cosmogonies	Graca Rocha	1999-05-11 18:16:35	http://arxiv.org/abs/astro-ph/9905127v1	We use Python I, II, and III cosmic microwave background anisotropy data to constrain cosmogonies. We account for the Python beamwidth and calibration uncertainties. We consider open and spatially-flat-Lambda cold dark matter cosmogonies, with nonrelativistic-mass density parameter Omega_0 in the range 0.1--1, baryonic-mass density parameter Omega_B in the range (0.005--0.029) h^{-2}, and age of the universe t_0 in the range (10--20) Gyr. Marginalizing over all parameters but Omega_0, the combined Python data favors an open (spatially-flat-Lambda) model with Omega_0 simeq 0.2 (0.1). At the 2 sigma confidence level model normalizations deduced from the combined Python data are mostly consistent with those drawn from the DMR, UCSB South Pole 1994, ARGO, MAX 4 and 5, White Dish, and SuZIE data sets.			arxiv	['Radoslaw Stompor', 'Ken Ganga', 'Bharat Ratra', 'Stephen R. Platt', 'Naoshi Sugiyama', 'Krzysztof M. Gorski']	95.0
345	A Python-based Post-processing Toolset For Seismic Analyses	Steve Brasier	2014-12-19 16:09:16	http://arxiv.org/abs/1412.6410v1	This paper discusses the design and implementation of a Python-based toolset to aid in assessing the response of the UK's Advanced Gas Reactor nuclear power stations to earthquakes. The seismic analyses themselves are carried out with a commercial Finite Element solver, but understanding the raw model output this produces requires customised post-processing and visualisation tools. Extending the existing tools had become increasingly difficult and a decision was made to develop a new, Python-based toolset. This comprises of a post-processing framework (aftershock) which includes an embedded Python interpreter, and a plotting package (afterplot) based on numpy and matplotlib. The new toolset had to be significantly more flexible and easier to maintain than the existing code-base, while allowing the majority of development to be carried out by engineers with little training in software development. The resulting architecture will be described with a focus on exploring how the design drivers were met and the successes and challenges arising from the choices made.			arxiv	['Fred Pollard']	96.0
346	Rabacus: A Python Package for Analytic Cosmological Radiative Transfer Calculations	Gabriel Altay	2015-02-10 07:03:42	http://arxiv.org/abs/1502.02798v2	We describe Rabacus, a Python package for calculating the transfer of hydrogen ionizing radiation in simplified geometries relevant to astronomy and cosmology. We present example solutions for three specific cases: 1) a semi-infinite slab gas distribution in a homogeneous isotropic background, 2) a spherically symmetric gas distribution with a point source at the center, and 3) a spherically symmetric gas distribution in a homogeneous isotropic background. All problems can accommodate arbitrary spectra and density profiles as input. The solutions include a treatment of both hydrogen and helium, a self-consistent calculation of equilibrium temperatures, and the transfer of recombination radiation. The core routines are written in Fortran 90 and then wrapped in Python leading to execution speeds thousands of times faster than equivalent routines written in pure Python. In addition, all variables have associated units for ease of analysis. The software is part of the Python Package Index and the source code is available on Bitbucket at https://bitbucket.org/galtay/rabacus . In addition, installation instructions and a detailed users guide are available at http://pythonhosted.org//rabacus .			arxiv	['John Wise']	97.0
347	Weighted graph algorithms with Python	A. Kapanowski	2015-04-29 12:20:20	http://arxiv.org/abs/1504.07828v1	Python implementation of selected weighted graph algorithms is presented. The minimal graph interface is defined together with several classes implementing this interface. Graph nodes can be any hashable Python objects. Directed edges are instances of the Edge class. Graphs are instances of the Graph class. It is based on the adjacency-list representation, but with fast lookup of nodes and neighbors (dict-of-dict structure). Other implementations of this class are also possible. In this work, many algorithms are implemented using a unified approach. There are separate classes and modules devoted to different algorithms. Three algorithms for finding a minimum spanning tree are implemented: the Boruvka's algorithm, the Prim's algorithm (three implementations), and the Kruskal's algorithm. Three algorithms for solving the single-source shortest path problem are implemented: the dag shortest path algorithm, the Bellman-Ford algorithm, and the Dijkstra's algorithm (two implementations). Two algorithms for solving all-pairs shortest path problem are implemented: the Floyd-Warshall algorithm and the Johnson's algorithm. All algorithms were tested by means of the unittest module, the Python unit testing framework. Additional computer experiments were done in order to compare real and theoretical computational complexity. The source code is available from the public GitHub repository.			arxiv	['Ł. Gałuszka']	98.0
348	Garbage Collection in JyNI - How to bridge Mark/Sweep and Reference Counting GC	Stefan Richthofer	2016-07-01 19:11:01	http://arxiv.org/abs/1607.00825v1	Jython is a Java-based Python implementation and the most seamless way to integrate Python and Java. It achieves high efficiency by compiling Python code to Java bytecode and thus letting Java's JIT optimize it - an approach that enables Python code to call Java functions or to subclass Java classes. It enables Python code to leverage Java's multithreading features and utilizes Java's built-in garbage collection (GC). However, it currently does not support CPython's C-API and thus does not support native extensions like NumPy and SciPy. Since most scientific code depends on such extensions, it is not runnable with Jython. Jython Native Interface (JyNI) is a compatibility layer that aims to provide CPython's native C extension API on top of Jython. JyNI is implemented using the Java Native Interface (JNI) and its native part is designed to be binary compatible with existing extension builds [...].			arxiv	[]	99.0
349	Devito: Towards a generic Finite Difference DSL using Symbolic Python	Michael Lange	2016-09-12 12:15:36	http://arxiv.org/abs/1609.03361v1	Domain specific languages (DSL) have been used in a variety of fields to express complex scientific problems in a concise manner and provide automated performance optimization for a range of computational architectures. As such DSLs provide a powerful mechanism to speed up scientific Python computation that goes beyond traditional vectorization and pre-compilation approaches, while allowing domain scientists to build applications within the comforts of the Python software ecosystem. In this paper we present Devito, a new finite difference DSL that provides optimized stencil computation from high-level problem specifications based on symbolic Python expressions. We demonstrate Devito's symbolic API and performance advantages over traditional Python acceleration methods before highlighting its use in the scientific context of seismic inversion problems.			arxiv	['Navjot Kukreja', 'Mathias Louboutin', 'Fabio Luporini', 'Felippe Vieira', 'Vincenzo Pandolfo', 'Paulius Velesko', 'Paulius Kazakas', 'Gerard Gorman']	100.0
350	Transformation of Python Applications into Function-as-a-Service Deployments	Josef Spillner	2017-05-23 10:43:53	http://arxiv.org/abs/1705.08169v1	New cloud programming and deployment models pose challenges to software application engineers who are looking, often in vain, for tools to automate any necessary code adaptation and transformation. Function-as-a-Service interfaces are particular non-trivial targets when considering that most cloud applications are implemented in non-functional languages. Among the most widely used of these languages is Python. This starting position calls for an automated approach to transform monolithic Python code into modular FaaS units by partially automated decomposition. Hence, this paper introduces and evaluates Lambada, a Python module to dynamically decompose, convert and deploy unmodified Python code into AWS Lambda functions. Beyond the tooling in the form of a measured open source prototype implementation, the paper contributes a description of the algorithms and code rewriting rules as blueprints for transformations of other scripting languages.			arxiv	[]	101.0
351	NL4Py: Agent-Based Modeling in Python with Parallelizable NetLogo Workspaces	Chathika Gunaratne	2018-08-09 18:21:55	http://arxiv.org/abs/1808.03292v5	External control of agent-based models is vital for complex adaptive systems research. Often these experiments require vast numbers of simulation runs and are computationally expensive. NetLogo is the language of choice for most agent-based modelers but lacks direct API access through Python. NL4Py is a Python package for the parallel execution of NetLogo simulations via Python, designed for speed, scalability, and simplicity of use. NL4Py provides access to the large number of open-source machine learning and analytics libraries of Python and enables convenient and efficient parallelization of NetLogo simulations with minimal coding expertise by domain scientists.			arxiv	['Ivan Garibay']	102.0
352	LensKit for Python: Next-Generation Software for Recommender System Experiments	Michael D. Ekstrand	2018-09-10 04:15:05	http://arxiv.org/abs/1809.03125v4	LensKit is an open-source toolkit for building, researching, and learning about recommender systems. First released in 2010 as a Java framework, it has supported diverse published research, small-scale production deployments, and education in both MOOC and traditional classroom settings. In this paper, I present the next generation of the LensKit project, re-envisioning the original tool's objectives as flexible Python package for supporting recommender systems research and development. LensKit for Python (LKPY) enables researchers and students to build robust, flexible, and reproducible experiments that make use of the large and growing PyData and Scientific Python ecosystem, including scikit-learn, TensorFlow, and PyTorch. To that end, it provides classical collaborative filtering implementations, recommender system evaluation metrics, data preparation routines, and tools for efficiently batch running recommendation algorithms, all usable in any combination with each other or with other Python software. This paper describes the design goals, use cases, and capabilities of LKPY, contextualized in a reflection on the successes and failures of the original LensKit for Java software.			arxiv	[]	103.0
353	Tangent: Automatic Differentiation Using Source Code Transformation in Python	Bart van Merriënboer	2017-11-07 20:15:24	http://arxiv.org/abs/1711.02712v1	Automatic differentiation (AD) is an essential primitive for machine learning programming systems. Tangent is a new library that performs AD using source code transformation (SCT) in Python. It takes numeric functions written in a syntactic subset of Python and NumPy as input, and generates new Python functions which calculate a derivative. This approach to automatic differentiation is different from existing packages popular in machine learning, such as TensorFlow and Autograd. Advantages are that Tangent generates gradient code in Python which is readable by the user, easy to understand and debug, and has no runtime overhead. Tangent also introduces abstractions for easily injecting logic into the generated gradient code, further improving usability.			arxiv	['Alexander B. Wiltschko', 'Dan Moldovan']	104.0
354	Optimizing and Evaluating Transient Gradual Typing	Michael M. Vitousek	2019-02-20 23:20:15	http://arxiv.org/abs/1902.07808v1	Gradual typing enables programmers to combine static and dynamic typing in the same language. However, ensuring a sound interaction between the static and dynamic parts can incur significant runtime cost. In this paper, we perform a detailed performance analysis of the transient gradual typing approach implemented in Reticulated Python, a gradually typed variant of Python. The transient approach inserts lightweight checks throughout a program rather than installing proxies on higher order values. We show that, when running Reticulated Python and the transient approach on CPython, performance decreases as programs evolve from dynamic to static types, up to a 6x slowdown compared to equivalent Python programs. To reduce this overhead, we design a static analysis and optimization that removes redundant runtime checks. The optimization employs a static type inference algorithm that solves traditional subtyping constraints and also a new kind of check constraint. We evaluate the resulting performance and find that for many programs, the efficiency of partially typed programs is close to their untyped counterparts, removing most of the slowdown of transient checks. Finally, we measure the efficiency of Reticulated Python programs when running on PyPy, a tracing JIT. We find that combining PyPy with our type inference algorithm reduces the overall overhead to zero.			arxiv	['Jeremy G. Siek', 'Avik Chaudhuri']	105.0
355	PyNetMet: Python tools for efficient work with networks and metabolic models	D. Gamermann	2012-11-30 09:25:06	http://arxiv.org/abs/1211.7196v1	Background: The study of genome-scale metabolic models and their underlying networks is one of the most important fields in systems biology. The complexity of these models and their description makes the use of computational tools an essential element in their research. Therefore there is a strong need of efficient and versatile computational tools for the research in this area. Results: In this manuscript we present PyNetMet, a Python library of tools to work with networks and metabolic models. These are open-source free tools for use in a Python platform, which adds considerably versatility to them when compared with their desktop software similars. On the other hand these tools allow one to work with different standards of metabolic models (OptGene and SBML) and the fact that they are programmed in Python opens the possibility of efficient integration with any other already existing Python tool. Conclusions: PyNetMet is, therefore, a collection of computational tools that will facilitate the research work with metabolic models and networks.			arxiv	['A. Montagud', 'R. A. Jaime Infante', 'J. Triana', 'P. F. de Córdoba', 'J. F. Urchueguía']	106.0
356	Network visualizations with Pyvis and VisJS	Giancarlo Perrone	2020-06-02 17:32:32	http://arxiv.org/abs/2006.04951v1	Pyvis is a Python module that enables visualizing and interactively manipulating network graphs in the Jupyter notebook, or as a standalone web application. Pyvis is built on top of the powerful and mature VisJS JavaScript library, which allows for fast and responsive interactions while also abstracting away the low-level JavaScript and HTML. This means that elements of the rendered graph visualization, such as node/edge attributes can be specified within Python and shipped to the JavaScript layer for VisJS to render. This declarative approach makes it easy to quickly explore graph visualizations and investigate data relationships. In addition, Pyvis is highly customizable so that colors, sizes, and hover tooltips can be assigned to the rendered graph. The network graph layout is controlled by a front-end physics engine that is configurable from a Python interface, allowing for the detailed placement of the graph elements. In this paper, we outline use cases for Pyvis with specific examples to highlight key features for any analysis workflow. A brief overview of Pyvis' implementation describes how the Python front-end binding uses simple Pyvis calls.			arxiv	['Jose Unpingco', 'Haw-minn Lu']	107.0
357	Extendible and Efficient Python Framework for Solving Evolution Equations with Stabilized Discontinuous Galerkin Method	Andreas Dedner	2020-09-25 16:23:57	http://arxiv.org/abs/2009.13416v2	This paper discusses a Python interface for the recently published DUNE-FEM-DG module which provides highly efficient implementations of the Discontinuous Galerkin (DG) method for solving a wide range of non linear partial differential equations (PDE). Although the C++ interfaces of DUNE-FEM-DG are highly flexible and customizable, a solid knowledge of C++ is necessary to make use of this powerful tool. With this work easier user interfaces based on Python and the Unified Form Language are provided to open DUNE-FEM-DG for a broader audience. The Python interfaces are demonstrated for both parabolic and first order hyperbolic PDEs.			arxiv	['Robert Klöfkorn']	108.0
358	Use of Python programming language in astronomy and science	Daniel M. Faes	2018-07-12 20:09:02	http://arxiv.org/abs/1807.04806v1	The use of Python is noticeably growing among the scientific community, and Astronomy is not an exception. The power of Python consists of being an extremely versatile high-level language, easy to program that combines both traditional programming and data reduction and analysis tools. Here I make a brief introduction to Python, mentioning a few programming practices implemented in the language and some of its useful features on the process of data manipulation. I cover in a little more detail the standard scientific libraries (NumPy and SciPy) for data handling, the graphical library (Matplotlib), and tools for specific use in astronomy (PyFITS and PyRAF). Good programming practices and how they are implemented at the language are also viewed. Python resources and references are mentioned through- out the text for those who wish to go deeper and make use of the power of the language.			arxiv	[]	109.0
359	zfit: scalable pythonic fitting	Jonas Eschle	2019-10-29 17:45:12	http://arxiv.org/abs/1910.13429v2	Statistical modeling is a key element in many scientific fields and especially in High-Energy Physics (HEP) analysis. The standard framework to perform this task in HEP is the C++ ROOT/RooFit toolkit; with Python bindings that are only loosely integrated into the scientific Python ecosystem. In this paper, zfit, a new alternative to RooFit written in pure Python, is presented. Most of all, zfit provides a well defined high-level API and workflow for advanced model building and fitting, together with an implementation on top of TensorFlow, allowing a transparent usage of CPUs and GPUs. It is designed to be extendable in a very simple fashion, allowing the usage of cutting-edge developments from the scientific Python ecosystem in a transparent way. The main features of zfit are introduced, and its extension to data analysis, especially in the context of HEP experiments, is discussed.			arxiv	['Albert Puig Navarro', 'Rafael Silva Coutinho', 'Nicola Serra']	110.0
360	An Executable Structural Operational Formal Semantics for Python	Maximilian A. Köhl	2021-09-07 15:11:23	http://arxiv.org/abs/2109.03139v1	Python is a popular high-level general-purpose programming language also heavily used by the scientific community. It supports a variety of different programming paradigms and is preferred by many for its ease of use. With the vision of harvesting static analysis techniques like abstract interpretation for Python, we develop a formal semantics for Python. A formal semantics is an important cornerstone for any sound static analysis technique. We base our efforts on the general framework of structural operational semantics yielding a small-step semantics in principle allowing for concurrency and interaction with an environment. The main contributions of this thesis are twofold: first, we develop a meta-theoretic framework for the formalization of structural operational semantics in tandem with the necessary tool support for the automated derivation of interpreters from such formal semantics, and, second, we validate the suitability of this approach for the formalization of modern programming languages developing a semantics for Python.			arxiv	[]	111.0
361	Social Networks as a Collective Intelligence: An Examination of the Python Ecosystem	Thomas Pike	2022-01-16 13:02:19	http://arxiv.org/abs/2201.06040v1	The Python ecosystem represents a global, data rich, technology-enabled network. By analyzing Python's dependency network, its top 14 most imported libraries and cPython (or core Python) libraries, this research finds clear evidence the Python network can be considered a problem solving network. Analysis of the contributor network of the top 14 libraries and cPython reveals emergent specialization, where experts of specific libraries are isolated and focused while other experts link these critical libraries together, optimizing both local and global information exchange efficiency. As these networks are expanded, the local efficiency drops while the density increases, representing a possible transition point between exploitation (optimizing working solutions) and exploration (finding new solutions). These results provide insight into the optimal functioning of technology-enabled social networks and may have larger implications for the effective functioning of modern organizations.			arxiv	['Robert Colter', 'Mark Bailey', 'Jackie Kazil', 'John Speed Meyers']	112.0
362	PyMigBench and PyMigTax: A Benchmark and Taxonomy for Python Library Migration	Mohayeminul Islam	2022-07-03 21:00:08	http://arxiv.org/abs/2207.01124v1	Developers heavily rely on Application Programming Interfaces (APIs) from libraries to build their projects. However, libraries might become obsolete, or new libraries with better APIs might become available. In such cases, developers need to replace the used libraries with alternative libraries, a process referred to as library migration. When done manually, library migration can be tedious, time-consuming, and error-prone. Most of the current research on automated library migration techniques focus on Java libraries, and even more so on version migrations of the same library. Despite the increasing popularity of Python, limited research work has investigated migration between Python libraries. In this paper, we investigate the nature of Python library migrations in open-source systems. We analyze the code changes that happen during library migration and build PyMigBench, a manually verified migration benchmark. PyMigBench contains 436 migration-related code changes from 74 commits in 57 client repositories, and includes migrations between 34 unique pairs of libraries. Additionally, we manually analyze the migration-related code changes and create a taxonomy of migrations, PyMigTax, that categorizes migrations across various dimensions. Our contributions provide the necessary foundations for developing automated Python library migration tools and techniques.			arxiv	['Ajay Kumar Jha', 'Sarah Nadi']	113.0
363	Modelling the Turtle Python library in CSP	Dara MacConville	2022-07-20 07:24:36	http://arxiv.org/abs/2207.09706v1	Software verification is an important tool in establishing the reliability of critical systems. One potential area of application is in the field of robotics, as robots take on more tasks in both day-to-day areas and highly specialised domains. Robots are usually given a plan to follow, if there are errors in this plan the robot will not perform reliably. The capability to check plans for errors in advance could prevent this. Python is a popular programming language in the robotics domain, through the use of the Robot Operating System (ROS) and various other libraries. Python's Turtle package provides a mobile agent, which we formally model here using Communicating Sequential Processes (CSP). Our interactive toolchain CSP2Turtle with CSP model and Python components, enables Turtle plans to be verified in CSP before being executed in Python. This means that certain classes of errors can be avoided, and provides a starting point for more detailed verification of Turtle programs and more complex robotic systems. We illustrate our approach with examples of robot navigation and obstacle avoidance in a 2D grid-world.			arxiv	['Marie Farrell', 'Matt Luckcuck', 'Rosemary Monahan']	114.0
364	SIGWfast: a python package for the computation of scalar-induced gravitational wave spectra	Lukas T. Witkowski	2022-09-12 15:00:12	http://arxiv.org/abs/2209.05296v1	SIGWfast is a python code to compute the scalar-induced gravitational wave spectrum from a primordial scalar power spectrum that can be given in analytical or numerical form. SIGWfast was written with the aim of being easy to install and use, and to produce results fast, typically in a matter of a few seconds. To this end the code employs vectorization techniques within python, but there is also the option to compile a C++ module to perform the relevant integrations, further accelerating the computation. The python-only version should run on all platforms that support python 3. The version employing the C++ module is only available for Linux and MacOS systems.			arxiv	[]	115.0
365	Serenity: Library Based Python Code Analysis for Code Completion and Automated Machine Learning	Wenting Zhao	2023-01-05 02:09:08	http://arxiv.org/abs/2301.05108v1	Dynamically typed languages such as Python have become very popular. Among other strengths, Python's dynamic nature and its straightforward linking to native code have made it the de-facto language for many research areas such as Artificial Intelligence. This flexibility, however, makes static analysis very hard. While creating a sound, or a soundy, analysis for Python remains an open problem, we present in this work Serenity, a framework for static analysis of Python that turns out to be sufficient for some tasks. The Serenity framework exploits two basic mechanisms: (a) reliance on dynamic dispatch at the core of language translation, and (b) extreme abstraction of libraries, to generate an abstraction of the code. We demonstrate the efficiency and usefulness of Serenity's analysis in two applications: code completion and automated machine learning. In these two applications, we demonstrate that such analysis has a strong signal, and can be leveraged to establish state-of-the-art performance, comparable to neural models and dynamic analysis respectively.			arxiv	['Ibrahim Abdelaziz', 'Julian Dolby', 'Kavitha Srinivas', 'Mossad Helali', 'Essam Mansour']	116.0
366	Transactional Python for Durable Machine Learning: Vision, Challenges, and Feasibility	Supawit Chockchowwat	2023-05-15 16:27:09	http://arxiv.org/abs/2305.08770v1	In machine learning (ML), Python serves as a convenient abstraction for working with key libraries such as PyTorch, scikit-learn, and others. Unlike DBMS, however, Python applications may lose important data, such as trained models and extracted features, due to machine failures or human errors, leading to a waste of time and resources. Specifically, they lack four essential properties that could make ML more reliable and user-friendly -- durability, atomicity, replicability, and time-versioning (DART). This paper presents our vision of Transactional Python that provides DART without any code modifications to user programs or the Python kernel, by non-intrusively monitoring application states at the object level and determining a minimal amount of information sufficient to reconstruct a whole application. Our evaluation of a proof-of-concept implementation with public PyTorch and scikit-learn applications shows that DART can be offered with overheads ranging 1.5%--15.6%.			arxiv	['Zhaoheng Li', 'Yongjoo Park']	117.0
367	pytest-inline: An Inline Testing Tool for Python	Yu Liu	2023-05-22 20:58:44	http://arxiv.org/abs/2305.13486v1	We present pytest-inline, the first inline testing framework for Python. We recently proposed inline tests to make it easier to test individual program statements. But, there is no framework-level support for developers to write inline tests in Python. To fill this gap, we design and implement pytest-inline as a plugin for pytest, the most popular Python testing framework. Using pytest-inline, a developer can write an inline test by assigning test inputs to variables in a target statement and specifying the expected test output. Then, pytest-inline runs each inline test and fails if the target statement's output does not match the expected output. In this paper, we describe our design of pytest-inline, the testing features that it provides, and the intended use cases. Our evaluation on inline tests that we wrote for 80 target statements from 31 open-source Python projects shows that using pytest-inline incurs negligible overhead, at 0.012x. pytest-inline is integrated into the pytest-dev organization, and a video demo is at https://www.youtube.com/watch?v=pZgiAxR_uJg.			arxiv	['Zachary Thurston', 'Alan Han', 'Pengyu Nie', 'Milos Gligoric', 'Owolabi Legunsen']	118.0
368	Taming the Panda with Python: A Powerful Duo for Seamless Robotics Programming and Integration	Jean Elsner	2023-07-14 21:11:28	http://arxiv.org/abs/2307.07633v1	Franka Emika robots have gained significant popularity in research and education due to their exceptional versatility and advanced capabilities. This work introduces panda-py - a Python interface and framework designed to empower Franka Emika robotics with accessible and efficient programming. The panda-py interface enhances the usability of Franka Emika robots, enabling researchers and educators to interact with them more effectively. By leveraging Python's simplicity and readability, users can quickly grasp the necessary programming concepts for robot control and manipulation. Moreover, integrating panda-py with other widely used Python packages in domains such as computer vision and machine learning amplifies the robot's capabilities. Researchers can seamlessly leverage the vast ecosystem of Python libraries, thereby enabling advanced perception, decision-making, and control functionalities. This compatibility facilitates the efficient development of sophisticated robotic applications, integrating state-of-the-art techniques from diverse domains without the added complexity of ROS.			arxiv	[]	119.0
369	Natlog: Embedding Logic Programming into the Python Deep-Learning Ecosystem	Paul Tarau	2023-08-30 09:05:13	http://arxiv.org/abs/2308.15890v1	Driven by expressiveness commonalities of Python and our Python-based embedded logic-based language Natlog, we design high-level interaction patterns between equivalent language constructs and data types on the two sides. By directly connecting generators and backtracking, nested tuples and terms, coroutines and first-class logic engines, reflection and meta-interpretation, we enable logic-based language constructs to access the full power of the Python ecosystem. We show the effectiveness of our design via Natlog apps working as orchestrators for JAX and Pytorch pipelines and as DCG-driven GPT3 and DALL.E prompt generators. Keyphrases: embedding of logic programming in the Python ecosystem, high-level inter-paradigm data exchanges, coroutining with logic engines, logic-based neuro-symbolic computing, logic grammars as prompt-generators for Large Language Models, logic-based neural network configuration and training.			arxiv	[]	120.0
370	Awkward Just-In-Time (JIT) Compilation: A Developer's Experience	Ianna Osborne	2023-10-02 13:52:22	http://arxiv.org/abs/2310.01461v1	Awkward Array is a library for performing NumPy-like computations on nested, variable-sized data, enabling array-oriented programming on arbitrary data structures in Python. However, imperative (procedural) solutions can sometimes be easier to write or faster to run. Performant imperative programming requires compilation; JIT-compilation makes it convenient to compile in an interactive Python environment. Various functions in Awkward Arrays JIT-compile a user's code into executable machine code. They use several different techniques, but reuse parts of each others' implementations. We discuss the techniques used to achieve the Awkward Arrays acceleration with JIT-compilation, focusing on RDataFrame, cppyy, and Numba, particularly Numba on GPUs: conversions of Awkward Arrays to and from RDataFrame; standalone cppyy; passing Awkward Arrays to and from Python functions compiled by Numba; passing Awkward Arrays to Python functions compiled for GPUs by Numba; and header-only libraries for populating Awkward Arrays from C++ without any Python dependencies.			arxiv	['Jim Pivarski', 'Ioana Ifrim', 'Angus Hollands', 'Henry Schreiner']	121.0
371	Accelerating Pythonic coupled cluster implementations: a comparison between CPUs and GPUs	Maximilian H. Kriebel	2023-10-06 19:55:11	http://arxiv.org/abs/2310.04559v1	We scrutinize how to accelerate the bottleneck operations of Pythonic coupled cluster implementations performed on a \texttt{NVIDIA} Tesla V100S PCIe 32GB (rev 1a) Graphics Processing Unit (GPU). The \texttt{NVIDIA} Compute Unified Device Architecture (CUDA) API is interacted with via \texttt{CuPy}, an open-source library for Python, designed as a \texttt{NumPy} drop-in replacement for GPUs. The implementation uses the Cholesky linear algebra domain and is done in {PyBEST}, the Pythonic Black-box Electronic Structure Tool -- a fully-fledged modern electronic structure software package. Due to the limitations of Video Memory (VRAM), the GPU calculations must be performed batch-wise. Timing results of some contractions containing large tensors are presented. The \texttt{CuPy} implementation leads to factor 10 speed-up compared to calculations on 36 CPUs. Furthermore, we benchmark several Pythonic routines for time and memory requirements to identify the optimal choice of the tensor contraction operations available. Finally, we compare an example CCSD and pCCD-LCCSD calculation performed solely on CPUs to their CPU--GPU hybrid implementation. Our results indicate a significant speed-up (up to a factor of 16 regarding the bottleneck operations) when offloading specific contractions to the GPU using \texttt{CuPy}.			arxiv	['Paweł Tecmer', 'Marta Gałyńska', 'Aleksandra Leszczyk', 'Katharina Boguslawski']	122.0
372	Python Unleashed on Systems Biology	Christopher R. Myers	2007-04-24 18:48:18	http://arxiv.org/abs/0704.3259v1	We have built an open-source software system for the modeling of biomolecular reaction networks, SloppyCell, which is written in Python and makes substantial use of third-party libraries for numerics, visualization, and parallel programming. We highlight here some of the powerful features that Python provides that enable SloppyCell to do dynamic code synthesis, symbolic manipulation, and parallel exploration of complex parameter spaces.			arxiv	['Ryan N. Gutenkunst', 'James. P. Sethna']	123.0
373	How applicable is Python as first computer language for teaching programming in a pre-university educational environment, from a teacher's point of view?	Fotis Georgatos	2008-09-09 14:39:57	http://arxiv.org/abs/0809.1437v1	This project report attempts to evaluate the educational properties of the Python computer language, in practice. This is done by examining computer language evolution history, related scientific background work, the existing educational research on computer languages and Python's experimental application in higher secondary education in Greece, during first half of year 2002. This Thesis Report was delivered in advance of a thesis defense for a Masters/Doctorandus (MSc/Drs) title with the Amstel Institute/Universiteit van Amsterdam, during the same year.			arxiv	[]	124.0
374	mlpy: Machine Learning Python	Davide Albanese	2012-02-29 13:49:10	http://arxiv.org/abs/1202.6548v2	mlpy is a Python Open Source Machine Learning library built on top of NumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of state-of-the-art machine learning methods for supervised and unsupervised problems and it is aimed at finding a reasonable compromise among modularity, maintainability, reproducibility, usability and efficiency. mlpy is multiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at the website http://mlpy.fbk.eu.			arxiv	['Roberto Visintainer', 'Stefano Merler', 'Samantha Riccadonna', 'Giuseppe Jurman', 'Cesare Furlanello']	125.0
375	pcigale: porting Code Investigating Galaxy Emission to Python	Yannick Roehlly	2013-09-24 22:49:51	http://arxiv.org/abs/1309.6366v1	We present pcigale, the port to Python of CIGALE (Code Investigating Galaxy Emission) a Fortran spectral energy distribution (SED) fitting code developed at the Laboratoire d'Astrophysique de Marseille. After recalling the specifics of the SED fitting method, we show the gains in modularity and versatility offered by Python, as well as the drawbacks compared to the compiled code.			arxiv	['Denis Burgarella', 'Véronique Buat', 'Médéric Boquien', 'Laure Ciesla', 'Sébastien Heinis']	126.0
376	Modernizing PHCpack through phcpy	Jan Verschelde	2013-09-30 21:05:03	http://arxiv.org/abs/1310.0056v2	PHCpack is a large software package for solving systems of polynomial equations. The executable phc is menu driven and file oriented. This paper describes the development of phcpy, a Python interface to PHCpack. Instead of navigating through menus, users of phcpy solve systems in the Python shell or via scripts. Persistent objects replace intermediate files.			arxiv	[]	127.0
377	High-Content Digital Microscopy with Python	Fabrice Salvaire	2014-04-25 10:54:26	http://arxiv.org/abs/1404.6385v2	High-Content Digital Microscopy enhances user comfort, data storage and analysis throughput, paving the way to new researches and medical diagnostics. A digital microscopy platform aims at capturing an image of a cover slip, at storing information on a file server and a database, at visualising the image and analysing its content. We will discuss how the Python ecosystem can provide such software framework efficiently. Moreover this paper will give an illustration of the data chunking approach to manage the huge amount of data.			arxiv	[]	128.0
378	Mining online social networks with Python to study urban mobility	Antònia Tugores	2014-04-25 10:54:23	http://arxiv.org/abs/1404.6966v1	On-line social networks have grown quickly over the last few years and nowadays many people use them frequently. Furthermore the emergence of smartphones allows to access these networks any time from any physical location. Among the social networks, Twitter offers a particularly large set of data publicly available. Here we discuss the procedure to mine this data and store it in distributed databases using Python scripts. We also illustrate how geolocated tweets can be used to study the mobility of people in urban areas.			arxiv	['Pere Colet']	129.0
379	Computing the coefficients for the power series solution of the Lane-Emden equation with the Python library SymPy	Klaus Rohe	2014-09-06 12:19:37	http://arxiv.org/abs/1409.2008v2	It is shown how the Python library Sympy can be used to compute symbolically the coefficients of the power series solution of the Lane-Emden equation (LEE). Sympy is an open source Python library for symbolic mathematics. The power series solutions are compared to the numerically computed solutions using matplotlib. The results of a run time measurement of the implemented algorithm are discussed at the end.			arxiv	[]	130.0
380	Frequentism and Bayesianism: A Python-driven Primer	Jake VanderPlas	2014-11-18 21:00:00	http://arxiv.org/abs/1411.5018v1	This paper presents a brief, semi-technical comparison of the essential features of the frequentist and Bayesian approaches to statistical inference, with several illustrative examples implemented in Python. The differences between frequentism and Bayesianism fundamentally stem from differing definitions of probability, a philosophical divide which leads to distinct approaches to the solution of statistical problems as well as contrasting ways of asking and answering questions about unknown parameters. After an example-driven discussion of these differences, we briefly compare several leading Python statistical packages which implement frequentist inference using classical methods and Bayesian inference using Markov Chain Monte Carlo.			arxiv	[]	131.0
381	Wyrm, A Pythonic Toolbox for Brain-Computer Interfacing	Bastian Venthur	2014-12-19 15:34:01	http://arxiv.org/abs/1412.6378v1	A Brain-Computer Interface (BCI) is a system that measures central nervous system activity and translates the recorded data into an output suitable for a computer to use as an input signal. Such a BCI system consists of three parts, the signal acquisition, the signal processing and the feedback/stimulus presentation. In this paper we present Wyrm, a signal processing toolbox for BCI in Python. Wyrm is applicable to a broad range of neuroscientific problems and capable for running online experiments in real time and off-line data analysis and visualisation.			arxiv	['Benjamin Blankertz']	132.0
382	PyPanda: a Python Package for Gene Regulatory Network Reconstruction	David G. P. van IJzendoorn	2016-04-22 19:17:43	http://arxiv.org/abs/1604.06783v2	PANDA (Passing Attributes between Networks for Data Assimilation) is a gene regulatory network inference method that uses message-passing to integrate multiple sources of 'omics data. PANDA was originally coded in C++. In this application note we describe PyPanda, the Python version of PANDA. PyPanda runs considerably faster than the C++ version and includes additional features for network analysis. Availability: The open source PyPanda Python package is freely available at https://github.com/davidvi/pypanda. Contact: d.g.p.van ijzendoorn@lumc.nl			arxiv	['Kimberly Glass', 'John Quackenbush', 'Marieke L. Kuijjer']	133.0
383	Data Poisoning: Lightweight Soft Fault Injection for Python	Mohammad Amin Alipour	2016-11-04 19:24:14	http://arxiv.org/abs/1611.01501v1	This paper introduces and explores the idea of data poisoning, a light-weight peer-architecture technique to inject faults into Python programs. This method requires very small modification to the original program, which facilitates evaluation of sensitivity of systems that are prototyped or modeled in Python. We propose different fault scenarios that can be injected to programs using data poisoning. We use Dijkstra's Self Stabilizing Ring Algorithm to illustrate the approach.			arxiv	['Alex Groce']	134.0
384	AutoWIG: Automatic Generation of Python Bindings for C++ Libraries	Pierre Fernique	2017-05-31 09:19:42	http://arxiv.org/abs/1705.11000v1	Most of Python and R scientific packages incorporate compiled scientific libraries to speed up the code and reuse legacy libraries. While several semi-automatic solutions exist to wrap these compiled libraries, the process of wrapping a large library is cumbersome and time consuming. In this paper, we introduce AutoWIG, a Python package that wraps automatically compiled libraries into high-level languages using LLVM/Clang technologies and the Mako templating engine. Our approach is automatic, extensible, and applies to complex C++ libraries, composed of thousands of classes or incorporating modern meta-programming constructs.			arxiv	['Christophe Pradal']	135.0
385	Leabra7: a Python package for modeling recurrent, biologically-realistic neural networks	C. Daniel Greenidge	2018-09-11 21:09:25	http://arxiv.org/abs/1809.04166v2	Emergent is a software package that uses the AdEx neural dynamics model and LEABRA learning algorithm to simulate and train arbitrary recurrent neural network architectures in a biologically-realistic manner. We present Leabra7, a complementary Python library that implements these same algorithms. Leabra7 is developed and distributed using modern software development principles, and integrates tightly with Python's scientific stack. We demonstrate recurrent Leabra7 networks using traditional pattern-association tasks and a standard machine learning task, classifying the IRIS dataset.			arxiv	['Noam Miller', 'Kenneth A. Norman']	136.0
386	Cyanure: An Open-Source Toolbox for Empirical Risk Minimization for Python, C++, and soon more	Julien Mairal	2019-12-17 18:04:31	http://arxiv.org/abs/1912.08165v2	Cyanure is an open-source C++ software package with a Python interface. The goal of Cyanure is to provide state-of-the-art solvers for learning linear models, based on stochastic variance-reduced stochastic optimization with acceleration mechanisms. Cyanure can handle a large variety of loss functions (logistic, square, squared hinge, multinomial logistic) and regularization functions (l_2, l_1, elastic-net, fused Lasso, multi-task group Lasso). It provides a simple Python API, which is very close to that of scikit-learn, which should be extended to other languages such as R or Matlab in a near future.			arxiv	[]	137.0
387	Comparing Python, Go, and C++ on the N-Queens Problem	Pascal Fua	2020-01-08 13:09:11	http://arxiv.org/abs/2001.02491v1	Python currently is the dominant language in the field of Machine Learning but is often criticized for being slow to perform certain tasks. In this report, we use the well-known $N$-queens puzzle as a benchmark to show that once compiled using the Numba compiler it becomes competitive with C++ and Go in terms of execution speed while still allowing for very fast prototyping. This is true of both sequential and parallel programs. In most cases that arise in an academic environment, it therefore makes sense to develop in ordinary Python, identify computational bottlenecks, and use Numba to remove them.			arxiv	['Krzysztof Lis']	138.0
388	CVXPY: A Python-Embedded Modeling Language for Convex Optimization	Steven Diamond	2016-03-03 01:07:38	http://arxiv.org/abs/1603.00943v2	CVXPY is a domain-specific language for convex optimization embedded in Python. It allows the user to express convex optimization problems in a natural syntax that follows the math, rather than in the restrictive standard form required by solvers. CVXPY makes it easy to combine convex optimization with high-level features of Python such as parallelism and object-oriented design. CVXPY is available at http://www.cvxpy.org/ under the GPL license, along with documentation and examples.			arxiv	['Stephen Boyd']	139.0
389	libact: Pool-based Active Learning in Python	Yao-Yuan Yang	2017-10-01 17:18:03	http://arxiv.org/abs/1710.00379v1	libact is a Python package designed to make active learning easier for general users. The package not only implements several popular active learning strategies, but also features the active-learning-by-learning meta-algorithm that assists the users to automatically select the best strategy on the fly. Furthermore, the package provides a unified interface for implementing more strategies, models and application-specific labelers. The package is open-source on Github, and can be easily installed from Python Package Index repository.			arxiv	['Shao-Chuan Lee', 'Yu-An Chung', 'Tung-En Wu', 'Si-An Chen', 'Hsuan-Tien Lin']	140.0
390	psrqpy: a python interface for querying the ATNF pulsar catalogue	Matthew Pitkin	2018-06-05 11:48:48	http://arxiv.org/abs/1806.07809v1	This Python module provides an interface for querying the Australia Telescope National Facility (ATNF) pulsar catalogue (Manchester et al. 2005). The intended users are astronomers wanting to extract data from the catalogue through a script rather than having to download and parse text tables output using the standard web interface. It allows users to access information, such as pulsar frequencies and sky locations, on all pulsars in the catalogue. Querying of the catalogue can easily be incorporated into Python scripts.			arxiv	[]	141.0
391	HolPy: Interactive Theorem Proving in Python	Bohua Zhan	2019-05-15 06:39:00	http://arxiv.org/abs/1905.05970v2	HolPy is an interactive theorem proving system implemented in Python. It uses higher-order logic as the logical foundation. Its main features include a pervasive use of macros in producing, checking, and storing proofs, a JSON-based format for theories, and an API for implementing proof automation and other extensions in Python. A point-and-click-based user interface is implemented for general-purpose theorem proving. We describe the main design decisions of HolPy, current applications, and plans for the future.			arxiv	[]	142.0
392	hankel: A Python library for performing simple and accurate Hankel transformations	Steven G. Murray	2019-06-03 21:37:26	http://arxiv.org/abs/1906.01088v1	This paper presents \textsc{hankel}, a pure-python code for solving Hankel-type integrals and transforms. Such transforms are common in the physical sciences, especially appearing as the radial solution to angularly symmetric Fourier Transforms in arbitrary dimensions. The code harnesses the advantages of solving such transforms via the one-dimensional Hankel transform -- an increase in conceptual simplicity and efficiency -- and implements them in the user-friendly and flexible Python language. We discuss several limitations of the adopted method, and point to the code's extensive documentation for further examples.			arxiv	['Francis J. Poulin']	143.0
393	Astroalign: A Python module for astronomical image registration	Martin Beroiz	2019-09-06 14:56:51	http://arxiv.org/abs/1909.02946v2	We present an algorithm implemented in the astroalign Python module for image registration in astronomy. Our module does not rely on WCS information and instead matches 3-point asterisms (triangles) on the images to find the most accurate linear transformation between the two. It is especially useful in the context of aligning images prior to stacking or performing difference image analysis. Astroalign can match images of different point-spread functions, seeing, and atmospheric conditions.			arxiv	['Juan B. Cabral', 'Bruno Sanchez']	144.0
394	CausalML: Python Package for Causal Machine Learning	Huigang Chen	2020-02-25 17:35:33	http://arxiv.org/abs/2002.11631v2	CausalML is a Python implementation of algorithms related to causal inference and machine learning. Algorithms combining causal inference and machine learning have been a trending topic in recent years. This package tries to bridge the gap between theoretical work on methodology and practical applications by making a collection of methods in this field available in Python. This paper introduces the key concepts, scope, and use cases of this package.			arxiv	['Totte Harinen', 'Jeong-Yoon Lee', 'Mike Yung', 'Zhenyu Zhao']	145.0
395	Pykat: Python package for modelling precision optical interferometers	Daniel D. Brown	2020-04-14 02:21:49	http://arxiv.org/abs/2004.06270v2	\textsc{Pykat} is a Python package which extends the popular optical interferometer modelling software \textsc{Finesse}. It provides a more modern and efficient user interface for conducting complex numerical simulations, as well as enabling the use of Python's extensive scientific software ecosystem. In this paper we highlight the relationship between \textsc{Pykat} and \textsc{Finesse}, how it is used, and provide an illustrative example of how it has helped to better understand the characteristics of the current generation of gravitational wave interferometers.			arxiv	['Philip Jones', 'Samuel Rowlinson', 'Andreas Freise', 'Sean Leavey', 'Anna C. Green', 'Daniel Toyra']	146.0
396	rigidPy: Rigidity Analysis in Python	Varda F. Hagh	2021-08-16 16:05:54	http://arxiv.org/abs/2108.07195v2	rigidPy is a Python package that provides a set of tools necessary for studying rigidity and mechanical response in spring networks. It also includes suitable modules for generating new realizations of networks with applications in glassy systems and protein structures. rigidPy is available freely on GitHub and can be installed using Python Package Index (PyPi). The detailed setup information is provided in this paper, along with an overview of the mathematical framework that has been used in developing the package.			arxiv	['Mahdi Sadjadi']	147.0
397	Pyndri: a Python Interface to the Indri Search Engine	Christophe Van Gysel	2017-01-03 17:17:34	http://arxiv.org/abs/1701.00749v1	We introduce pyndri, a Python interface to the Indri search engine. Pyndri allows to access Indri indexes from Python at two levels: (1) dictionary and tokenized document collection, (2) evaluating queries on the index. We hope that with the release of pyndri, we will stimulate reproducible, open and fast-paced IR research.			arxiv	['Evangelos Kanoulas', 'Maarten de Rijke']	148.0
398	miniKanren as a Tool for Symbolic Computation in Python	Brandon T. Willard	2020-05-24 03:09:08	http://arxiv.org/abs/2005.11644v3	"In this article, we give a brief overview of the current state and future potential of symbolic computation within the Python statistical modeling and machine learning community. We detail the use of miniKanren as an underlying framework for term rewriting and symbolic mathematics, as well as its ability to orchestrate the use of existing Python libraries. We also discuss the relevance and potential of relational programming for implementing more robust, portable, domain-specific ""math-level"" optimizations--with a slight focus on Bayesian modeling. Finally, we describe the work going forward and raise some questions regarding potential cross-overs between statistical modeling and programming language theory."			arxiv	[]	149.0
399	SymFields: An Open Source Symbolic Fields Analysis Tool for General Curvilinear Coordinates in Python	Nan Chu	2020-12-19 16:08:15	http://arxiv.org/abs/2012.10723v1	An open source symbolic tool for vector fields analysis 'SymFields' is developed in Python. The SymFields module is constructed upon Python symbolic module sympy, which could only conduct scaler field analysis. With SymFields module, you can conduct vector analysis for general curvilinear coordinates regardless whether it is orthogonal or not. In SymFields, the differential operators based on metric tensor are normalized to real physical values, which means your can use real physical value of the vector fields as inputs. This could greatly free the physicists from the tedious calculation under complicated coordinates.			arxiv	[]	150.0
400	FDApy: a Python package for functional data	Steven Golovkine	2021-01-26 10:07:33	http://arxiv.org/abs/2101.11003v1	We introduce the Python package, FDApy, as an implementation of functional data. This package provide modules for the analysis of such data. It includes classes for different dimensional data as well as irregularly sampled functional data. A simulation toolbox is also provided. It might be used to simulate different clusters of functional data. Some methodologies to handle these data are implemented, such as dimension reduction and clustering. New methods can be easily added. The package is publicly available on the Python Package Index and Github.			arxiv	[]	151.0
401	Accelerated Multiple Precision Direct Method and Mixed Precision Iterative Refinement on Python Programming Environment	Tomonori Kouya	2021-07-27 01:57:03	http://arxiv.org/abs/2107.12550v1	"Current Python programming environment does not have any reliable and efficient multiple precision floating-point (MPF) arithmetic except ``mpmath"" and ``gmpy2"" packages based on GNU MP(GMP) and MPFR libraries. Although it is well known that multi-component-type MPF library can be utilized for middle length precision arithmetic under 200 bits, they are not widely used on Python environment. In this paper, we describe our accelerated MPF direct method with AVX2 techniques and its application to mixed precision iterative refinement combined with mpmath, and demonstrate their efficiency on x86\_64 computational environments."			arxiv	[]	152.0
402	Analysing high-throughput sequencing data in Python with HTSeq 2.0	Givanna H Putri	2021-12-02 02:32:31	http://arxiv.org/abs/2112.00939v1	Summary: HTSeq 2.0 provides a more extensive API including a new representation for sparse genomic data, enhancements in htseq-count to suit single cell omics, a new script for data using cell and molecular barcodes, improved documentation, testing and deployment, bug fixes, and Python 3 support. Availability and implementation: HTSeq 2.0 is released as an open-source software under the GNU General Public Licence and available from the Python Package Index at https://pypi.python.org/pypi/HTSeq. The source code is available on Github at https://github.com/htseq/htseq. Contact: fabio.zanini@unsw.edu.au			arxiv	['Simon Anders', 'Paul Theodor Pyl', 'John E Pimanda', 'Fabio Zanini']	153.0
403	py-irt: A Scalable Item Response Theory Library for Python	John P. Lalor	2022-03-02 18:09:46	http://arxiv.org/abs/2203.01282v2	py-irt is a Python library for fitting Bayesian Item Response Theory (IRT) models. py-irt estimates latent traits of subjects and items, making it appropriate for use in IRT tasks as well as ideal-point models. py-irt is built on top of the Pyro and PyTorch frameworks and uses GPU-accelerated training to scale to large data sets. Code, documentation, and examples can be found at https://github.com/nd-ball/py-irt. py-irt can be installed from the GitHub page or the Python Package Index (PyPI).			arxiv	['Pedro Rodriguez']	154.0
404	Exporting Ada Software to Python and Julia	Jan Verschelde	2022-06-28 19:51:48	http://arxiv.org/abs/2206.14270v1	The objective is to demonstrate the making of Ada software available to Python and Julia programmers using GPRbuild. GPRbuild is the project manager of the GNAT toolchain. With GPRbuild the making of shared object files is fully automated and the software can be readily used in Python and Julia. The application is the build process of PHCpack, a free and open source software package to solve polynomial systems by homotopy continuation methods, written mainly in Ada, with components in C++, available at github at https://github.com/janverschelde/PHCpack.			arxiv	[]	155.0
405	PyQCAMS: Python Quasi-Classical Atom-Molecule Scattering	Rian Koots	2023-04-05 20:22:02	http://arxiv.org/abs/2304.02731v1	We present Python Quasi-classical atom-molecule scattering (PyQCAMS), a new Python package for atom-molecule scattering within the quasi-classical trajectory approach. The input consists of mass, collision energy, impact parameter, and pair-wise interactions to choose between Buckingham, generalized Lennard-Jones, and Morse potentials. As the output, the code provides the vibrational quenching, dissociation, and reactive cross sections along with the rovibrational energy distribution of the reaction products. Furthermore, we treat H$_2$ + Ca $\rightarrow$ CaH + H reactions as a prototypical example to illustrate the properties and performance of the software. Finally, we study the parallelization performance of the code by looking into the time per trajectory as a function of the number of CPUs used.			arxiv	['Jesús Pérez-Ríos']	156.0
406	Python Tool for Visualizing Variability of Pareto Fronts over Multiple Runs	Shuhei Watanabe	2023-05-15 17:59:34	http://arxiv.org/abs/2305.08852v1	Hyperparameter optimization is crucial to achieving high performance in deep learning. On top of the performance, other criteria such as inference time or memory requirement often need to be optimized due to some practical reasons. This motivates research on multi-objective optimization (MOO). However, Pareto fronts of MOO methods are often shown without considering the variability caused by random seeds and this makes the performance stability evaluation difficult. Although there is a concept named empirical attainment surface to enable the visualization with uncertainty over multiple runs, there is no major Python package for empirical attainment surface. We, therefore, develop a Python package for this purpose and describe the usage. The package is available at https://github.com/nabenabe0928/empirical-attainment-func.			arxiv	[]	157.0
407	ARULESPY: Exploring Association Rules and Frequent Itemsets in Python	Michael Hahsler	2023-05-24 15:52:01	http://arxiv.org/abs/2305.15263v1	The R arules package implements a comprehensive infrastructure for representing, manipulating, and analyzing transaction data and patterns using frequent itemsets and association rules. The package also provides a wide range of interest measures and mining algorithms, including the code of Christian Borgelt's popular and efficient C implementations of the association mining algorithms Apriori and Eclat, and optimized C/C++ code for mining and manipulating association rules using sparse matrix representation. This document describes the new Python package arulespy, which makes this infrastructure available for Python users.			arxiv	[]	158.0
408	A Simple Python Testbed for Federated Learning Algorithms	Miroslav Popovic	2023-05-31 16:59:51	http://arxiv.org/abs/2305.20027v2	Nowadays many researchers are developing various distributed and decentralized frameworks for federated learning algorithms. However, development of such a framework targeting smart Internet of Things in edge systems is still an open challenge. In this paper, we present our solution to that challenge called Python Testbed for Federated Learning Algorithms. The solution is written in pure Python, and it supports both centralized and decentralized algorithms. The usage of the presented solution is both validated and illustrated by three simple algorithm examples.			arxiv	['Marko Popovic', 'Ivan Kastelan', 'Miodrag Djukic', 'Silvia Ghilezan']	159.0
409	UXsim: An open source macroscopic and mesoscopic traffic simulator in Python -- a technical overview	Toru Seo	2023-09-29 10:16:28	http://arxiv.org/abs/2309.17114v2	This note describes a technical overview of UXsim, an open source macro/mesoscopic traffic simulator in pure Python programming language. UXsim is based on Kinematic Wave model (more specifically, mesoscopic version of Newell's simplified car-following model) and dynamic user optimum-like route choice principle, which are well established methodology in the transportation research field. It can compute dynamical network traffic flow and have basic visualization and analysis capability. Furthermore, users can implement their own models and control methods into the simulator by using Python, thanks to the flexibility of the language. The simulator and its codes are freely available at https://github.com/toruseo/UXsim under the MIT license.			arxiv	[]	160.0
410	arfpy: A python package for density estimation and generative modeling with adversarial random forests	Kristin Blesch	2023-11-13 14:28:21	http://arxiv.org/abs/2311.07366v1	This paper introduces $\textit{arfpy}$, a python implementation of Adversarial Random Forests (ARF) (Watson et al., 2023), which is a lightweight procedure for synthesizing new data that resembles some given data. The software $\textit{arfpy}$ equips practitioners with straightforward functionalities for both density estimation and generative modeling. The method is particularly useful for tabular data and its competitive performance is demonstrated in previous literature. As a major advantage over the mostly deep learning based alternatives, $\textit{arfpy}$ combines the method's reduced requirements in tuning efforts and computational resources with a user-friendly python interface. This supplies audiences across scientific fields with software to generate data effortlessly.			arxiv	['Marvin N. Wright']	161.0
411	Toward a comprehensive simulation framework for hypergraphs: a Python-base approach	Quoc Chuong Nguyen	2024-01-08 14:24:54	http://arxiv.org/abs/2401.03917v1	Hypergraphs, or generalization of graphs such that edges can contain more than two nodes, have become increasingly prominent in understanding complex network analysis. Unlike graphs, hypergraphs have relatively few supporting platforms, and such dearth presents a barrier to more widespread adaptation of hypergraph computational toolboxes that could enable further research in several areas. Here, we introduce HyperRD, a Python package for hypergraph computation, simulation, and interoperability with other powerful Python packages in graph and hypergraph research. Then, we will introduce two models on hypergraph, the general Schelling's model and the SIR model, and simulate them with HyperRD.			arxiv	['Trung Kien Le']	162.0
412	Postprandial morphological response of the intestinal epithelium of the Burmese python (Python molurus)	Jean-Hervé Lignot	2006-11-06 13:08:54	http://arxiv.org/abs/q-bio/0611019v1	The postprandial morphological changes of the intestinal epithelium of Burmese pythons were examined using fasting pythons and at eight time points after feeding. In fasting pythons, tightly packed enterocytes possess very short microvilli and are arranged in a pseudostratified fashion. Enterocyte width increases by 23% within 24 h postfeeding, inducing significant increases in villus length and intestinal mass. By 6 days postfeeding, enterocyte volume had peaked, following as much as an 80% increase. Contributing to enterocyte hypertrophy is the cellular accumulation of lipid droplets at the tips and edges of the villi of the proximal and middle small intestine, but which were absent in the distal small intestine. At 3 days postfeeding, conventional and environmental scanning electron microscopy revealed cracks and lipid extrusion along the narrow edges of the villi and at the villus tips. Transmission electron microscopy demonstrated the rapid postprandial lengthening of enterocyte microvilli, increasing 4.8-fold in length within 24 h, and the maintaining of that length through digestion. Beginning at 24 h postfeeding, spherical particles were found embedded apically within enterocytes of the proximal and middle small intestine. These particles possessed an annular-like construction and were stained with the calcium-stain Alizarine red S suggesting that they were bone in origin. Following the completion of digestion, many of the postprandial responses were reversed, as observed by the atrophy of enterocytes, the shortening of villi, and the retraction of the microvilli. Further exploration of the python intestine will reveal the underlying mechanisms of these trophic responses and the origin and fate of the engulfed particles.			arxiv	['Cécile Helmstetter', 'Stephen M Secor']	163.0
413	SimpleSBML: A Python package for creating, editing, and interrogating SBML models: Version 2.0	Herbert M Sauro	2020-09-04 00:38:04	http://arxiv.org/abs/2009.01969v3	In this technical report, we describe a new version of SimpleSBML which provides an easier to use interface to python-libSBML allowing users of Python to more easily construct, edit, and inspect SBML based models. The most commonly used package for constructing SBML models in Python is python-libSBML based on the C/C++ library libSBML. python-libSBML is a comprehensive library with a large range of options but can be difficult for new users to learn and requires long scripts to create even the simplest models. Inspecting existing SBML models can also be difficult due to the complexity of the underlying object model. Instead, we present SimpleSBML, a package that allows users to add and inspect species, parameters, reactions, events, and rules to a libSBML model with only one command for each. Models can be exported to SBML format, and SBML files can be imported and converted to SimpleSBML commands making it very easy to edit the original SBML model. In the new version, a range of `get' methods is provided that allows users to inspect existing SBML models without having to understand the underlying object model used by libSBML.			arxiv	[]	164.0
414	Gradual Typing in an Open World	Michael M. Vitousek	2016-10-26 19:36:31	http://arxiv.org/abs/1610.08476v1	Gradual typing combines static and dynamic typing in the same language, offering the benefits of both to programmers. Static typing provides error detection and strong guarantees while dynamic typing enables rapid prototyping and flexible programming idioms. For programmers to fully take advantage of a gradual type system, however, they must be able to trust their type annotations, and so runtime checks must be performed at the boundaries of static and dynamic code to ensure that static types are respected. Higher order and mutable values cannot be completely checked at these boundaries, and so additional checks must be performed at their use sites. Traditionally, this has been achieved by installing wrappers or proxies on such values that moderate the flow of data between static and dynamic, but these can cause problems if the language supports comparison of object identity or has a foreign function interface. Reticulated Python is a gradually typed variant of Python implemented via a source-to-source translator for Python 3. It implements a proxy-free alternative design named transient casts. This paper presents a formal semantics for transient casts and shows that not only are they sound, but they work in an open-world setting in which the Reticulated translator has only been applied to some of the program; the rest is untranslated Python. We formalize this open world soundness property and use Coq to prove that it holds for Anthill Python, a calculus that models Reticulated Python.			arxiv	['Jeremy G. Siek']	165.0
415	PyART: Python API Recommendation in Real-Time	Xincheng He	2021-02-09 08:50:02	http://arxiv.org/abs/2102.04706v1	API recommendation in real-time is challenging for dynamic languages like Python. Many existing API recommendation techniques are highly effective, but they mainly support static languages. A few Python IDEs provide API recommendation functionalities based on type inference and training on a large corpus of Python libraries and third-party libraries. As such, they may fail to recommend or make poor recommendations when type information is missing or target APIs are project-specific. In this paper, we propose a novel approach, PyART, to recommend APIs for Python programs in real-time. It features a light-weight analysis to derives so-called optimistic data-flow, which is neither sound nor complete, but simulates the local data-flow information humans can derive. It extracts three kinds of features: data-flow, token similarity, and token co-occurrence, in the context of the program point where a recommendation is solicited. A predictive model is trained on these features using the Random Forest algorithm. Evaluation on 8 popular Python projects demonstrates that PyART can provide effective API recommendations. When historic commits can be leveraged, which is the target scenario of a state-of-the-art tool ARIREC, our average top-1 accuracy is over 50% and average top-10 accuracy over 70%, outperforming APIREC and Intellicode (i.e., the recommendation component in Visual Studio) by 28.48%-39.05% for top-1 accuracy and 24.41%-30.49% for top-10 accuracy. In other applications such as when historic comments are not available and cross-project recommendation, PyART also shows better overall performance. The time to make a recommendation is less than a second on average, satisfying the real-time requirement.			arxiv	['Lei Xu', 'Xiangyu Zhang', 'Rui Hao', 'Yang Feng', 'Baowen Xu']	166.0
416	Python's Lunches in Jackiw-Teitelboim gravity with matter	Dongsu Bak	2021-12-08 10:51:52	http://arxiv.org/abs/2112.04224v2	We study Python's lunch geometries in the two-dimensional Jackiw-Teitelboim model coupled to a massless scalar field in the semiclassical limit. We show that all extrema including the minimal quantum extremal surface, bulges and appetizers lie inside the horizon. We obtain fully back-reacted general bulk solutions with a massless scalar field, which can be understood as deformations of black holes. The temperatures of the left/right black holes become in general different from each other. Moreover, in the presence of both state and source deformations at the same time, the asymptotic black hole spacetime is further excited from that of the vacuum solution. We provide information-theoretic interpretation of deformed geometries including Python's lunches, minimal quantum extremal surface and appetizers according to the entanglement wedge reconstruction hypothesis. By considering the restricted circuit complexity associated with Python's lunch geometries and the operator complexity of the Petz map reconstructing a code space operation, we show that the observational probability of Python's lunch degrees of freedom from the boundary is exponentially suppressed. Thus, any bulk causality violation effects related with Python's lunch degrees are suppressed nonperturbatively.			arxiv	['Chanju Kim', 'Sang-Heon Yi', 'Junggi Yoon']	167.0
417	pycefr: Python Competency Level through Code Analysis	Gregorio Robles	2022-03-30 01:54:26	http://arxiv.org/abs/2203.15990v1	Python is known to be a versatile language, well suited both for beginners and advanced users. Some elements of the language are easier to understand than others: some are found in any kind of code, while some others are used only by experienced programmers. The use of these elements lead to different ways to code, depending on the experience with the language and the knowledge of its elements, the general programming competence and programming skills, etc. In this paper, we present pycefr, a tool that detects the use of the different elements of the Python language, effectively measuring the level of Python proficiency required to comprehend and deal with a fragment of Python code. Following the well-known Common European Framework of Reference for Languages (CEFR), widely used for natural languages, pycefr categorizes Python code in six levels, depending on the proficiency required to create and understand it. We also discuss different use cases for pycefr: identifying code snippets that can be understood by developers with a certain proficiency, labeling code examples in online resources such as Stackoverflow and GitHub to suit them to a certain level of competency, helping in the onboarding process of new developers in Open Source Software projects, etc. A video shows availability and usage of the tool: https://tinyurl.com/ypdt3fwe.			arxiv	['Raula Gaikovina Kula', 'Chaiyong Ragkhitwetsagul', 'Tattiya Sakulniwat', 'Kenichi Matsumoto', 'Jesus M. Gonzalez-Barahona']	168.0
418	Safe-DS: A Domain Specific Language to Make Data Science Safe	Lars Reimann	2023-02-28 13:14:07	http://arxiv.org/abs/2302.14548v2	Due to the long runtime of Data Science (DS) pipelines, even small programming mistakes can be very costly, if they are not detected statically. However, even basic static type checking of DS pipelines is difficult because most are written in Python. Static typing is available in Python only via external linters. These require static type annotations for parameters or results of functions, which many DS libraries do not provide. In this paper, we show how the wealth of Python DS libraries can be used in a statically safe way via Safe-DS, a domain specific language (DSL) for DS. Safe-DS catches conventional type errors plus errors related to range restrictions, data manipulation, and call order of functions, going well beyond the abilities of current Python linters. Python libraries are integrated into Safe-DS via a stub language for specifying the interface of its declarations, and an API-Editor that is able to extract type information from the code and documentation of Python libraries, and automatically generate suitable stubs. Moreover, Safe-DS complements textual DS pipelines with a graphical representation that eases safe development by preventing syntax errors. The seamless synchronization of textual and graphic view lets developers always choose the one best suited for their skills and current task. We think that Safe-DS can make DS development easier, faster, and more reliable, significantly reducing development costs.			arxiv	['Günter Kniesel-Wünsche']	169.0
419	Efficient and Accurate Automatic Python Bindings with cppyy & Cling	Baidyanath Kundu	2023-04-05 19:12:05	http://arxiv.org/abs/2304.02712v1	The simplicity of Python and the power of C++ force stark choices on a scientific software stack. There have been multiple developments to mitigate language boundaries by implementing language bindings, but the impedance mismatch between the static nature of C++ and the dynamic one of Python hinders their implementation; examples include the use of user-defined Python types with templated C++ and advanced memory management. The development of the C++ interpreter Cling has changed the way we can think of language bindings as it provides an incremental compilation infrastructure available at runtime. That is, Python can interrogate C++ on demand, and bindings can be lazily constructed at runtime. This automatic binding provision requires no direct support from library authors and offers better performance than alternative solutions, such as PyBind11. ROOT pioneered this approach with PyROOT, which was later enhanced with its successor, cppyy. However, until now, cppyy relied on the reflection layer of ROOT, which is limited in terms of provided features and performance. This paper presents the next step for language interoperability with cppyy, enabling research into uniform cross-language execution environments and boosting optimization opportunities across language boundaries. We illustrate the use of advanced C++ in Numba-accelerated Python through cppyy. We outline a path forward for re-engineering parts of cppyy to use upstream LLVM components to improve performance and sustainability. We demonstrate cppyy purely based on a C++ reflection library, InterOp, which offers interoperability primitives based on Cling and Clang-Repl.			arxiv	['Vassil Vassilev', 'Wim Lavrijsen']	170.0
420	Empowering Learner-Centered Instruction: Integrating ChatGPT Python API and Tinker Learning for Enhanced Creativity and Problem-Solving Skills	Yun-Cheng Tsai	2023-05-01 13:40:25	http://arxiv.org/abs/2305.00821v1	The ChatGPT Python API plays a crucial role in promoting Learner-Centered Instruction (LCI) and aligns with the principles of Tinker Learning, allowing students to discover their learning strategies. LCI emphasizes the importance of active, hands-on learning experiences and encourages students to take responsibility for their learning journey. By integrating the ChatGPT Python API into the educational process, students can explore various resources, generate new ideas, and create content in a more personalized manner. This innovative approach enables students to engage with the learning material deeper, fostering a sense of ownership and motivation. As they work through the Creative Learning Spiral, students develop essential skills such as critical thinking, problem-solving, and creativity. The ChatGPT Python API is a valuable tool for students to explore different solutions, evaluate alternatives, and make informed decisions, all while encouraging self-directed learning. In Tinker Learning environments, the integration of ChatGPT Python API empowers students to experiment and iterate, allowing them to find the most effective learning strategies that cater to their individual needs and preferences. This personalized approach helps students to become more confident in their abilities, leading to tremendous academic success and long-term skill development. By leveraging the capabilities of the ChatGPT Python API, educational institutions can create a more engaging, supportive, and dynamic learning environment. This approach aligns with the principles of Learner-Centered Instruction and Tinker Learning, promoting a culture of curiosity, exploration, and creativity among students while preparing them for the challenges of the fast-paced, ever-changing world.			arxiv	[]	171.0
421	GT4Py: High Performance Stencils for Weather and Climate Applications using Python	Enrique G. Paredes	2023-11-14 17:07:24	http://arxiv.org/abs/2311.08322v1	All major weather and climate applications are currently developed using languages such as Fortran or C++. This is typical in the domain of high performance computing (HPC), where efficient execution is an important concern. Unfortunately, this approach leads to implementations that intermix optimizations for specific hardware architectures with the high-level numerical methods that are typical for the domain. This leads to code that is verbose, difficult to extend and maintain, and difficult to port to different hardware architectures. Here, we propose a different strategy based on GT4Py (GridTools for Python). GT4Py is a Python framework to write weather and climate applications that includes a high-level embedded domain specific language (DSL) to write stencil computations. The toolchain integrated in GT4Py enables automatic code-generation,to obtain the performance of state-of-the-art C++ and CUDA implementations. The separation of concerns between the mathematical definitions and the actual implementations allows for performance portability of the computations on a wide range of computing architectures, while being embedded in Python allows easy access to the tools of the Python ecosystem to enhance the productivity of the scientists and facilitate integration in complex workflows. Here, the initial release of GT4Py is described, providing an overview of the current state of the framework and performance results showing how GT4Py can outperform pure Python implementations by orders of magnitude.			arxiv	['Linus Groner', 'Stefano Ubbiali', 'Hannes Vogt', 'Alberto Madonna', 'Kean Mariotti', 'Felipe Cruz', 'Lucas Benedicic', 'Mauro Bianco', 'Joost VandeVondele', 'Thomas C. Schulthess']	172.0
422	ModuleGuard:Understanding and Detecting Module Conflicts in Python Ecosystem	Ruofan Zhu	2024-01-04 06:26:07	http://arxiv.org/abs/2401.02090v1	Python has become one of the most popular programming languages for software development due to its simplicity, readability, and versatility. As the Python ecosystem grows, developers face increasing challenges in avoiding module conflicts, which occur when different packages have the same namespace modules. Unfortunately, existing work has neither investigated the module conflict comprehensively nor provided tools to detect the conflict. Therefore, this paper systematically investigates the module conflict problem and its impact on the Python ecosystem. We propose a novel technique called InstSimulator, which leverages semantics and installation simulation to achieve accurate and efficient module extraction. Based on this, we implement a tool called ModuleGuard to detect module conflicts for the Python ecosystem. For the study, we first collect 97 MC issues, classify the characteristics and causes of these MC issues, summarize three different conflict patterns, and analyze their potential threats. Then, we conducted a large-scale analysis of the whole PyPI ecosystem (4.2 million packages) and GitHub popular projects (3,711 projects) to detect each MC pattern and analyze their potential impact. We discovered that module conflicts still impact numerous TPLs and GitHub projects. This is primarily due to developers' lack of understanding of the modules within their direct dependencies, not to mention the modules of the transitive dependencies. Our work reveals Python's shortcomings in handling naming conflicts and provides a tool and guidelines for developers to detect conflicts.			arxiv	['Xingyu Wang', 'Chengwei Liu', 'Zhengzi Xu', 'Wenbo Shen', 'Rui Chang', 'Yang Liu']	173.0
423	Multi-Agent Programming Contest 2012 - The Python-DTU Team	Jørgen Villadsen	2012-10-01 15:07:16	http://arxiv.org/abs/1210.0437v1	We provide a brief description of the Python-DTU system, including the overall design, the tools and the algorithms that we plan to use in the agent contest.			arxiv	['Andreas Schmidt Jensen', 'Mikko Berggren Ettienne', 'Steen Vester', 'Kenneth Balsiger Andersen', 'Andreas Frøsig']	174.0
424	Python Classes for Numerical Solution of PDE's	Asif Mushtaq	2015-03-16 11:01:13	http://arxiv.org/abs/1503.04602v1	We announce some Python classes for numerical solution of partial differential equations, or boundary value problems of ordinary differential equations. These classes are built on routines in \texttt{numpy} and \texttt{scipy.sparse.linalg} (or \texttt{scipy.linalg} for smaller problems).			arxiv	['Trond Kvamsdal', 'Kåre Olaussen']	175.0
425	A Python Class for Higher-Dimensional Schrödinger Equations	Amna Noreen	2015-03-16 11:14:51	http://arxiv.org/abs/1503.04607v1	"We announce a Python class for numerical solution of Schr{\""o}dinger equations in one or more space dimensions, employing some recently developed general classes for numerical solution of partial differential equations, and routines from \texttt{numpy} and \texttt{scipy.sparse.linalg} (or \texttt{scipy.linalg} for smaller problems)."			arxiv	['Kåre Olaussen']	176.0
426	The NLTK FrameNet API: Designing for Discoverability with a Rich Linguistic Resource	Nathan Schneider	2017-03-21 21:36:28	http://arxiv.org/abs/1703.07438v2	A new Python API, integrated within the NLTK suite, offers access to the FrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as well as annotated sentences can be processed programatically, or browsed with human-readable displays via the interactive Python prompt.			arxiv	['Chuck Wooters']	177.0
427	StegIbiza: Steganography in Club Music Implemented in Python	Krzysztof Szczypiorski	2017-05-22 14:56:49	http://arxiv.org/abs/1705.07788v1	This paper introduces the implementation of steganography method called StegIbiza, which uses tempo modulation as hidden message carrier. With the use of Python scripting language, a bit string was encoded and decoded using WAV and MP3 files. Once the message was hidden into a music files, an internet radio was created to evaluate broadcast possibilities. No dedicated music or signal processing equipment was used in this StegIbiza implementation			arxiv	['Wojciech Zydecki']	178.0
428	ruptures: change point detection in Python	Charles Truong	2018-01-02 20:35:23	http://arxiv.org/abs/1801.00826v1	ruptures is a Python library for offline change point detection. This package provides methods for the analysis and segmentation of non-stationary signals. Implemented algorithms include exact and approximate detection for various parametric and non-parametric models. ruptures focuses on ease of use by providing a well-documented and consistent interface. In addition, thanks to its modular structure, different algorithms and models can be connected and extended within this package.			arxiv	['Laurent Oudre', 'Nicolas Vayatis']	179.0
429	libconform v0.1.0: a Python library for conformal prediction	Jonas Fassbender	2019-07-03 16:24:10	http://arxiv.org/abs/1907.02015v1	This paper introduces libconform v0.1.0, a Python library for the conformal prediction framework, licensed under the MIT-license. libconform is not yet stable. This paper describes the main algorithms implemented and documents the API of libconform. Also some details about the implementation and changes in future versions are described.			arxiv	[]	180.0
430	srlearn: A Python Library for Gradient-Boosted Statistical Relational Models	Alexander L. Hayes	2019-12-17 20:46:32	http://arxiv.org/abs/1912.08198v1	We present srlearn, a Python library for boosted statistical relational models. We adapt the scikit-learn interface to this setting and provide examples for how this can be used to express learning and inference problems.			arxiv	[]	181.0
431	anesthetic: nested sampling visualisation	Will Handley	2019-05-12 18:37:10	http://arxiv.org/abs/1905.04768v1	anesthetic is a Python package for processing nested sampling runs, and will be useful for any scientist or statistician who uses nested sampling software. anesthetic unifies many existing tools and techniques in an extensible framework that is intuitive for users familiar with the standard Python packages, namely NumPy, SciPy, Matplotlib and pandas.			arxiv	[]	182.0
432	fgivenx: A Python package for functional posterior plotting	Will Handley	2019-08-02 15:30:12	http://arxiv.org/abs/1908.01711v1	fgivenx is a Python package for functional posterior plotting, currently used in astronomy, but will be of use to scientists performing any Bayesian analysis which has predictive posteriors that are functions. The source code for fgivenx is available on GitHub at https://github.com/williamjameshandley/fgivenx			arxiv	[]	183.0
433	PyNose: A Test Smell Detector For Python	Tongjie Wang	2021-08-10 12:43:09	http://arxiv.org/abs/2108.04639v1	Similarly to production code, code smells also occur in test code, where they are called test smells. Test smells have a detrimental effect not only on test code but also on the production code that is being tested. To date, the majority of the research on test smells has been focusing on programming languages such as Java and Scala. However, there are no available automated tools to support the identification of test smells for Python, despite its rapid growth in popularity in recent years. In this paper, we strive to extend the research to Python, build a tool for detecting test smells in this language, and conduct an empirical analysis of test smells in Python projects. We started by gathering a list of test smells from existing research and selecting test smells that can be considered language-agnostic or have similar functionality in Python's standard Unittest framework. In total, we identified 17 diverse test smells. Additionally, we searched for Python-specific test smells by mining frequent code change patterns that can be considered as either fixing or introducing test smells. Based on these changes, we proposed our own test smell called Suboptimal assert. To detect all these test smells, we developed a tool called PyNose in the form of a plugin to PyCharm, a popular Python IDE. Finally, we conducted a large-scale empirical investigation aimed at analyzing the prevalence of test smells in Python code. Our results show that 98% of the projects and 84% of the test suites in the studied dataset contain at least one test smell. Our proposed Suboptimal assert smell was detected in as much as 70.6% of the projects, making it a valuable addition to the list.			arxiv	['Yaroslav Golubev', 'Oleg Smirnov', 'Jiawei Li', 'Timofey Bryksin', 'Iftekhar Ahmed']	184.0
434	MKLpy: a python-based framework for Multiple Kernel Learning	Ivano Lauriola	2020-07-20 10:10:13	http://arxiv.org/abs/2007.09982v1	Multiple Kernel Learning is a recent and powerful paradigm to learn the kernel function from data. In this paper, we introduce MKLpy, a python-based framework for Multiple Kernel Learning. The library provides Multiple Kernel Learning algorithms for classification tasks, mechanisms to compute kernel functions for different data types, and evaluation strategies. The library is meant to maximize the usability and to simplify the development of novel solutions.			arxiv	['Fabio Aiolli']	185.0
435	ana_cont: Python package for analytic continuation	Josef Kaufmann	2021-05-24 11:33:35	http://arxiv.org/abs/2105.11211v1	We present the Python package ana_cont for the analytic continuation of fermionic and bosonic many-body Green's functions by means of either the Pade approximants or the maximum entropy method. The determination of hyperparameters and the implementation are described in detail. The code is publicly available on GitHub, where also documentation and learning resources are provided.			arxiv	['Karsten Held']	186.0
436	DeepAL: Deep Active Learning in Python	Kuan-Hao Huang	2021-11-30 10:17:58	http://arxiv.org/abs/2111.15258v1	We present DeepAL, a Python library that implements several common strategies for active learning, with a particular emphasis on deep active learning. DeepAL provides a simple and unified framework based on PyTorch that allows users to easily load custom datasets, build custom data handlers, and design custom strategies without much modification of codes. DeepAL is open-source on Github and welcome any contribution.			arxiv	[]	187.0
437	GridPyM: a Python module to handle grid diagrams	Agnese Barbensi	2022-10-13 22:35:14	http://arxiv.org/abs/2210.07399v2	Grid diagrams are a combinatorial version of classical link diagrams, widely used in theoretical, computational and applied knot theory. Motivated by questions from (bio)-physical knot theory, we introduce GridPyM, a Sage compatible Python module that handles grid diagrams. GridPyM focuses on generating and simplifying grids, and on modelling local transformations between them.			arxiv	['Daniele Celoria']	188.0
438	Diddy: a Python toolbox for infinite discrete dynamical systems	Ville Salo	2023-05-02 12:51:25	http://arxiv.org/abs/2305.01375v1	We introduce Diddy, a collection of Python scripts for analyzing infinite discrete dynamical systems. The main focus is on generalized multidimensional shifts of finite type (SFTs). We show how Diddy can be used to easily define SFTs and cellular automata, and analyze their basic properties. We also showcase how to verify or rediscover some results from coding theory and cellular automata theory.			arxiv	['Ilkka Törmä']	189.0
439	AQUATK: An Audio Quality Assessment Toolkit	Ashvala Vinay	2023-11-16 02:55:13	http://arxiv.org/abs/2311.10113v1	Recent advancements in Neural Audio Synthesis (NAS) have outpaced the development of standardized evaluation methodologies and tools. To bridge this gap, we introduce AquaTk, an open-source Python library specifically designed to simplify and standardize the evaluation of NAS systems. AquaTk offers a range of audio quality metrics, including a unique Python implementation of the basic PEAQ algorithm, and operates in multiple modes to accommodate various user needs.			arxiv	['Alexander Lerch']	190.0
440	Gradual Soundness: Lessons from Static Python	Kuang-Chen Lu	2022-06-28 08:53:44	http://arxiv.org/abs/2206.13831v1	Context: Gradually-typed languages allow typed and untyped code to interoperate, but typically come with significant drawbacks. In some languages, the types are unreliable; in others, communication across type boundaries can be extremely expensive; and still others allow only limited forms of interoperability. The research community is actively seeking a sound, fast, and expressive approach to gradual typing. Inquiry: This paper describes Static Python, a language developed by engineers at Instagram that has proven itself sound, fast, and reasonably expressive in production. Static Python's approach to gradual types is essentially a programmer-tunable combination of the concrete and transient approaches from the literature. Concrete types provide full soundness and low performance overhead, but impose nonlocal constraints. Transient types are sound in a shallow sense and easier to use; they help to bridge the gap between untyped code and typed concrete code. Approach: We evaluate the language in its current state and develop a model that captures the essence of its approach to gradual types. We draw upon personal communication, bug reports, and the Static Python regression test suite to develop this model. Knowledge: Our main finding is that the gradual soundness that arises from a mix of concrete and transient types is an effective way to lower the maintenance cost of the concrete approach. We also find that method-based JIT technology can eliminate the costs of the transient approach. On a more technical level, this paper describes two contributions: a model of Static Python and a performance evaluation of Static Python. The process of formalization found several errors in the implementation, including fatal errors. Grounding: Our model of Static Python is implemented in PLT Redex and tested using property-based soundness tests and 265 tests from the Static Python regression suite. This paper includes a small core of the model to convey the main ideas of the Static Python approach and its soundness. Our performance claims are based on production experience in the Instagram web server. Migrations to Static Python in the server have caused a 3.7\% increase in requests handled per second at maximum CPU load. Importance: Static Python is the first sound gradual language whose piece-meal application to a realistic codebase has consistently improved performance. Other language designers may wish to replicate its approach, especially those who currently maintain unsound gradual languages and are seeking a path to soundness.			arxiv	['Ben Greenman', 'Carl Meyer', 'Dino Viehland', 'Aniket Panse', 'Shriram Krishnamurthi']	191.0
441	Data Reduction and Analysis of the Python V Cosmic Microwave Background Anisotropy Experiment	Kimberly Ann Coble	1999-11-22 20:16:01	http://arxiv.org/abs/astro-ph/9911419v1	Observations of the microwave sky using the Python telescope in its fifth season of operation at the Amundsen-Scott South Pole Station in Antarctica are presented. The system consists of a 0.75 m off-axis telescope instrumented with a HEMT amplifier-based radiometer having continuum sensitivity from 37-45 GHz in two frequency bands. With a $0.91^{\circ} \times 1.02^{\circ} $ beam the instrument fully sampled 598 deg$^2$ of sky, including fields measured during the previous four seasons of Python observations. Interpreting the observed fluctuations as anisotropy in the cosmic microwave background, we place constraints on the angular power spectrum of fluctuations in eight multipole bands up to $l \sim 260$. The observed spectrum is consistent with both the COBE experiment and previous Python results. Total-power Wiener-filtered maps of the CMB are also presented. There is no significant contamination from known foregrounds. The results show a discernible rise in the angular power spectrum from large ($l \sim 40$) to small ($l \sim 200$) angular scales.			arxiv	[]	192.0
442	An Anthological Review of Research Utilizing MontyLingua, a Python-Based End-to-End Text Processor	Maurice HT Ling	2006-11-22 03:24:54	http://arxiv.org/abs/cs/0611113v1	MontyLingua, an integral part of ConceptNet which is currently the largest commonsense knowledge base, is an English text processor developed using Python programming language in MIT Media Lab. The main feature of MontyLingua is the coverage for all aspects of English text processing from raw input text to semantic meanings and summary generation, yet each component in MontyLingua is loosely-coupled to each other at the architectural and code level, which enabled individual components to be used independently or substituted. However, there has been no review exploring the role of MontyLingua in recent research work utilizing it. This paper aims to review the use of and roles played by MontyLingua and its components in research work published in 19 articles between October 2004 and August 2006. We had observed a diversified use of MontyLingua in many different areas, both generic and domain-specific. Although the use of text summarizing component had not been observe, we are optimistic that it will have a crucial role in managing the current trend of information overload in future research.			arxiv	[]	193.0
443	Object-oriented implementations of the MPDATA advection equation solver in C++, Python and Fortran	Sylwester Arabas	2013-01-07 20:59:13	http://arxiv.org/abs/1301.1334v2	Three object-oriented implementations of a prototype solver of the advection equation are introduced. The presented programs are based on Blitz++ (C++), NumPy (Python), and Fortran's built-in array containers. The solvers include an implementation of the Multidimensional Positive-Definite Advective Transport Algorithm (MPDATA). The introduced codes exemplify how the application of object-oriented programming (OOP) techniques allows to reproduce the mathematical notation used in the literature within the program code. A discussion on the tradeoffs of the programming language choice is presented. The main angles of comparison are code brevity and syntax clarity (and hence maintainability and auditability) as well as performance. In the case of Python, a significant performance gain is observed when switching from the standard interpreter (CPython) to the PyPy implementation of Python. Entire source code of all three implementations is embedded in the text and is licensed under the terms of the GNU GPL license.			arxiv	['Dorota Jarecka', 'Anna Jaruga', 'Maciej Fijałkowski']	194.0
444	PaPy: Parallel and Distributed Data-processing Pipelines in Python	Marcin Cieslik	2014-07-15 03:13:00	http://arxiv.org/abs/1407.4378v1	PaPy, which stands for parallel pipelines in Python, is a highly flexible framework that enables the construction of robust, scalable workflows for either generating or processing voluminous datasets. A workflow is created from user-written Python functions (nodes) connected by 'pipes' (edges) into a directed acyclic graph. These functions are arbitrarily definable, and can make use of any Python modules or external binaries. Given a user-defined topology and collection of input data, functions are composed into nested higher-order maps, which are transparently and robustly evaluated in parallel on a single computer or on remote hosts. Local and remote computational resources can be flexibly pooled and assigned to functional nodes, thereby allowing facile load-balancing and pipeline optimization to maximize computational throughput. Input items are processed by nodes in parallel, and traverse the graph in batches of adjustable size -- a trade-off between lazy-evaluation, parallelism, and memory consumption. The processing of a single item can be parallelized in a scatter/gather scheme. The simplicity and flexibility of distributed workflows using PaPy bridges the gap between desktop -> grid, enabling this new computing paradigm to be leveraged in the processing of large scientific datasets.			arxiv	['Cameron Mura']	195.0
445	Using Virtual Observatory with Python: querying remote astronomical databases	F. Paletou	2014-08-29 14:15:27	http://arxiv.org/abs/1408.7026v2	This tutorial is devoted to extending an existing catalogue with data taken elsewhere, either from CDS Vizier or Simbad database. As an example, we used the so-called 'Spectroscopic Survey of Stars in the Solar Neighborhood' (aka. S4N, Allende Prieto et al. 2004) in order to retrieve all objects with available data for the set of fundamental stellar parameters effective temperature, surface gravity and metallicity. Then for each object in this dataset we query Simbad database to retrieve the projected rotational velocity. This combines Vizier and Simbad queries made using Python astroquery module. The tutorial covers remote database access, filtering tables with arbitrary criteria, creating and writing your own tables, and basics of plotting in Python.			arxiv	['I. Zolotukhin']	196.0
446	SPySort: Neuronal Spike Sorting with Python	Christophe Pouzat	2014-12-19 15:40:00	http://arxiv.org/abs/1412.6383v1	Extracellular recordings with multi-electrode arrays is one of the basic tools of contemporary neuroscience. These recordings are mostly used to monitor the activities, understood as sequences of emitted action potentials, of many individual neurons. But the raw data produced by extracellular recordings are most commonly a mixture of activities from several neurons. In order to get the activities of the individual contributing neurons, a pre-processing step called spike sorting is required. We present here a pure Python implementation of a well tested spike sorting procedure. The latter was designed in a modular way in order to favour a smooth transition from an interactive sorting, for instance with IPython, to an automatic one. Surprisingly enough - or sadly enough, depending on one's view point -, recoding our now 15 years old procedure into Python was the occasion of major methodological improvements.			arxiv	['Georgios Is. Detorakis']	197.0
447	Using Python to Dive into Signalling Data with CellNOpt and BioServices	Thomas Cokelaer	2014-12-19 15:43:09	http://arxiv.org/abs/1412.6386v1	Systems biology is an inter-disciplinary field that studies systems of biological components at different scales, which may be molecules, cells or entire organism. In particular, systems biology methods are applied to understand functional deregulations within human cells (e.g., cancers). In this context, we present several python packages linked to CellNOptR (R package), which is used to build predictive logic models of signalling networks by training networks (derived from literature) to signalling (phospho-proteomic) data. The first package (cellnopt.wrapper) is a wrapper based on RPY2 that allows a full access to CellNOptR functionalities within Python. The second one (cellnopt.core) was designed to ease the manipulation and visualisation of data structures used in CellNOptR, which was achieved by using Pandas, NetworkX and matplotlib. Systems biology also makes extensive use of web resources and services. We will give an overview and status of BioServices, which allows one to access programmatically to web resources used in life science and how it can be combined with CellNOptR.			arxiv	['Julio Saez-Rodriguez']	198.0
448	Lowering the learning curve for declarative programming: a Python API for the IDP system	Joost Vennekens	2015-11-03 14:21:23	http://arxiv.org/abs/1511.00916v1	Programmers may be hesitant to use declarative systems, because of the associated learning curve. In this paper, we present an API that integrates the IDP Knowledge Base system into the Python programming language. IDP is a state-of-the-art logical system, which uses SAT, SMT, Logic Programming and Answer Set Programming technology. Python is currently one of the most widely used (teaching) languages for programming. The first goal of our API is to allow a Python programmer to use the declarative power of IDP, without needing to learn any new syntax or semantics. The second goal is allow IDP to be added to/removed from an existing code base with minimal changes.			arxiv	[]	199.0
449	PyRIDE: An Interactive Development Environment for PR2 Robot	Xun Wang	2016-05-30 02:40:43	http://arxiv.org/abs/1605.09089v1	Python based Robot Interactive Development Environment (PyRIDE) is a software that supports rapid \textit{interactive} programming of robot skills and behaviours on PR2/ROS (Robot Operating System) platform. One of the key features of PyRIDE is its interactive remotely accessible Python console that allows its users to program robots \textit{online} and in \textit{realtime} in the same way as using the standard Python interactive interpreter. It allows programs to be modified while they are running. PyRIDE is also a software integration framework that abstracts and aggregates disparate low level ROS software modules, e.g. arm joint motor controllers, and exposes their functionalities through a unified Python programming interface. PR2 programmers are able to experiment and develop robot behaviours without dealing with specific details of accessing underlying softwares and hardwares. PyRIDE provides a client-server mechanism that allows remote user access of the robot functionalities, e.g. remote robot monitoring and control, access real-time robot camera image data etc. This enables multi-modal human robot interactions using different devices and user interfaces. All these features are seamlessly integrated into one lightweight and portable middleware package. In this paper, we use four real life scenarios to demonstrate PyRIDE key features and illustrate the usefulness of software.			arxiv	['Mary-Anne Williams']	200.0
450	Massively parallel implementation in Python of a pseudo-spectral DNS code for turbulent flows	Mikael Mortensen	2016-07-01 19:05:11	http://arxiv.org/abs/1607.00850v1	Direct Numerical Simulations (DNS) of the Navier Stokes equations is a valuable research tool in fluid dynamics, but there are very few publicly available codes and, due to heavy number crunching, codes are usually written in low-level languages. In this work a \textasciitilde{}100 line standard scientific Python DNS code is described that nearly matches the performance of pure C for thousands of processors and billions of unknowns. With optimization of a few routines in Cython, it is found to match the performance of a more or less identical solver implemented from scratch in C++. Keys to the efficiency of the solver are the mesh decomposition and three dimensional FFT routines, implemented directly in Python using MPI, wrapped through MPI for Python, and a serial FFT module (both numpy.fft or pyFFTW may be used). Two popular decomposition strategies, slab and pencil, have been implemented and tested.			arxiv	[]	201.0
451	PyTransport: A Python package for the calculation of inflationary correlation functions	David J. Mulryne	2016-09-01 20:00:19	http://arxiv.org/abs/1609.00381v2	PyTransport constitutes a straightforward code written in C++ together with Python scripts which automatically edit, compile and run the C++ code as a Python module. It has been written for Unix-like systems (OS X and Linux). Primarily the module employs the transport approach to inflationary cosmology to calculate the tree-level power-spectrum and bispectrum of user specified models of multi-field inflation, accounting for all sub and super-horizon effects. The transport method we utilise means only coupled differential equations need to be solved, and the implementation presented here combines the speed of C++ with the functionality and convenience of Python. This document details the code and illustrates how to use it with a worked example. It has been updated to be a companion to the second version of the code, PyTransport 2.0, which includes functionality to deal with models of inflation with a curved field space metric.			arxiv	['John W. Ronayne']	202.0
452	A scikit-based Python environment for performing multi-label classification	Piotr Szymański	2017-02-05 22:28:20	http://arxiv.org/abs/1702.01460v5	scikit-multilearn is a Python library for performing multi-label classification. The library is compatible with the scikit/scipy ecosystem and uses sparse matrices for all internal operations. It provides native Python implementations of popular multi-label classification methods alongside a novel framework for label space partitioning and division. It includes modern algorithm adaptation methods, network-based label space division approaches, which extracts label dependency information and multi-label embedding classifiers. It provides python wrapped access to the extensive multi-label method stack from Java libraries and makes it possible to extend deep learning single-label methods for multi-label tasks. The library allows multi-label stratification and data set management. The implementation is more efficient in problem transformation than other established libraries, has good test coverage and follows PEP8. Source code and documentation can be downloaded from http://scikit.ml and also via pip. The library follows BSD licensing scheme.			arxiv	['Tomasz Kajdanowicz']	203.0
453	Hands-on Experience with Gaussian Processes (GPs): Implementing GPs in Python - I	Kshitij Tiwari	2018-09-06 10:19:50	http://arxiv.org/abs/1809.01913v1	This document serves to complement our website which was developed with the aim of exposing the students to Gaussian Processes (GPs). GPs are non-parametric Bayesian regression models that are largely used by statisticians and geospatial data scientists for modeling spatial data. Several open source libraries spanning from Matlab [1], Python [2], R [3] etc., are already available for simple plug-and-use. The objective of this handout and in turn the website was to allow the users to develop stand-alone GPs in Python by relying on minimal external dependencies. To this end, we only use the default python modules and assist the users in developing their own GPs from scratch giving them an in-depth knowledge of what goes on under the hood. The module covers GP inference using maximum likelihood estimation (MLE) and gives examples of 1D (dummy) spatial data.			arxiv	[]	204.0
454	Multiscale finite element calculations in Python using SfePy	Robert Cimrman	2018-10-01 12:41:29	http://arxiv.org/abs/1810.00674v1	SfePy (Simple finite elements in Python) is a software for solving various kinds of problems described by partial differential equations in one, two or three spatial dimensions by the finite element method. Its source code is mostly (85\%) Python and relies on fast vectorized operations provided by the NumPy package. For a particular problem two interfaces can be used: a declarative application programming interface (API), where problem description/definition files (Python modules) are used to define a calculation, and an imperative API, that can be used for interactive commands, or in scripts and libraries. After outlining the SfePy package development, the paper introduces its implementation, structure and general features. The components for defining a partial differential equation are described using an example of a simple heat conduction problem. Specifically, the declarative API of SfePy is presented in the example. To illustrate one of SfePy's main assets, the framework for implementing complex multiscale models based on the theory of homogenization, an example of a two-scale piezoelastic model is presented, showing both the mathematical description of the problem and the corresponding code.			arxiv	['Vladimír Lukeš', 'Eduard Rohan']	205.0
455	DLTPy: Deep Learning Type Inference of Python Function Signatures using Natural Language Context	Casper Boone	2019-12-02 10:55:40	http://arxiv.org/abs/1912.00680v1	Due to the rise of machine learning, Python is an increasingly popular programming language. Python, however, is dynamically typed. Dynamic typing has shown to have drawbacks when a project grows, while at the same time it improves developer productivity. To have the benefits of static typing, combined with high developer productivity, types need to be inferred. In this paper, we present DLTPy: a deep learning type inference solution for the prediction of types in function signatures based on the natural language context (identifier names, comments and return expressions) of a function. We found that DLTPy is effective and has a top-3 F1-score of 91.6%. This means that in most of the cases the correct type is within the top-3 predictions. We conclude that natural language contained in comments and return expressions are beneficial to predicting types more accurately. DLTPy does not significantly outperform or underperform the previous work NL2Type for Javascript, but does show that similar prediction is possible for Python.			arxiv	['Niels de Bruin', 'Arjan Langerak', 'Fabian Stelmach']	206.0
456	CASA 6: Modular Integration in Python	Ryan Raba	2019-12-19 18:09:59	http://arxiv.org/abs/1912.09439v1	CASA, the Common Astronomy Software Applications, is the primary data processing software for the Atacama Large Millimeter/submillimeter Array (ALMA) and the Karl G. Jansky Very Large Array (VLA), and is often used also for other radio telescopes. CASA has always been distributed as a single, integrated application, including a Python interpreter and all the libraries, packages and modules. As part of the ongoing development of CASA 6, and the switch from Python 2 to 3, CASA will provide greater flexibility for users to integrate CASA into existing Python workflows by using a modular architecture and standard pip wheel installation. These proceedings of the 2019 Astronomical Data Analysis Software & Systems (ADASS) conference will give an overview of the CASA 6 project.			arxiv	['Darrell Schiebel', 'Bjorn Emonts', 'Robert Garwood', 'Federico Montesino Pouzols', 'Sandra Castro', 'C. Enrique Garcia-Dabo', 'David Mehringer', 'Ville Suoranta']	207.0
457	Programing Using High Level Design With Python and FORTRAN: A Study Case in Astrophysics	Eduardo dos Santos Pereira	2012-07-16 12:50:30	http://arxiv.org/abs/1207.3658v1	In this work, we present a short review about the high level design methodology (HLDM), that is based on the use of very high level (VHL) programing language as main, and the use of the intermediate level (IL) language only for the critical processing time. The languages used are Python (VHL) and FORTRAN (IL). Moreover, this methodology, making use of the oriented object programing (OOP), permits to produce a readable, portable and reusable code. Also is presented the concept of computational framework, that naturally appears from the OOP paradigm. As an example, we present the framework called PYGRAWC (Python framework for Gravitational Waves from Cosmological origin). Even more, we show that the use of HLDM with Python and FORTRAN produces a powerful tool for solving astrophysical problems.			arxiv	['Oswaldo D. Miranda']	208.0
458	Parallel Astronomical Data Processing with Python: Recipes for multicore machines	Navtej Singh	2013-06-03 20:00:04	http://arxiv.org/abs/1306.0573v1	High performance computing has been used in various fields of astrophysical research. But most of it is implemented on massively parallel systems (supercomputers) or graphical processing unit clusters. With the advent of multicore processors in the last decade, many serial software codes have been re-implemented in parallel mode to utilize the full potential of these processors. In this paper, we propose parallel processing recipes for multicore machines for astronomical data processing. The target audience are astronomers who are using Python as their preferred scripting language and who may be using PyRAF/IRAF for data processing. Three problems of varied complexity were benchmarked on three different types of multicore processors to demonstrate the benefits, in terms of execution time, of parallelizing data processing tasks. The native multiprocessing module available in Python makes it a relatively trivial task to implement the parallel code. We have also compared the three multiprocessing approaches - Pool/Map, Process/Queue, and Parallel Python. Our test codes are freely available and can be downloaded from our website.			arxiv	['Lisa-Marie Browne', 'Ray Butler']	209.0
459	Pycobra: A Python Toolbox for Ensemble Learning and Visualisation	Benjamin Guedj	2017-04-25 14:05:34	http://arxiv.org/abs/1707.00558v3	We introduce \texttt{pycobra}, a Python library devoted to ensemble learning (regression and classification) and visualisation. Its main assets are the implementation of several ensemble learning algorithms, a flexible and generic interface to compare and blend any existing machine learning algorithm available in Python libraries (as long as a \texttt{predict} method is given), and visualisation tools such as Voronoi tessellations. \texttt{pycobra} is fully \texttt{scikit-learn} compatible and is released under the MIT open-source license. \texttt{pycobra} can be downloaded from the Python Package Index (PyPi) and Machine Learning Open Source Software (MLOSS). The current version (along with Jupyter notebooks, extensive documentation, and continuous integration tests) is available at \href{https://github.com/bhargavvader/pycobra}{https://github.com/bhargavvader/pycobra} and official documentation website is \href{https://modal.lille.inria.fr/pycobra}{https://modal.lille.inria.fr/pycobra}.			arxiv	['Bhargav Srinivasa Desikan']	210.0
460	Python Non-Uniform Fast Fourier Transform (PyNUFFT): multi-dimensional non-Cartesian image reconstruction package for heterogeneous platforms and applications to MRI	Jyh-Miin Lin	2017-10-09 17:12:46	http://arxiv.org/abs/1710.03197v1	This paper reports the development of a Python Non-Uniform Fast Fourier Transform (PyNUFFT) package, which accelerates non-Cartesian image reconstruction on heterogeneous platforms. Scientific computing with Python encompasses a mature and integrated environment. The NUFFT algorithm has been extensively used for non-Cartesian image reconstruction but previously there was no native Python NUFFT library. The current PyNUFFT software enables multi-dimensional NUFFT on heterogeneous platforms. The PyNUFFT also provides several solvers, including the conjugate gradient method, $\ell$1 total-variation regularized ordinary least square (L1TV-OLS) and $\ell$1 total-variation regularized least absolute deviation (L1TV-LAD). Metaprogramming libraries were employed to accelerate PyNUFFT. The PyNUFFT package has been tested on multi-core CPU and GPU, with acceleration factors of 6.3 - 9.5$\times$ on a 32 thread CPU platform and 5.4 - 13$\times$ on the GPU.			arxiv	[]	211.0
461	MPDAF - A Python package for the analysis of VLT/MUSE data	Laure Piqueras	2017-10-10 13:03:12	http://arxiv.org/abs/1710.03554v1	MUSE (Multi Unit Spectroscopic Explorer) is an integral-field spectrograph mounted on the Very Large Telescope (VLT) in Chile and made available to the European community since October 2014. The Centre de Recherche Astrophysique de Lyon has developed a dedicated software to help MUSE users analyze the reduced data. In this paper we introduce MPDAF, the MUSE Python Data Analysis Framework, based on several well-known Python libraries (Numpy, Scipy, Matplotlib, Astropy) which offers new tools to manipulate MUSE-specific data. We present different examples showing how this Python package may be useful for MUSE data analysis.			arxiv	['Simon Conseil', 'Martin Shepherd', 'Roland Bacon', 'Floriane Leclercq', 'Johan Richard']	212.0
462	On the Worst-Case Complexity of TimSort	Nicolas Auger	2018-05-22 14:27:38	http://arxiv.org/abs/1805.08612v3	TimSort is an intriguing sorting algorithm designed in 2002 for Python, whose worst-case complexity was announced, but not proved until our recent preprint. In fact, there are two slightly different versions of TimSort that are currently implemented in Python and in Java respectively. We propose a pedagogical and insightful proof that the Python version runs in $\mathcal{O}(n\log n)$. The approach we use in the analysis also applies to the Java version, although not without very involved technical details. As a byproduct of our study, we uncover a bug in the Java implementation that can cause the sorting method to fail during the execution. We also give a proof that Python's TimSort running time is in $\mathcal{O}(n + n\log \rho)$, where $\rho$ is the number of runs (i.e. maximal monotonic sequences), which is quite a natural parameter here and part of the explanation for the good behavior of TimSort on partially sorted inputs.			arxiv	['Vincent Jugé', 'Cyril Nicaud', 'Carine Pivoteau']	213.0
463	unyt: Handle, manipulate, and convert data with units in Python	Nathan J. Goldbaum	2018-06-06 20:43:01	http://arxiv.org/abs/1806.02417v3	Software that processes real-world data or that models a physical system must have some way of managing units. While simple approaches like the understood convention that all data are in a unit system (such as the MKS SI unit system) do work in practice, they are fraught with possible sources of error both by developers and users of the software. In this paper we present unyt, a Python library based on NumPy and SymPy for handling data that has units. It is designed both to aid quick interactive calculations and to be tightly integrated into a larger Python application or library. We compare unyt with two other Python libraries for handling units, Pint and astropy.units, and find that unyt is faster, has higher test coverage, and has fewer lines of code.			arxiv	['John A. ZuHone', 'Matthew J. Turk', 'Kacper Kowalik', 'Anna L. Rosen']	214.0
464	Pykg2vec: A Python Library for Knowledge Graph Embedding	Shih Yuan Yu	2019-06-04 04:22:32	http://arxiv.org/abs/1906.04239v1	Pykg2vec is an open-source Python library for learning the representations of the entities and relations in knowledge graphs. Pykg2vec's flexible and modular software architecture currently implements 16 state-of-the-art knowledge graph embedding algorithms, and is designed to easily incorporate new algorithms. The goal of pykg2vec is to provide a practical and educational platform to accelerate research in knowledge graph representation learning. Pykg2vec is built on top of TensorFlow and Python's multiprocessing framework and provides modules for batch generation, Bayesian hyperparameter optimization, mean rank evaluation, embedding, and result visualization. Pykg2vec is released under the MIT License and is also available in the Python Package Index (PyPI). The source code of pykg2vec is available at https://github.com/Sujit-O/pykg2vec.			arxiv	['Sujit Rokka Chhetri', 'Arquimedes Canedo', 'Palash Goyal', 'Mohammad Abdullah Al Faruque']	215.0
465	AutoGMM: Automatic and Hierarchical Gaussian Mixture Modeling in Python	Thomas L. Athey	2019-09-06 01:45:27	http://arxiv.org/abs/1909.02688v5	Background: Gaussian mixture modeling is a fundamental tool in clustering, as well as discriminant analysis and semiparametric density estimation. However, estimating the optimal model for any given number of components is an NP-hard problem, and estimating the number of components is in some respects an even harder problem. Findings: In R, a popular package called mclust addresses both of these problems. However, Python has lacked such a package. We therefore introduce AutoGMM, a Python algorithm for automatic Gaussian mixture modeling, and its hierarchical version, HGMM. AutoGMM builds upon scikit-learn's AgglomerativeClustering and GaussianMixture classes, with certain modifications to make the results more stable. Empirically, on several different applications, AutoGMM performs approximately as well as mclust, and sometimes better. Conclusions: AutoMM, a freely available Python package, enables efficient Gaussian mixture modeling by automatically selecting the initialization, number of clusters and covariance constraints.			arxiv	['Tingshan Liu', 'Benjamin D. Pedigo', 'Joshua T. Vogelstein']	216.0
466	GIMP-ML: Python Plugins for using Computer Vision Models in GIMP	Kritik Soman	2020-04-27 18:00:37	http://arxiv.org/abs/2004.13060v3	This paper introduces GIMP-ML v1.1, a set of Python plugins for the widely popular GNU Image Manipulation Program (GIMP). It enables the use of recent advances in computer vision to the conventional image editing pipeline. Applications from deep learning such as monocular depth estimation, semantic segmentation, mask generative adversarial networks, image super-resolution, de-noising, de-hazing, matting, enlightening and coloring have been incorporated with GIMP through Python-based plugins. Additionally, operations on images such as k-means based color clustering have also been added. GIMP-ML relies on standard Python packages such as numpy, pytorch, open-cv, scipy. Apart from these, several image manipulation techniques using these plugins have been compiled and demonstrated in the YouTube channel (https://youtube.com/user/kritiksoman) with the objective of demonstrating the use-cases for machine learning based image modification. In addition, GIMP-ML also aims to bring the benefits of using deep learning networks used for computer vision tasks to routine image processing workflows. The code and installation procedure for configuring these plugins is available at https://github.com/kritiksoman/GIMP-ML.			arxiv	[]	217.0
467	PyMT5: multi-mode translation of natural language and Python code with transformers	Colin B. Clement	2020-10-07 04:10:58	http://arxiv.org/abs/2010.03150v1	Simultaneously modeling source code and natural language has many exciting applications in automated software development and understanding. Pursuant to achieving such technology, we introduce PyMT5, the Python method text-to-text transfer transformer, which is trained to translate between all pairs of Python method feature combinations: a single model that can both predict whole methods from natural language documentation strings (docstrings) and summarize code into docstrings of any common style. We present an analysis and modeling effort of a large-scale parallel corpus of 26 million Python methods and 7.7 million method-docstring pairs, demonstrating that for docstring and method generation, PyMT5 outperforms similarly-sized auto-regressive language models (GPT2) which were English pre-trained or randomly initialized. On the CodeSearchNet test set, our best model predicts 92.1% syntactically correct method bodies, achieved a BLEU score of 8.59 for method generation and 16.3 for docstring generation (summarization), and achieved a ROUGE-L F-score of 24.8 for method generation and 36.7 for docstring generation.			arxiv	['Dawn Drain', 'Jonathan Timcheck', 'Alexey Svyatkovskiy', 'Neel Sundaresan']	218.0
468	Advanced Python Performance Monitoring with Score-P	Andreas Gocht	2020-10-29 09:35:50	http://arxiv.org/abs/2010.15444v2	Within the last years, Python became more prominent in the scientific community and is now used for simulations, machine learning, and data analysis. All these tasks profit from additional compute power offered by parallelism and offloading. In the domain of High Performance Computing (HPC), we can look back to decades of experience exploiting different levels of parallelism on the core, node or inter-node level, as well as utilising accelerators. By using performance analysis tools to investigate all these levels of parallelism, we can tune applications for unprecedented performance. Unfortunately, standard Python performance analysis tools cannot cope with highly parallel programs. Since the development of such software is complex and error-prone, we demonstrate an easy-to-use solution based on an existing tool infrastructure for performance analysis. In this paper, we describe how to apply the established instrumentation framework \scorep to trace Python applications. We finish with a study of the overhead that users can expect for instrumenting their applications.			arxiv	['Robert Schöne', 'Jan Frenzel']	219.0
469	PyOD: A Python Toolbox for Scalable Outlier Detection	Yue Zhao	2019-01-06 18:29:35	http://arxiv.org/abs/1901.01588v2	PyOD is an open-source Python toolbox for performing scalable outlier detection on multivariate data. Uniquely, it provides access to a wide range of outlier detection algorithms, including established outlier ensembles and more recent neural network-based approaches, under a single, well-documented API designed for use by both practitioners and researchers. With robustness and scalability in mind, best practices such as unit testing, continuous integration, code coverage, maintainability checks, interactive examples and parallelization are emphasized as core components in the toolbox's development. PyOD is compatible with both Python 2 and 3 and can be installed through Python Package Index (PyPI) or https://github.com/yzhao062/pyod.			arxiv	['Zain Nasrullah', 'Zheng Li']	220.0
470	Some remarks on the performance of Matlab, Python and Octave in simulating dynamical systems	P. F. S. Guedes	2019-10-14 12:59:45	http://arxiv.org/abs/1910.06117v1	Matlab has been considered as a leader computational platform for many engineering fields. Well documented and reliable, Matlab presents as a great advantage its ability to increase the user productivity. However, Python and Octave are among some of the languages that have challenged Matlab. Octave and Python are well known examples of high-level scripting languages, with a great advantage of being open source software. The novelty of this paper is devoted to offer a comparison among these tree languages in the simulation of dynamical systems. We have applied the lower bound error to estimate the error of simulation. The comparison was performed with the chaotic systems Duffing-Ueda oscillator and the Chua's circuit, both identified with polynomial NARMAX. Octave presents the best reliable outcome. Nevertheless, Matlab needs the lowest time to undertake the same activity. Python has presented the worse result for the stop simulation criterion.			arxiv	['E. G. Nepomuceno']	221.0
471	Automated Unit Test Generation for Python	Stephan Lukasczyk	2020-07-28 08:12:23	http://arxiv.org/abs/2007.14049v1	Automated unit test generation is an established research field, and mature test generation tools exist for statically typed programming languages such as Java. It is, however, substantially more difficult to automatically generate supportive tests for dynamically typed programming languages such as Python, due to the lack of type information and the dynamic nature of the language. In this paper, we describe a foray into the problem of unit test generation for dynamically typed languages. We introduce Pynguin, an automated unit test generation framework for Python. Using Pynguin, we aim to empirically shed light on two central questions: (1) Do well-established search-based test generation methods, previously evaluated only on statically typed languages, generalise to dynamically typed languages? (2) What is the influence of incomplete type information and dynamic typing on the problem of automated test generation? Our experiments confirm that evolutionary algorithms can outperform random test generation also in the context of Python, and can even alleviate the problem of absent type information to some degree. However, our results demonstrate that dynamic typing nevertheless poses a fundamental issue for test generation, suggesting future work on integrating type inference.			arxiv	['Florian Kroiß', 'Gordon Fraser']	222.0
472	I Know What You Imported Last Summer: A study of security threats in thePython ecosystem	Aadesh Bagmar	2021-02-11 22:46:17	http://arxiv.org/abs/2102.06301v1	The popularity of Python has risen rapidly over the past 15 years. It is a major language in some of the most exciting technologies today. This popularity has led to a large ecosystem of third-party packages available via the pip package registry which hosts more than 200,000 packages. These third-party packages can be reused by simply importing the package after installing using package managers like pip. The ease of reuse of third-party software comes with security risks putting millions of users in danger. In this project, we study the ecosystem to analyze this threat. The mature ecosystem of Python has multiple weak spots that we highlight in our project. First, we demonstrate how trivial it is to exploit the Python ecosystem. Then, we systematically analyze dependencies amongst packages, maintainers, and publicly reported security issues. Most attacks are possible only if users install malicious packages. We thus try to analyze and evaluate different methods used by attackers to force incorrect downloads. We quantify your ideas by estimating the potential threat that can be caused by exploiting a popular Python package. We also discuss methods used in the industry to defend against such attacks			arxiv	['Josiah Wedgwood', 'Dave Levin', 'Jim Purtilo']	223.0
473	Social Network Analysis: From Graph Theory to Applications with Python	Dmitri Goldenberg	2021-02-05 18:46:02	http://arxiv.org/abs/2102.10014v1	Social network analysis is the process of investigating social structures through the use of networks and graph theory. It combines a variety of techniques for analyzing the structure of social networks as well as theories that aim at explaining the underlying dynamics and patterns observed in these structures. It is an inherently interdisciplinary field which originally emerged from the fields of social psychology, statistics and graph theory. This talk will covers the theory of social network analysis, with a short introduction to graph theory and information spread. Then we will deep dive into Python code with NetworkX to get a better understanding of the network components, followed-up by constructing and implying social networks from real Pandas and textual datasets. Finally we will go over code examples of practical use-cases such as visualization with matplotlib, social-centrality analysis and influence maximization for information spread.			arxiv	[]	224.0
474	ManyTypes4Py: A Benchmark Python Dataset for Machine Learning-based Type Inference	Amir M. Mir	2021-04-10 08:10:06	http://arxiv.org/abs/2104.04706v1	In this paper, we present ManyTypes4Py, a large Python dataset for machine learning (ML)-based type inference. The dataset contains a total of 5,382 Python projects with more than 869K type annotations. Duplicate source code files were removed to eliminate the negative effect of the duplication bias. To facilitate training and evaluation of ML models, the dataset was split into training, validation and test sets by files. To extract type information from abstract syntax trees (ASTs), a lightweight static analyzer pipeline is developed and accompanied with the dataset. Using this pipeline, the collected Python projects were analyzed and the results of the AST analysis were stored in JSON-formatted files. The ManyTypes4Py dataset is shared on zenodo and its tools are publicly available on GitHub.			arxiv	['Evaldas Latoskinas', 'Georgios Gousios']	225.0
475	Catalogs of C and Python Antipatterns by CS1 Students	Yorah Bosse	2021-04-02 02:12:41	http://arxiv.org/abs/2104.12542v1	Understanding students' programming misconceptions is critical. Doing so depends on identifying the reasons why students make errors when learning a new programming language. Knowing the misconceptions can help students to improve their reflection about their mistakes and also help instructors to design better teaching strategies. In this technical report, we propose catalogs of antipatterns for two programming languages: C and Python. To accomplish this, we analyzed the codes of 166 CS1 engineering students when they were coding solutions to programming exercises. In our results, we catalog 41 CS1 antipatterns from 95 cataloged misconceptions in C and Python. These antipatterns were separated into three catalogs: C, Python, and antipatterns found in code using both programming languages. For each antipattern, we present code examples, students' solutions (if they are present), a possible solution to avoid the antipattern, among other information.			arxiv	['Igor Scaliante Wiese', 'Marco Aurélio Graciotto Silva', 'Nelson Lago', 'Leônidas de Oliveira Brandão', 'David Redmiles', 'Fabio Kon', 'Marco A. Gerosa']	226.0
476	GGCHEMPY: A pure Python-based gas-grain chemical code for efficient simulation of interstellar chemistry	Jixing Ge	2021-10-21 13:05:49	http://arxiv.org/abs/2110.11117v1	In this paper, we present a new gas-grain chemical code for interstellar clouds written in pure Python (GGCHEMPY). By combining with the high-performance Python compiler Numba, GGCHEMPY is as efficient as the Fortran-based version. With the Python features, flexible computational workflows and extensions become possible. As a showcase, GGCHEMPY is applied to study the general effects of three-dimensional projection on molecular distributions using a two-core system which can be easily extended for more complex cases. By comparing the molecular distribution differences between two overlapping cores and two merging cores, we summarized the typical chemical differences such as, N2H+, HC3N, C2S, H2CO, HCN and C2H, which can be used to interpret 3-D structures in molecular clouds.			arxiv	[]	227.0
477	Performance Evaluation of Python Parallel Programming Models: Charm4Py and mpi4py	Zane Fink	2021-11-08 23:32:39	http://arxiv.org/abs/2111.04872v2	Python is rapidly becoming the lingua franca of machine learning and scientific computing. With the broad use of frameworks such as Numpy, SciPy, and TensorFlow, scientific computing and machine learning are seeing a productivity boost on systems without a requisite loss in performance. While high-performance libraries often provide adequate performance within a node, distributed computing is required to scale Python across nodes and make it genuinely competitive in large-scale high-performance computing. Many frameworks, such as Charm4Py, DaCe, Dask, Legate Numpy, mpi4py, and Ray, scale Python across nodes. However, little is known about these frameworks' relative strengths and weaknesses, leaving practitioners and scientists without enough information about which frameworks are suitable for their requirements. In this paper, we seek to narrow this knowledge gap by studying the relative performance of two such frameworks: Charm4Py and mpi4py. We perform a comparative performance analysis of Charm4Py and mpi4py using CPU and GPU-based microbenchmarks other representative mini-apps for scientific computing.			arxiv	['Simeng Liu', 'Jaemin Choi', 'Matthias Diener', 'Laxmikant V. Kale']	228.0
478	PyHHMM: A Python Library for Heterogeneous Hidden Markov Models	Fernando Moreno-Pino	2022-01-12 07:32:36	http://arxiv.org/abs/2201.06968v1	We introduce PyHHMM, an object-oriented open-source Python implementation of Heterogeneous-Hidden Markov Models (HHMMs). In addition to HMM's basic core functionalities, such as different initialization algorithms and classical observations models, i.e., continuous and multinoulli, PyHHMM distinctively emphasizes features not supported in similar available frameworks: a heterogeneous observation model, missing data inference, different model order selection criterias, and semi-supervised training. These characteristics result in a feature-rich implementation for researchers working with sequential data. PyHHMM relies on the numpy, scipy, scikit-learn, and seaborn Python packages, and is distributed under the Apache-2.0 License. PyHHMM's source code is publicly available on Github (https://github.com/fmorenopino/HeterogeneousHMM) to facilitate adoptions and future contributions. A detailed documentation (https://pyhhmm.readthedocs.io/en/latest), which covers examples of use and models' theoretical explanation, is available. The package can be installed through the Python Package Index (PyPI), via 'pip install pyhhmm'.			arxiv	['Emese Sükei', 'Pablo M. Olmos', 'Antonio Artés-Rodríguez']	229.0
479	SBMLDiagrams: A python package to process and visualize SBML layout and render	Jin Xu	2022-04-26 22:01:35	http://arxiv.org/abs/2204.12611v2	Summary: The Systems Biology Markup Language (SBML) is an extensible standard format for exchanging biochemical models. One of the extensions for SBML is the SBML Layout and Render package. This allows modelers to describe a biochemical model as a pathway diagram. However, up to now there has been little support to help users easily add and retrieve such information from SBML. In this application note, we describe a new Python package called SBMLDiagrams. This package allows a user to add layout and render information or retrieve it using a straightforward Python API. The package uses skia-python to support the rendering of the diagrams, allowing export to commons formats such as PNG or PDF. Availability: SBMLDiagrams is publicly available and licensed under the liberal MIT open-source license. The package is available for all major platforms. The source code has been deposited at GitHub (github.com/sys-bio/SBMLDiagrams). Users can install the package using the standard pip installation mechanism: pip install SBMLDiagrams. Contact: hsauro@uw.edu.			arxiv	['Jessie Jiang', 'Herbert M. Sauro']	230.0
480	LabVIEW is faster and C is economical interfacing tool for UCT automation	Ankur Kumar	2022-05-17 12:00:25	http://arxiv.org/abs/2205.08260v1	An in-house developed 2D ultrasound computerized Tomography system is fully automated. Performance analysis of instrument and software interfacing soft tools, namely the LabVIEW, MATLAB, C, and Python, is presented. The instrument interfacing algorithms, hardware control algorithms, signal processing, and analysis codes are written using above mentioned soft tool platforms. Total of eight performance indices are used to compare the ease of (a) realtime control of electromechanical assembly, (b) sensors, instruments integration, (c) synchronized data acquisition, and (d) simultaneous raw data processing. It is found that C utilizes the least processing power and performs a lower number of processes to perform the same task. In runtime analysis (data acquisition and realtime control), LabVIEW performs best, taking 365.69s in comparison to MATLAB (623.83s), Python ( 1505.54s), and C (1252.03s) to complete the experiment. Python performs better in establishing faster interfacing and minimum RAM usage. LabVIEW is recommended for its fast process execution. C is recommended for the most economical implementation. Python is recommended for complex system automation having a very large number of components involved. This article provides a methodology to select optimal soft tools for instrument automation-related aspects.			arxiv	['Mayank Goswami']	231.0
481	atoMEC: An open-source average-atom Python code	Timothy J. Callow	2022-06-02 14:41:22	http://arxiv.org/abs/2206.01074v2	Average-atom models are an important tool in studying matter under extreme conditions, such as those conditions experienced in planetary cores, brown and white dwarfs, and during inertial confinement fusion. In the right context, average-atom models can yield results with similar accuracy to simulations which require orders of magnitude more computing time, and thus can greatly reduce financial and environmental costs. Unfortunately, due to the wide range of possible models and approximations, and the lack of open-source codes, average-atom models can at times appear inaccessible. In this paper, we present our open-source average-atom code, atoMEC. We explain the aims and structure of atoMEC to illuminate the different stages and options in an average-atom calculation, and to facilitate community contributions. We also discuss the use of various open-source Python packages in atoMEC, which have expedited its development.			arxiv	['Daniel Kotik', 'Eli Kraisler', 'Attila Cangi']	232.0
482	Pychastic: Precise Brownian Dynamics using Taylor-Itō integrators in Python	Radost Waszkiewicz	2022-09-09 14:43:37	http://arxiv.org/abs/2209.04332v2	In the last decade, Python-powered physics simulations ecosystem has been growing steadily, allowing greater interoperability, and becoming an important tool in numerical exploration of physical phenomena, particularly in soft matter systems. Driven by the need for fast and precise numerical integration in colloidal dynamics, here we formulate the problem of Brownian Dynamics (BD) in a mathematically consistent formalism of the It\=o calculus, and develop a Python package to assist numerical computations. We show that, thanks to the automatic differentiation packages, the classical truncated Taylor-It\=o integrators can be implemented without the burden of computing the derivatives of the coefficient functions beforehand. Furthermore, we show how to circumvent the difficulties of BD simulations such as calculations of the divergence of the mobility tensor in the diffusion equation and discontinuous trajectories encountered when working with dynamics on $S^2$ and $SO(3)$. The resulting Python package, Pychastic, is capable of performing BD simulations including hydrodynamic interactions at speeds comparable to dedicated implementations in lower-level programming languages, but with a much simpler end-user interface.			arxiv	['Maciej Bartczak', 'Kamil Kolasa', 'Maciej Lisicki']	233.0
483	Repairing Bugs in Python Assignments Using Large Language Models	Jialu Zhang	2022-09-29 15:41:17	http://arxiv.org/abs/2209.14876v1	Students often make mistakes on their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex, to build an APR system -- MMAPR -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate MMAPR on 286 real student programs and compare to a baseline built by combining a state-of-the-art Python syntax repair engine, BIFI, and state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that MMAPR can fix more programs and produce smaller patches on average.			arxiv	['José Cambronero', 'Sumit Gulwani', 'Vu Le', 'Ruzica Piskac', 'Gustavo Soares', 'Gust Verbruggen']	234.0
484	Comparing neural network training performance between Elixir and Python	Lucas C. Tavano	2022-10-25 11:57:14	http://arxiv.org/abs/2210.13945v1	With a wide range of libraries focused on the machine learning market, such as TensorFlow, NumPy, Pandas, Keras, and others, Python has made a name for itself as one of the main programming languages. In February 2021, Jos\'e Valim and Sean Moriarity published the first version of the Numerical Elixir (Nx) library, a library for tensor operations written in Elixir. Nx aims to allow the language be a good choice for GPU-intensive operations. This work aims to compare the results of Python and Elixir on training convolutional neural networks (CNN) using MNIST and CIFAR-10 datasets, concluding that Python achieved overall better results, and that Elixir is already a viable alternative.			arxiv	['Lucas K. Amin', 'Adolfo Gustavo Serra-Seca-Neto']	235.0
485	Excel Spreadsheet Analyzer	Amir Nassereldine	2022-11-01 20:35:13	http://arxiv.org/abs/2211.06333v1	Spreadsheets are widely used in various fields to do large numerical analysis. While several companies have relied on spreadsheets for decades, data scientists are going in the direction of using scientific programming languages such as python to do their data analysis due to the support, community, and vast amount of libraries. While using python to analyze a company's spreadsheets, some information such as the formulas and dependencies of a cell are lost. We propose a tool that creates an abstract intermediate representation (AIR) of a spreadsheet. This representation facilitates the transfer from spreadsheets into scientific programming languages while preserving inter-dependency information about data. In addition to that, we build a python library on top of our tool to perform some data analysis in python.			arxiv	['Patrick Chen', 'Jinjun Xiong']	236.0
486	Visualizing Contributor Code Competency for PyPI Libraries: Preliminary Results	Indira Febriyanti	2022-12-04 17:48:52	http://arxiv.org/abs/2212.01882v1	Python is known to be used by beginners to professional programmers. Python provides functionality to its community of users through PyPI libraries, which allows developers to reuse functionalities to an application. However, it is unknown the extent to which these PyPI libraries require proficient code in their implementation. We conjecture that PyPI contributors may decide to implement more advanced Pythonic code, or stick with more basic Python code. Are complex codes only committed by few contributors, or only to specific files? The new idea in this paper is to confirm who and where complex code is implemented. Hence, we present a visualization to show the relationship between proficient code, contributors, and files. Analyzing four PyPI projects, we are able to explore which files contain more elegant code, and which contributors committed to these files. Our results show that most files contain more basic competency files, and that not every contributor contributes competent code. We show how~our visualization is able to summarize such information, and opens up different possibilities for understanding how to make elegant contributions.			arxiv	['Raula Gaikovina Kula', 'Ruksit Rojpaisarnkit', 'Kanchanok Kannee', 'Yusuf Sulistyo Nugroho', 'Kenichi Matsumoto']	237.0
487	Optimization of the Analysis of Vital Events Using Threads	Rubi Melania Coasaca Callacondo	2023-01-04 17:16:07	http://arxiv.org/abs/2301.01710v1	Objective: Optimize the time of data analysis of Vital Events (births, deaths and marriages) using Threads. Methodology: A code was created in python without threads and another with threads, after He performed 5 tests with a single attribute and with 1,2,3,4,5,6,7,8 and 9 attributes this was done in both codes with the same amount of data, to know if the python code with threads is optimal when parsing Vital Facts data. Results: The python code with Threads turned out to be the most optimal since it optimized the compilation time of the 5 tests with 1 attribute by 16attributes was obtained as a result that the more attributes you group, the more effective the use of threads. Conclusion: Python code with threads is more optimal than code without threads Therefore, it is concluded that the implementation of threads is recommended in the analysis of data in similar works.			arxiv	['Grylia Yaneth Chata Iscarra', 'Fred Torres-Cruz']	238.0
488	Photochemical and RadiatiOn Transport model for Extensive USe (PROTEUS)	Yuki Nakamura	2023-01-06 08:14:44	http://arxiv.org/abs/2301.02415v1	We introduce a new flexible one-dimensional photochemical model named Photochemical and RadiatiOn Transport model for Extensive USe (PROTEUS), which consists of a Python graphical user interface (GUI) program and Fortran 90 modules. PROTEUS is designed for adaptability to many planetary atmospheres, for flexibility to deal with thousands of or more chemical reactions with high efficiency, and for intuitive operation with GUI. Chemical reactions can be easily implemented into the Python GUI program in a simple string format, and users can intuitively select a planet and chemical reactions on GUI. Chemical reactions selected on GUI are automatically analyzed by string parsing functions in the Python GUI program, then applied to the Fortran 90 modules to simulate with the selected chemical reactions on a selected planet. PROTEUS can significantly save the time for those who need to develop a new photochemical model; users just need to write chemical reactions in the Python GUI program and just select them on GUI to run a new photochemical model.			arxiv	['Naoki Terada', 'Shungo Koyama', 'Tatsuya Yoshida', 'Hiroki Karyu', 'Kaori Terada', 'Takeshi Kuroda', 'Arihiro Kamada', 'Isao Murata', 'Shotaro Sakai', 'Yuhei Suzuki', 'Mirai Kobayashi', 'François Leblanc']	239.0
489	Landscape of High-performance Python to Develop Data Science and Machine Learning Applications	Oscar Castro	2023-02-07 07:56:21	http://arxiv.org/abs/2302.03307v2	Python has become the prime language for application development in the Data Science and Machine Learning domains. However, data scientists are not necessarily experienced programmers. While Python lets them quickly implement their algorithms, when moving at scale, computation efficiency becomes inevitable. Thus, harnessing high-performance devices such as multicore processors and Graphical Processing Units (GPUs) to their potential is generally not trivial. The present narrative survey was thought as a reference document for such practitioners to help them make their way in the wealth of tools and techniques available for the Python language. Our document revolves around user scenarios, which are meant to cover most situations they may face. We believe that this document may also be of practical use to tool developers, who may use our work to identify potential lacks in existing tools and help them motivate their contributions.			arxiv	['Pierrick Bruneau', 'Jean-Sébastien Sottet', 'Dario Torregrossa']	240.0
490	PNet: A Python Library for Petri Net Modeling and Simulation	Zhu En Chay	2023-02-23 14:27:50	http://arxiv.org/abs/2302.12054v1	Petri Net is a formalism to describe changes between 2 or more states across discrete time and has been used to model many systems. We present PNet - a pure Python library for Petri Net modeling and simulation in Python programming language. The design of PNet focuses on reducing the learning curve needed to define a Petri Net by using a text-based language rather than programming constructs to define transition rules. Complex transition rules can be refined as regular Python functions. To demonstrate the simplicity of PNet, we present 2 examples - bread baking, and epidemiological models.			arxiv	['Bing Feng Goh', 'Maurice HT Ling']	241.0
491	Method Chaining Redux: An Empirical Study of Method Chaining in Java, Kotlin, and Python	Ali M. Keshk	2023-03-20 16:54:05	http://arxiv.org/abs/2303.11269v1	There are possible benefits and drawbacks to chaining methods together, as is often done in fluent APIs. A prior study investigated how Java developers chain methods in over 2.7k open-source projects. That study observed, for the dataset analyzed, that the use of method chaining in Java is popular and seems to be increasing over time. That study however was limited to a smaller sample of Java projects, and it is also not clear if the results generalize to other languages. In this work, we first replicate the prior results by building a similar dataset and our own analysis scripts. We then extend those results by analyzing a much larger dataset of 89k Java projects and generalizing to other programming languages by analyzing 26k Kotlin projects and 98k Python projects. The results show chaining is more popular in Java and Kotlin than Python, chaining use in Kotlin is not growing, and Python sees more use in non-testing code.			arxiv	['Robert Dyer']	242.0
492	Development of MC/DC: a performant, scalable, and portable Python-based Monte Carlo neutron transport code	Ilham Variansyah	2023-05-12 17:42:52	http://arxiv.org/abs/2305.07636v1	We discuss the current development of MC/DC (Monte Carlo Dynamic Code). MC/DC is primarily designed to serve as an exploratory Python-based MC transport code. However, it seeks to offer improved performance, massive scalability, and backend portability by leveraging Python code-generation libraries and implementing an innovative abstraction strategy and compilation scheme. Here, we verify MC/DC capabilities and perform an initial performance assessment. We found that MC/DC can run hundreds of times faster than its pure Python mode and about 2.5 times slower, but with comparable parallel scaling, than the high-performance MC code Shift for simple problems. Finally, to further exercise MC/DC's time-dependent MC transport capabilities, we propose a challenge problem based on the C5G7-TD benchmark model.			arxiv	['J. P. Morgan', 'Jordan Northrop', 'Kyle E. Niemeyer', 'Ryan G. McClarren']	243.0
493	Exponential Integrators for Phase-Field Equations using Pseudo-spectral Methods: A Python Implementation	Elvis do A. Soares	2023-05-15 20:27:18	http://arxiv.org/abs/2305.08998v1	In this paper, we implement exponential integrators, specifically Integrating Factor (IF) and Exponential Time Differencing (ETD) methods, using pseudo-spectral techniques to solve phase-field equations within a Python framework. These exponential integrators have showcased robust performance and accuracy when addressing stiff nonlinear partial differential equations. We compare these integrators to the well-known implicit-explicit (IMEX) Euler integrators used in phase-field modeling. The synergy between pseudo-spectral techniques and exponential integrators yields significant benefits for modeling intricate systems governed by phase-field dynamics, such as solidification processes and pattern formation. Our comprehensive Python implementation illustrates the effectiveness of this combined approach in solving phase-field model equations. The results obtained from this implementation highlight the accuracy and computational advantages of the ETD method compared to other numerical techniques.			arxiv	['Amaro G. Barreto Jr.', 'Frederico W. Tavares']	244.0
494	Pyqcm: An open-source Python library for quantum cluster methods	Théo N. Dionne	2023-05-29 22:37:01	http://arxiv.org/abs/2305.18643v2	Pyqcm is a Python/C++ library that implements a few quantum cluster methods with an exact diagonalization impurity solver. Quantum cluster methods are used in the study of strongly correlated electrons to provide an approximate solution to Hubbard-like models. The methods covered by this library are Cluster Perturbation Theory (CPT), the Variational Cluster Approach (VCA) and Cellular (or Cluster) Dynamical Mean Field Theory (CDMFT). The impurity solver (the technique used to compute the cluster's interacting Green function) is exact diagonalization from sparse matrices, using the Lanczos algorithm and variants thereof. The core library is written in C++ for performance, but the interface is in Python, for ease of use and inter-operability with the numerical Python ecosystem. The library is distributed under the GPL license.			arxiv	['Alexandre Foley', 'Moïse Rousseau', 'David Sénéchal']	245.0
495	DeepOnto: A Python Package for Ontology Engineering with Deep Learning	Yuan He	2023-07-06 15:35:02	http://arxiv.org/abs/2307.03067v1	"Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more ""Pythonic"" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning methodologies, primarily pre-trained LMs. In this paper, we also demonstrate the practical utility of Deeponto through two use-cases: the Digital Health Coaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment Evaluation Initiative (OAEI)."			arxiv	['Jiaoyan Chen', 'Hang Dong', 'Ian Horrocks', 'Carlo Allocca', 'Taehun Kim', 'Brahmananda Sapkota']	246.0
496	PyPartMC: A Pythonic interface to a particle-resolved, Monte Carlo aerosol simulation framework	Zachary D'Aquino	2023-08-03 21:10:44	http://arxiv.org/abs/2308.02052v3	PyPartMC is a Pythonic interface to PartMC, a stochastic, particle-resolved aerosol model implemented in Fortran. Both PyPartMC and PartMC are free, libre, and open-source. PyPartMC reduces the number of steps and mitigates the effort necessary to install and utilize the resources of PartMC. Without PyPartMC, setting up PartMC requires: working with UNIX shell, providing Fortran and C libraries, and performing standard Fortran and C source code configuration, compilation and linking. This can be challenging for those less experienced with computational research or those intending to use PartMC in environments where provision of UNIX tools is less straightforward (e.g., on Windows). PyPartMC offers a single-step installation/upgrade process of PartMC and all dependencies through the pip Python package manager on Linux, macOS, and Windows. This allows streamlined access to the unmodified and versioned Fortran internals of the PartMC codebase from both Python and other interoperable environments (e.g., Julia through PyCall). Consequently, users of PyPartMC can setup, run, process and visualize output of PartMC simulations using a single general-purpose programming language.			arxiv	['Sylwester Arabas', 'Jeffrey Curtis', 'Akshunna Vaishnav', 'Nicole Riemer', 'Matthew West']	247.0
497	The Janus System: Multi-paradigm Programming in Prolog and Python	Theresa Swift	2023-08-30 09:07:05	http://arxiv.org/abs/2308.15893v1	Python and Prolog express different programming paradigms, with different strengths. Python is wildly popular because it is well-structured, easy to use, and mixes well with thousands of scientific and machine learning programs written in C. Prolog's logic-based approach provides powerful reasoning capabilities, especially when combined with constraint evaluation, probabilistic reasoning, well-founded negation, and other advances. Both languages have commonalities as well: both are usually written in C, both are dynamically typed, and both use data structures based on a small number of recursive types. This paper describes the design and implementation of Janus, a system that tightly combines Prolog and Python into a single process. Janus bi-translates data structures and offers performance of many hundreds of thousands of round-trip inter-language calls per second. Although Janus is still new, it has been used in commercial applications including natural language processing, visual query answering and robotic automation. Janus was developed for XSB, but porting Janus code to a second Prolog has been straightforward, indicating that Janus is a tool that other Prologs may easily adopt.			arxiv	['Carl Andersen']	248.0
498	The Calysto Scheme Project	Douglas S. Blank	2023-10-16 23:41:21	http://arxiv.org/abs/2310.10886v1	Calysto Scheme is written in Scheme in Continuation-Passing Style, and converted through a series of correctness-preserving program transformations into Python. It has support for standard Scheme functionality, including call/cc, as well as syntactic extensions, a nondeterministic operator for automatic backtracking, and many extensions to allow Python interoperation. Because of its Python foundation, it can take advantage of modern Python libraries, including those for machine learning and other pedagogical contexts. Although Calysto Scheme was developed with educational purposes in mind, it has proven to be generally useful due to its simplicity and ease of installation. It has been integrated into the Jupyter Notebook ecosystem and used in the classroom to teach introductory Programming Languages with some interesting and unique twists.			arxiv	['James B. Marshall']	249.0
499	TorchProbe: Fuzzing Dynamic Deep Learning Compilers	Qidong Su	2023-10-30 23:20:47	http://arxiv.org/abs/2310.20078v1	Static and dynamic computational graphs represent two distinct approaches to constructing deep learning frameworks. The former prioritizes compiler-based optimizations, while the latter focuses on programmability and user-friendliness. The recent release of PyTorch 2.0, which supports compiling arbitrary deep learning programs in Python, signifies a new direction in the evolution of deep learning infrastructure to incorporate compiler techniques in a more dynamic manner and support more dynamic language features like dynamic control flows and closures. Given PyTorch's seamless integration with Python, its compiler aims to support arbitrary deep learning code written in Python. However, the inherent dynamism of Python poses challenges to the completeness and robustness of the compiler. While recent research has introduced fuzzing to test deep learning compilers, there is still a lack of comprehensive analysis on how to test dynamic features. To address this issue, we propose several code transformations to generate test cases involving dynamic features. These transformations preserve the program's semantics, ensuring that any discrepancy between the transformed and original programs indicates the presence of a bug. Through our approach, we have successfully identified twenty previously unknown bugs in the PyTorch compiler and its underlying tensor compiler Triton.			arxiv	['Chuqin Geng', 'Gennady Pekhimenko', 'Xujie Si']	250.0
